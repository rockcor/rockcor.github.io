<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>头条大数据推荐项目</title><meta name="description" content="Stay Acute."><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><link rel="stylesheet" href="/style/common/jquery.fancybox.min.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="
 环境配置
 启动 hadoop、hive(连接 mysql)
#~/hadoop_code/start_hive.sh
start-all.sh
service docker start
docker start mysql
hive --service metastore &amp;amp;

#查看mysql
docker exec -it mysql bash
mysql -uroot -p
#密码: password
ctrl+P+Q 退出

 启动 hbase、spark、thriftserver
cd ~/bigdata
start-hbase.sh
./spark/sbin/start-all.sh
hbase thrift start

 检查
jps

10948 ThriftServer
3.."><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Rockcor's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">头条大数据推荐项目</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Click back to the top</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="toc-text"> 环境配置</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8-hadoop-hive%E8%BF%9E%E6%8E%A5-mysql"><span class="toc-text"> 启动 hadoop、hive(连接 mysql)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8-hbase-spark-thriftserver"><span class="toc-text"> 启动 hbase、spark、thriftserver</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A3%80%E6%9F%A5"><span class="toc-text"> 检查</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%A6%BB%E7%BA%BF%E8%AE%A1%E7%AE%97%E6%9B%B4%E6%96%B0%E7%89%A9%E5%93%81%E7%94%BB%E5%83%8F"><span class="toc-text"> 离线计算更新物品画像</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8-sqoop-%E8%BF%81%E7%A7%BB%E5%92%8C%E5%90%8C%E6%AD%A5%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-text"> 用 Sqoop 迁移和同步数据库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%9F%8B%E7%82%B9%E6%94%B6%E9%9B%86"><span class="toc-text"> 用户行为埋点收集</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%8B%E7%82%B9%E8%AE%BE%E7%BD%AE"><span class="toc-text"> 埋点设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8-flume-%E6%94%B6%E9%9B%86%E5%88%B0-hive-%E4%B8%AD"><span class="toc-text"> 用 flume 收集到 hive 中</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-supervisor-%E7%AE%A1%E7%90%86-flume-%E8%BF%9B%E7%A8%8B"><span class="toc-text"> 使用 supervisor 管理 flume 进程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95"><span class="toc-text"> 测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A6%BB%E7%BA%BF%E6%96%87%E7%AB%A0%E7%94%BB%E5%83%8F%E8%AE%A1%E7%AE%97"><span class="toc-text"> 离线文章画像计算</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%9F%E5%A7%8B%E6%96%87%E7%AB%A0%E6%95%B0%E6%8D%AE%E5%90%88%E5%B9%B6"><span class="toc-text"> 原始文章数据合并</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%86%E5%8F%B2%E6%96%87%E7%AB%A0-tfidf-%E8%AE%A1%E7%AE%97"><span class="toc-text"> 历史文章 tfidf 计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%86%E5%8F%B2%E6%96%87%E7%AB%A0-textrank-%E8%AE%A1%E7%AE%97"><span class="toc-text"> 历史文章 textrank 计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E8%AF%8D%E5%90%91%E9%87%8F%E6%A8%A1%E5%9E%8B-word2vec-%E5%92%8C%E5%A2%9E%E9%87%8F%E6%96%87%E7%AB%A0%E7%BC%96%E7%A0%81"><span class="toc-text"> 训练词向量模型 word2vec 和增量文章编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8-apscheduler-%E5%AE%9A%E6%97%B6%E6%9B%B4%E6%96%B0%E6%96%87%E7%AB%A0%E7%94%BB%E5%83%8F"><span class="toc-text"> 用 Apscheduler 定时更新文章画像</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%A6%BB%E7%BA%BF%E7%94%A8%E6%88%B7%E5%8F%AC%E5%9B%9E%E9%9B%86%E4%B8%8E%E6%8E%92%E5%BA%8F%E8%AE%A1%E7%AE%97"><span class="toc-text"> 离线用户召回集与排序计算</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E8%8E%B7%E5%8F%96"><span class="toc-text"> 用户画像存储与获取</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%A8%E6%88%B7%E6%9D%83%E9%87%8D%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F"><span class="toc-text"> 用户权重计算公式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AC%E5%9B%9E%E6%8E%92%E5%BA%8F"><span class="toc-text"> 召回排序</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E-als-%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AC%E5%9B%9E"><span class="toc-text"> 基于 ALS 模型的召回</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E5%8F%AC%E5%9B%9E"><span class="toc-text"> 基于内容的召回</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A6%BB%E7%BA%BF%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B-ctr"><span class="toc-text"> 离线排序模型 CTR</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E4%B8%9A%E5%8A%A1"><span class="toc-text"> 实时计算业务</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka-%E7%AE%80%E4%BB%8B"><span class="toc-text"> Kafka 简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flume-%E6%94%B6%E9%9B%86%E6%97%A5%E5%BF%97%E5%88%B0-kafka"><span class="toc-text"> flume 收集日志到 kafka</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E6%97%B6%E5%8F%AC%E5%9B%9E%E9%9B%86%E4%B8%9A%E5%8A%A1"><span class="toc-text"> 实时召回集业务</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E4%B8%9A%E5%8A%A1%E6%B5%81%E5%AE%9E%E7%8E%B0%E4%B8%8E-ab-%E6%B5%8B%E8%AF%95"><span class="toc-text"> 推荐业务流实现与 AB 测试</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#grpc"><span class="toc-text"> gRPC</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAuser_recoproto%E5%8D%8F%E8%AE%AE%E6%96%87%E4%BB%B6"><span class="toc-text"> 创建user_reco.proto协议文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%BC%96%E5%86%99"><span class="toc-text"> 服务端编写</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E5%93%88%E5%B8%8C%E5%88%86%E6%A1%B6%E8%BF%9B%E8%A1%8C%E6%B5%81%E9%87%8F%E5%88%87%E5%88%86"><span class="toc-text"> 通过哈希分桶进行流量切分</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E6%9C%8D%E5%8A%A1%E4%B8%AD%E5%BF%83"><span class="toc-text"> 推荐服务中心</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E4%B8%AD%E5%BF%83%E4%B8%9A%E5%8A%A1%E9%80%BB%E8%BE%91"><span class="toc-text"> 推荐中心业务逻辑</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E7%94%A8%E6%88%B7%E5%8F%AC%E5%9B%9E%E7%BB%93%E6%9E%9C"><span class="toc-text"> 获取用户召回结果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E7%BA%BF%E9%A2%84%E6%B5%8B"><span class="toc-text"> 在线预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E8%B7%AF%E5%8F%AC%E5%9B%9E"><span class="toc-text"> 多路召回</span></a></li></ol></li></ol></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/BigData"><i class="tag post-item-tag">BigData</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">头条大数据推荐项目</h1><time class="has-text-grey" datetime="2023-02-13T05:36:25.488Z">2023-02-13</time><article class="mt-2 post-content"><p><img src="/2023/02/13/%E5%A4%B4%E6%9D%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E9%A1%B9%E7%9B%AE/image-20230211193156286.png" alt=""></p>
<h1 id="环境配置"><a class="markdownIt-Anchor" href="#环境配置"></a> 环境配置</h1>
<h2 id="启动-hadoop-hive连接-mysql"><a class="markdownIt-Anchor" href="#启动-hadoop-hive连接-mysql"></a> 启动 hadoop、hive(连接 mysql)</h2>
<pre class="highlight"><code class="shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">~/hadoop_code/start_hive.sh</span>
start-all.sh
service docker start
docker start mysql
hive --service metastore &amp;
</code></pre>
<pre class="highlight"><code class="shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">查看mysql</span>
docker exec -it mysql bash
mysql -uroot -p
<span class="hljs-meta prompt_">#</span><span class="language-bash">密码: password</span>
ctrl+P+Q 退出
</code></pre>
<h2 id="启动-hbase-spark-thriftserver"><a class="markdownIt-Anchor" href="#启动-hbase-spark-thriftserver"></a> 启动 hbase、spark、thriftserver</h2>
<pre class="highlight"><code class="shell">cd ~/bigdata
start-hbase.sh
./spark/sbin/start-all.sh
hbase thrift start
</code></pre>
<h2 id="检查"><a class="markdownIt-Anchor" href="#检查"></a> 检查</h2>
<pre class="highlight"><code class="shell">jps

10948 ThriftServer
3816 ResourceManager
3145 DataNode
6571 HMaster
4813 RunJar
7667 Master
13557 Jps
6998 HRegionServer
9691 Worker
9948 RunJar
3645 SecondaryNameNode
2751 NameNode
4223 NodeManager
6463 HQuorumPeer
</code></pre>
<h1 id="离线计算更新物品画像"><a class="markdownIt-Anchor" href="#离线计算更新物品画像"></a> 离线计算更新物品画像</h1>
<h2 id="用-sqoop-迁移和同步数据库"><a class="markdownIt-Anchor" href="#用-sqoop-迁移和同步数据库"></a> 用 Sqoop 迁移和同步数据库</h2>
<p>业务数据通常存放在 mysql 数据库中，我们需要把它定期同步到 hadoop 的 hive 数据仓库中。</p>
<pre class="highlight"><code class="sql"><span class="hljs-keyword">create</span> database if <span class="hljs-keyword">not</span> <span class="hljs-keyword">exists</span> toutiao comment "user,news information of 136 mysql" location <span class="hljs-string">'/user/hive/warehouse/toutiao.db/'</span>;
</code></pre>
<pre class="highlight"><code class="shell">sqoop list-databases --connect jdbc:mysql://192.168.19.137:3306/ --username root -P
</code></pre>
<p>密码：<strong>password</strong><br>
会显示连接到的数据库:</p>
<pre class="highlight"><code class="">information_schema
hive
mysql
performance_schema
sys
toutiao
</code></pre>
<p>写增量导入的 Sqoop 脚本</p>
<pre class="highlight"><code class="shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">/root/toutiao_project/scripts/import_incremental.sh</span>
time=`date +"%Y-%m-%d" -d "-1day"`
declare -A check
check=([user_profile]=update_time [user_basic]=last_login [news_channel]=update_time)
declare -A merge
merge=([user_profile]=user_id [user_basic]=user_id [news_channel]=channel_id)

for k in ${!check[@]}
do
    sqoop import \
        --connect jdbc:mysql://192.168.19.137/toutiao \
        --username root \
        --password password \
        --table $k \
        --m 4 \
        --target-dir /user/hive/warehouse/toutiao.db/$k \
        --incremental lastmodified \
        --check-column ${check[$k]} \
        --merge-key ${merge[$k]} \
        --last-value ${time}
done
</code></pre>
<p>写 crontab-shell 脚本让 Sqoop 定时运行</p>
<pre class="highlight"><code class="shell">crontab -e
<span class="hljs-meta prompt_">#</span><span class="language-bash">每30分钟运行一次</span>
*/30 * * * * /root/toutiao_project/scripts/import_incremental.sh
service crond start
</code></pre>
<blockquote>
<p>这里 MySQL 里面没有创建好，实际会报错，不管。</p>
</blockquote>
<h2 id="用户行为埋点收集"><a class="markdownIt-Anchor" href="#用户行为埋点收集"></a> 用户行为埋点收集</h2>
<h3 id="埋点设置"><a class="markdownIt-Anchor" href="#埋点设置"></a> 埋点设置</h3>
<pre class="highlight"><code class="json"># 曝光的参数，
<span class="hljs-punctuation">{</span><span class="hljs-attr">"actionTime"</span><span class="hljs-punctuation">:</span><span class="hljs-string">"2019-04-10 18:15:35"</span><span class="hljs-punctuation">,</span><span class="hljs-attr">"readTime"</span><span class="hljs-punctuation">:</span><span class="hljs-string">""</span><span class="hljs-punctuation">,</span><span class="hljs-attr">"channelId"</span><span class="hljs-punctuation">:</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span><span class="hljs-attr">"param"</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">{</span><span class="hljs-attr">"action"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"exposure"</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">"userId"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"2"</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">"articleId"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"[18577, 14299]"</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">"algorithmCombine"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"C2"</span><span class="hljs-punctuation">}</span><span class="hljs-punctuation">}</span>

# 对文章发生行为的参数
<span class="hljs-punctuation">{</span><span class="hljs-attr">"actionTime"</span><span class="hljs-punctuation">:</span><span class="hljs-string">"2019-04-10 18:12:11"</span><span class="hljs-punctuation">,</span><span class="hljs-attr">"readTime"</span><span class="hljs-punctuation">:</span><span class="hljs-string">"2886"</span><span class="hljs-punctuation">,</span><span class="hljs-attr">"channelId"</span><span class="hljs-punctuation">:</span><span class="hljs-number">18</span><span class="hljs-punctuation">,</span><span class="hljs-attr">"param"</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">{</span><span class="hljs-attr">"action"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"read"</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">"userId"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"2"</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">"articleId"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"18005"</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">"algorithmCombine"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"C2"</span><span class="hljs-punctuation">}</span><span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">{</span><span class="hljs-attr">"actionTime"</span><span class="hljs-punctuation">:</span><span class="hljs-string">"2019-04-10 18:15:32"</span><span class="hljs-punctuation">,</span><span class="hljs-attr">"readTime"</span><span class="hljs-punctuation">:</span><span class="hljs-string">""</span><span class="hljs-punctuation">,</span><span class="hljs-attr">"channelId"</span><span class="hljs-punctuation">:</span><span class="hljs-number">18</span><span class="hljs-punctuation">,</span><span class="hljs-attr">"param"</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">{</span><span class="hljs-attr">"action"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"click"</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">"userId"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"2"</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">"articleId"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"18005"</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">"algorithmCombine"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"C2"</span><span class="hljs-punctuation">}</span><span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">{</span><span class="hljs-attr">"actionTime"</span><span class="hljs-punctuation">:</span><span class="hljs-string">"2019-04-10 18:15:34"</span><span class="hljs-punctuation">,</span><span class="hljs-attr">"readTime"</span><span class="hljs-punctuation">:</span><span class="hljs-string">"1053"</span><span class="hljs-punctuation">,</span><span class="hljs-attr">"channelId"</span><span class="hljs-punctuation">:</span><span class="hljs-number">18</span><span class="hljs-punctuation">,</span><span class="hljs-attr">"param"</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">{</span><span class="hljs-attr">"action"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"read"</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">"userId"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"2"</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">"articleId"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"18005"</span><span class="hljs-punctuation">,</span> <span class="hljs-attr">"algorithmCombine"</span><span class="hljs-punctuation">:</span> <span class="hljs-string">"C2"</span><span class="hljs-punctuation">}</span><span class="hljs-punctuation">}</span>
...
</code></pre>
<h3 id="用-flume-收集到-hive-中"><a class="markdownIt-Anchor" href="#用-flume-收集到-hive-中"></a> 用 flume 收集到 hive 中</h3>
<p>创建 flume 配置文件</p>
<pre class="highlight"><code class="shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">/root/bigdata/flume/collect_click.conf</span>
a1.sources = s1
a1.sinks = k1
a1.channels = c1
<span class="hljs-meta prompt_">
# </span><span class="language-bash">实时查看日志文件尾</span>
a1.sources.s1.channels= c1
a1.sources.s1.type = exec
a1.sources.s1.command = tail -F /root/logs/userClick.log
<span class="hljs-meta prompt_"># </span><span class="language-bash">设置两个拦截器 1.格式过滤 2.附加时间戳</span>
a1.sources.s1.interceptors=i1 i2
a1.sources.s1.interceptors.i1.type=regex_filter
a1.sources.s1.interceptors.i1.regex=\\{.*\\}
a1.sources.r1.interceptors.i1.excludeEvents = false
a1.sources.s1.interceptors.i2.type=timestamp
<span class="hljs-meta prompt_">
# </span><span class="language-bash">指定缓冲区和batchdata</span>
a1.channels.c1.type=memory
a1.channels.c1.capacity=30000
a1.channels.c1.transactionCapacity=1000
<span class="hljs-meta prompt_">
# </span><span class="language-bash">连接hdfs</span>
a1.sinks.k1.type=hdfs
a1.sinks.k1.channel=c1
a1.sinks.k1.hdfs.path=hdfs://192.168.19.137:9000/user/hive/warehouse/profile.db/user_action/%Y-%m-%d
a1.sinks.k1.hdfs.useLocalTimeStamp = true
a1.sinks.k1.hdfs.fileType=DataStream
a1.sinks.k1.hdfs.writeFormat=Text
a1.sinks.k1.hdfs.rollInterval=0
a1.sinks.k1.hdfs.rollSize=10240
a1.sinks.k1.hdfs.rollCount=0
a1.sinks.k1.hdfs.idleTimeout=60
</code></pre>
<p>hive 中创建数据库和表</p>
<pre class="highlight"><code class="sql"><span class="hljs-keyword">create</span> database if <span class="hljs-keyword">not</span> <span class="hljs-keyword">exists</span> profile comment "user action" location <span class="hljs-string">'/user/hive/warehouse/profile.db/'</span>;

<span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> user_action(
actionTime STRING comment "user actions time",
readTime STRING comment "user reading time",
channelId <span class="hljs-type">INT</span> comment "article channel id",
param map comment "action parameter")
COMMENT "user primitive action"
PARTITIONED <span class="hljs-keyword">BY</span>(dt STRING)
<span class="hljs-type">ROW</span> FORMAT SERDE <span class="hljs-string">'org.apache.hive.hcatalog.data.JsonSerDe'</span>
LOCATION <span class="hljs-string">'/user/hive/warehouse/profile.db/user_action'</span>;
</code></pre>
<p><code>ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'</code>:添加 json 格式匹配功能</p>
<p>flume 会自动生成目录，在 hive 内部表上直接同步。但是如果想要通过 spark sql 获取内容，每天还是要主动关联：</p>
<pre class="highlight"><code class="sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> user_action <span class="hljs-keyword">add</span> <span class="hljs-keyword">partition</span> (dt<span class="hljs-operator">=</span><span class="hljs-string">'2023-02-11'</span>) location "/user/hive/warehouse/profile.db/user_action/2023-02-11/"
</code></pre>
<h3 id="使用-supervisor-管理-flume-进程"><a class="markdownIt-Anchor" href="#使用-supervisor-管理-flume-进程"></a> 使用 supervisor 管理 flume 进程</h3>
<p>flume 及其依赖写入脚本/root/toutiao_project/scripts/collect-click.sh</p>
<pre class="highlight"><code class="shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">!/usr/bin/env bash</span>

export JAVA_HOME=/root/bigdata/jdk
export HADOOP_HOME=/root/bigdata/hadoop
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin

/root/bigdata/flume/bin/flume-ng agent -c /root/bigdata/flume/conf -f /root/bigdata/flume/conf/collect_click.conf -Dflume.root.logger=INFO,console -name a1
</code></pre>
<p>在/etc/supervisor 的 reco.conf 添加</p>
<pre class="highlight"><code class="shell">[program:collect-click]
command=/bin/bash /root/toutiao_project/scripts/collect_click.sh
user=root
autorestart=true
redirect_stderr=true
stdout_logfile=/root/logs/collect.log
loglevel=info
stopsignal=KILL
stopasgroup=true
killasgroup=true
</code></pre>
<p>最后用 supervisord 启动收集</p>
<pre class="highlight"><code class="shell">pip install supervisor
supervisord -c /etc/supervisord.conf
supervisorctl status
</code></pre>
<h3 id="测试"><a class="markdownIt-Anchor" href="#测试"></a> 测试</h3>
<pre class="highlight"><code class="shell">echo {\"actionTime\":\"2023-02-11 21:04:39\",\"readTime\":\"\",\"channelId\":18,\"param\":{\"action\": \"click\", \"userId\": \"2\", \"articleId\": \"14299\", \"algorithmCombine\": \"C2\"}} &gt;&gt; userClick.log
</code></pre>
<p>在 <a target="_blank" rel="noopener" href="http://192.168.19.137:50070/explorer.html#/user/hive/warehouse/profile.db/user_action/">前端页面</a> 和 hive 中应当看到结果。</p>
<h2 id="离线文章画像计算"><a class="markdownIt-Anchor" href="#离线文章画像计算"></a> 离线文章画像计算</h2>
<h3 id="原始文章数据合并"><a class="markdownIt-Anchor" href="#原始文章数据合并"></a> 原始文章数据合并</h3>
<ol>
<li>创建 spark 基类</li>
<li>启动 jupyter</li>
</ol>
<pre class="highlight"><code class="shell">source activate py365
jupyter notebook --allow-root --ip=192.168.19.137
<span class="hljs-meta prompt_"># </span><span class="language-bash">密码：123</span>
</code></pre>
<ol start="3">
<li>运行 full_call/merge_data</li>
</ol>
<h3 id="历史文章-tfidf-计算"><a class="markdownIt-Anchor" href="#历史文章-tfidf-计算"></a> 历史文章 tfidf 计算</h3>
<ol>
<li>jieba 分词，去除停用词，保留名词、英文和自定义词库中的词</li>
<li>使用 spark ML 中 CountVectorizer 包进行词频统计，得到词袋模型/字典<br>
<img src="/2023/02/13/%E5%A4%B4%E6%9D%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E9%A1%B9%E7%9B%AE/image-20230211214707213.png" alt=""></li>
<li>使用 spark ML 中 IDF 包进一步计算每个单词的权重</li>
<li>根据索引和权重排序得到可以每篇文章权重最高的 20 个词</li>
</ol>
<h3 id="历史文章-textrank-计算"><a class="markdownIt-Anchor" href="#历史文章-textrank-计算"></a> 历史文章 textrank 计算</h3>
<pre class="highlight"><code class="python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">textrank</span>(<span class="hljs-params">partition</span>):
    <span class="hljs-keyword">import</span> os

    <span class="hljs-keyword">import</span> jieba
    <span class="hljs-keyword">import</span> jieba.analyse
    <span class="hljs-keyword">import</span> jieba.posseg <span class="hljs-keyword">as</span> pseg
    <span class="hljs-keyword">import</span> codecs

    abspath = <span class="hljs-string">"/root/words"</span>

    <span class="hljs-comment"># 结巴加载用户词典</span>
    userDict_path = os.path.join(abspath, <span class="hljs-string">"ITKeywords.txt"</span>)
    jieba.load_userdict(userDict_path)

    <span class="hljs-comment"># 停用词文本</span>
    stopwords_path = os.path.join(abspath, <span class="hljs-string">"stopwords.txt"</span>)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_stopwords_list</span>():
        <span class="hljs-string">"""返回stopwords列表"""</span>
        stopwords_list = [i.strip()
                          <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> codecs.<span class="hljs-built_in">open</span>(stopwords_path).readlines()]
        <span class="hljs-keyword">return</span> stopwords_list

    <span class="hljs-comment"># 所有的停用词列表</span>
    stopwords_list = get_stopwords_list()

    <span class="hljs-keyword">class</span> <span class="hljs-title class_">TextRank</span>(jieba.analyse.TextRank):
        <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, window=<span class="hljs-number">20</span>, word_min_len=<span class="hljs-number">2</span></span>):
            <span class="hljs-built_in">super</span>(TextRank, self).__init__()
            self.span = window  <span class="hljs-comment"># 窗口大小</span>
            self.word_min_len = word_min_len  <span class="hljs-comment"># 单词的最小长度</span>
            <span class="hljs-comment"># 要保留的词性，根据jieba github ，具体参见https://github.com/baidu/lac</span>
            self.pos_filt = <span class="hljs-built_in">frozenset</span>(
                (<span class="hljs-string">'n'</span>, <span class="hljs-string">'x'</span>, <span class="hljs-string">'eng'</span>, <span class="hljs-string">'f'</span>, <span class="hljs-string">'s'</span>, <span class="hljs-string">'t'</span>, <span class="hljs-string">'nr'</span>, <span class="hljs-string">'ns'</span>, <span class="hljs-string">'nt'</span>, <span class="hljs-string">"nw"</span>, <span class="hljs-string">"nz"</span>, <span class="hljs-string">"PER"</span>, <span class="hljs-string">"LOC"</span>, <span class="hljs-string">"ORG"</span>))

        <span class="hljs-keyword">def</span> <span class="hljs-title function_">pairfilter</span>(<span class="hljs-params">self, wp</span>):
            <span class="hljs-string">"""过滤条件，返回True或者False"""</span>

            <span class="hljs-keyword">if</span> wp.flag == <span class="hljs-string">"eng"</span>:
                <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(wp.word) &lt;= <span class="hljs-number">2</span>:
                    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span>

            <span class="hljs-keyword">if</span> wp.flag <span class="hljs-keyword">in</span> self.pos_filt <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(wp.word.strip()) &gt;= self.word_min_len \
                    <span class="hljs-keyword">and</span> wp.word.lower() <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> stopwords_list:
                <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span>
    <span class="hljs-comment"># TextRank过滤窗口大小为5，单词最小为2</span>
    textrank_model = TextRank(window=<span class="hljs-number">5</span>, word_min_len=<span class="hljs-number">2</span>)
    allowPOS = (<span class="hljs-string">'n'</span>, <span class="hljs-string">"x"</span>, <span class="hljs-string">'eng'</span>, <span class="hljs-string">'nr'</span>, <span class="hljs-string">'ns'</span>, <span class="hljs-string">'nt'</span>, <span class="hljs-string">"nw"</span>, <span class="hljs-string">"nz"</span>, <span class="hljs-string">"c"</span>)
</code></pre>
<p>同样可以给出 20 个关键词。但是最终结果由 Textank * IDF 再取前 20 给出<br>
<img src="/2023/02/13/%E5%A4%B4%E6%9D%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E9%A1%B9%E7%9B%AE/image-20230211220415129.png" alt=""></p>
<h3 id="训练词向量模型-word2vec-和增量文章编码"><a class="markdownIt-Anchor" href="#训练词向量模型-word2vec-和增量文章编码"></a> 训练词向量模型 word2vec 和增量文章编码</h3>
<pre class="highlight"><code class="python"><span class="hljs-keyword">from</span> pyspark.ml.feature <span class="hljs-keyword">import</span> Word2Vec

<span class="hljs-comment"># minCount忽略总频率低于此频率的所有单词</span>
w2v = Word2Vec(vectorSize=<span class="hljs-number">100</span>, inputCol=<span class="hljs-string">'words'</span>, outputCol=<span class="hljs-string">'model'</span>, minCount=<span class="hljs-number">3</span>)
w2v_model = w2v.fit(words_df)
w2v_model.write().overwrite().save(<span class="hljs-string">"hdfs://hadoop-master:9000/headlines/models/test.word2vec"</span>)

<span class="hljs-keyword">from</span> pyspark.ml.feature <span class="hljs-keyword">import</span> Word2VecModel

word_vec = Word2VecModel.load(<span class="hljs-string">"hdfs://hadoop-master:9000/headlines/models/test.word2vec"</span>)
vectors = word_vec.getVectors()
</code></pre>
<p>编码后和每个单词权重相乘，最终得到每篇文章的特征向量（文章画像）</p>
<h3 id="用-apscheduler-定时更新文章画像"><a class="markdownIt-Anchor" href="#用-apscheduler-定时更新文章画像"></a> 用 Apscheduler 定时更新文章画像</h3>
<ol>
<li>增量更新文章编码，包括 hive 里的 article_profile
<blockquote>
<p>新词可以用平均值填充</p>
</blockquote>
</li>
<li>定期重新计算 tfidf、textrank 和 word2vec 模型</li>
<li>Apsheduler 是 crontab 升级版</li>
</ol>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> os
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(<span class="hljs-number">0</span>, os.path.join(BASE_DIR))
sys.path.insert(<span class="hljs-number">0</span>, os.path.join(BASE_DIR, <span class="hljs-string">'reco_sys'</span>))
<span class="hljs-keyword">from</span> apscheduler.schedulers.blocking <span class="hljs-keyword">import</span> BlockingScheduler
<span class="hljs-keyword">from</span> apscheduler.executors.pool <span class="hljs-keyword">import</span> ProcessPoolExecutor
<span class="hljs-keyword">from</span> scheduler.update <span class="hljs-keyword">import</span> update_article_profile


<span class="hljs-comment"># 创建scheduler，多进程执行</span>
executors = {
    <span class="hljs-string">'default'</span>: ProcessPoolExecutor(<span class="hljs-number">3</span>)
}

scheduler = BlockingScheduler(executors=executors)

<span class="hljs-comment"># 添加定时更新任务更新文章画像,每隔一小时更新</span>
scheduler.add_job(update_article_profile, trigger=<span class="hljs-string">'interval'</span>, hours=<span class="hljs-number">1</span>)


scheduler.start()
</code></pre>
<h1 id="离线用户召回集与排序计算"><a class="markdownIt-Anchor" href="#离线用户召回集与排序计算"></a> 离线用户召回集与排序计算</h1>
<h2 id="用户画像存储与获取"><a class="markdownIt-Anchor" href="#用户画像存储与获取"></a> 用户画像存储与获取</h2>
<p>用户画像需要快速迭代，方便读取，选择存储在 hbase 中。这里我们从 hbase 关联到 hive。</p>
<pre class="highlight"><code class="sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">external</span> <span class="hljs-keyword">table</span> user_profile_hbase(
user_id STRING comment "userID",
information map<span class="hljs-operator">&lt;</span>string, <span class="hljs-keyword">DOUBLE</span><span class="hljs-operator">&gt;</span> comment "user basic information",
article_partial map<span class="hljs-operator">&lt;</span>string, <span class="hljs-keyword">DOUBLE</span><span class="hljs-operator">&gt;</span> comment "article partial",
env map<span class="hljs-operator">&lt;</span>string, <span class="hljs-type">INT</span><span class="hljs-operator">&gt;</span> comment "user env")
COMMENT "user profile table"
STORED <span class="hljs-keyword">BY</span> <span class="hljs-string">'org.apache.hadoop.hive.hbase.HBaseStorageHandler'</span>
<span class="hljs-keyword">WITH</span> SERDEPROPERTIES ("hbase.columns.mapping" <span class="hljs-operator">=</span> ":key,basic:,partial:,env:")
TBLPROPERTIES ("hbase.table.name" <span class="hljs-operator">=</span> "user_profile");
</code></pre>
<p>读取 user_article_basic 表，<strong>合并行为表</strong>与<strong>文章画像中的主题词</strong></p>
<pre class="highlight"><code class="python"><span class="hljs-comment"># 获取基本用户行为信息，然后进行文章画像的主题词合并</span>
uup.spark.sql(<span class="hljs-string">"use profile"</span>)
<span class="hljs-comment"># 取出日志中的channel_id</span>
user_article_ = uup.spark.sql(<span class="hljs-string">"select * from user_article_basic"</span>).drop(<span class="hljs-string">'channel_id'</span>)
uup.spark.sql(<span class="hljs-string">'use article'</span>)
article_label = uup.spark.sql(<span class="hljs-string">"select article_id, channel_id, topics from article_profile"</span>)
<span class="hljs-comment"># 合并使用文章中正确的channel_id</span>
click_article_res = user_article_.join(article_label, how=<span class="hljs-string">'left'</span>, on=[<span class="hljs-string">'article_id'</span>])
</code></pre>
<h3 id="用户权重计算公式"><a class="markdownIt-Anchor" href="#用户权重计算公式"></a> 用户权重计算公式</h3>
<p><strong>用户标签权重 =( 行为类型权重之和) × 时间衰减</strong></p>
<table>
<thead>
<tr>
<th>行为</th>
<th>分值</th>
</tr>
</thead>
<tbody>
<tr>
<td>阅读时间(&lt;1000)</td>
<td>1</td>
</tr>
<tr>
<td>阅读时间(&gt;=1000)</td>
<td>2</td>
</tr>
<tr>
<td>收藏</td>
<td>2</td>
</tr>
<tr>
<td>分享</td>
<td>3</td>
</tr>
<tr>
<td>点击</td>
<td>5</td>
</tr>
<tr>
<td><strong>时间衰减</strong>=1/(log(t)+1) ,t 为时间发生时间距离当前时间的大小</td>
<td></td>
</tr>
</tbody>
</table>
<p>使用 happybase 关联文章表，统计每个词的标签权重，得到用户的关键词喜好 top10</p>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> happybase
<span class="hljs-comment">#  用于读取hbase缓存结果配置</span>
pool = happybase.ConnectionPool(size=<span class="hljs-number">10</span>, host=<span class="hljs-string">'192.168.19.137'</span>, port=<span class="hljs-number">9090</span>)

<span class="hljs-keyword">with</span> pool.connection() <span class="hljs-keyword">as</span> conn:
    table = conn.table(<span class="hljs-string">'user_profile'</span>)
    <span class="hljs-comment"># 获取每个键 对应的所有列的结果</span>
    data = table.row(<span class="hljs-string">b'user:2'</span>, columns=[<span class="hljs-string">b'partial'</span>])
    conn.close()
</code></pre>
<p>完善代码后，添加到 Apscheduler 中</p>
<pre class="highlight"><code class="python">scheduler.add_job(update_user_profile, trigger=<span class="hljs-string">'interval'</span>, hours=<span class="hljs-number">2</span>)
</code></pre>
<h2 id="召回排序"><a class="markdownIt-Anchor" href="#召回排序"></a> 召回排序</h2>
<ul>
<li>用户冷启动（前期点击行为较少情况）
<ul>
<li>非个性化推荐
<ul>
<li><strong>热门召回</strong>：自定义热门规则，根据当前时间段热点定期更新维护<em>热点文章库</em></li>
<li><strong>新文章召回</strong>：为了提高新文章的曝光率，建立<em>新文章库</em>，进行推荐</li>
</ul>
</li>
<li>个性化推荐：
<ul>
<li><strong>基于内容的协同过滤在线召回</strong>：基于用户实时兴趣画像相似的召回结果用于首页的个性化推荐</li>
</ul>
</li>
</ul>
</li>
<li>后期离线部分（用户点击行为较多，用户画像完善）
<ul>
<li>建立用户长期兴趣画像（详细）：包括用户各个维度的兴趣特征</li>
<li>训练排序模型
<ul>
<li><strong>LR 模型、FTRL、Wide&amp;Deep</strong></li>
</ul>
</li>
<li>离线部分的召回：
<ul>
<li><strong>基于模型协同过滤推荐离线召回</strong>：ALS</li>
<li><strong>基于内容的离线召回</strong>：或者称基于用户画像的召回</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="基于-als-模型的召回"><a class="markdownIt-Anchor" href="#基于-als-模型的召回"></a> 基于 ALS 模型的召回</h3>
<pre class="highlight"><code class="python"><span class="hljs-keyword">from</span> pyspark.ml.recommendation <span class="hljs-keyword">import</span> ALS
<span class="hljs-comment"># 模型训练和推荐默认每个用户固定文章个数</span>
als = ALS(userCol=<span class="hljs-string">'als_user_id'</span>, itemCol=<span class="hljs-string">'als_article_id'</span>, ratingCol=<span class="hljs-string">'clicked'</span>, checkpointInterval=<span class="hljs-number">1</span>)
model = als.fit(als_user_article_click)
recall_res = model.recommendForAllUsers(<span class="hljs-number">100</span>)
</code></pre>
<p>召回结果存储</p>
<pre class="highlight"><code class="python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">save_offline_recall_hbase</span>(<span class="hljs-params">partition</span>):
	<span class="hljs-string">"""离线模型召回结果存储
	"""</span>
	<span class="hljs-keyword">import</span> happybase
	pool = happybase.ConnectionPool(size=<span class="hljs-number">10</span>, host=<span class="hljs-string">'hadoop-master'</span>, port=<span class="hljs-number">9090</span>)
	<span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> partition:
		<span class="hljs-keyword">with</span> pool.connection() <span class="hljs-keyword">as</span> conn:
			<span class="hljs-comment"># 获取历史看过的该频道文章</span>
			history_table = conn.table(<span class="hljs-string">'history_recall'</span>)
			<span class="hljs-comment"># 多个版本</span>
			data = history_table.cells(<span class="hljs-string">'reco:his:{}'</span>.<span class="hljs-built_in">format</span>(row.user_id).encode(),
									   <span class="hljs-string">'channel:{}'</span>.<span class="hljs-built_in">format</span>(row.channel_id).encode())

			history = []
			<span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(data) &gt;= <span class="hljs-number">2</span>:
				<span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> data[:-<span class="hljs-number">1</span>]:
					history.extend(<span class="hljs-built_in">eval</span>(l))
			<span class="hljs-keyword">else</span>:
				history = []

			<span class="hljs-comment"># 过滤reco_article与history</span>
			reco_res = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(row.article_list) - <span class="hljs-built_in">set</span>(history))

			<span class="hljs-keyword">if</span> reco_res:

				table = conn.table(<span class="hljs-string">'cb_recall'</span>)
				<span class="hljs-comment"># 默认放在推荐频道</span>
				table.put(<span class="hljs-string">'recall:user:{}'</span>.<span class="hljs-built_in">format</span>(row.user_id).encode(),
						  {<span class="hljs-string">'als:{}'</span>.<span class="hljs-built_in">format</span>(row.channel_id).encode(): <span class="hljs-built_in">str</span>(reco_res).encode()})
				conn.close()

				<span class="hljs-comment"># 放入历史推荐过文章</span>
				history_table.put(<span class="hljs-string">"reco:his:{}"</span>.<span class="hljs-built_in">format</span>(row.user_id).encode(),
								  {<span class="hljs-string">'channel:{}'</span>.<span class="hljs-built_in">format</span>(row.channel_id): <span class="hljs-built_in">str</span>(reco_res).encode()})
			conn.close()

als_recall.foreachPartition(save_offline_recall_hbase)
</code></pre>
<h3 id="基于内容的召回"><a class="markdownIt-Anchor" href="#基于内容的召回"></a> 基于内容的召回</h3>
<p>即根据 LHS 等算法，快速得到用户当前点击文章的相似文章集，进行推荐。</p>
<pre class="highlight"><code class="python"><span class="hljs-comment"># 循环partition</span>
<span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> partition:
    <span class="hljs-comment"># 获取相似文章结果表</span>
    similar_article = similar_table.row(<span class="hljs-built_in">str</span>(row.article_id).encode(),
                                        columns=[<span class="hljs-string">b'similar'</span>])
    <span class="hljs-comment"># 相似文章相似度排序过滤，召回不需要太大的数据， 百个，千</span>
    _srt = <span class="hljs-built_in">sorted</span>(similar_article.items(), key=<span class="hljs-keyword">lambda</span> item: item[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)
    <span class="hljs-keyword">if</span> _srt:
        <span class="hljs-comment"># 每次行为推荐若干篇文章</span>
        reco_article = [<span class="hljs-built_in">int</span>(i[<span class="hljs-number">0</span>].split(<span class="hljs-string">b':'</span>)[<span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> _srt][:<span class="hljs-number">10</span>]
</code></pre>
<blockquote>
<p>基于内容和基于模型的结果存入同一张 hbase 表</p>
</blockquote>
<pre class="highlight"><code class="sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">external</span> <span class="hljs-keyword">table</span> cb_recall_hbase(
user_id STRING comment "userID",
als map<span class="hljs-operator">&lt;</span>string, <span class="hljs-keyword">ARRAY</span><span class="hljs-operator">&lt;</span><span class="hljs-type">BIGINT</span><span class="hljs-operator">&gt;&gt;</span> comment "als recall",
content map<span class="hljs-operator">&lt;</span>string, <span class="hljs-keyword">ARRAY</span><span class="hljs-operator">&lt;</span><span class="hljs-type">BIGINT</span><span class="hljs-operator">&gt;&gt;</span> comment "content recall",
online map<span class="hljs-operator">&lt;</span>string, <span class="hljs-keyword">ARRAY</span><span class="hljs-operator">&lt;</span><span class="hljs-type">BIGINT</span><span class="hljs-operator">&gt;&gt;</span> comment "online recall")
COMMENT "user recall table"
STORED <span class="hljs-keyword">BY</span> <span class="hljs-string">'org.apache.hadoop.hive.hbase.HBaseStorageHandler'</span>
<span class="hljs-keyword">WITH</span> SERDEPROPERTIES ("hbase.columns.mapping" <span class="hljs-operator">=</span> ":key,als:,content:,online:")
TBLPROPERTIES ("hbase.table.name" <span class="hljs-operator">=</span> "cb_recall");
</code></pre>
<h3 id="离线排序模型-ctr"><a class="markdownIt-Anchor" href="#离线排序模型-ctr"></a> 离线排序模型 CTR</h3>
<p>CTR（Click-Through Rate）预估：给定一个 Item，预测该 Item 会被点击的概率<br>
最基础的模型目前都是基于 LR 的点击率预估策略，目前在工业使用模型做预估的有这么几种类型</p>
<ul>
<li>宽模型 + 特征⼯程
<ul>
<li>LR/MLR + 非 ID 类特征(⼈⼯离散/GBDT/FM)</li>
<li>spark 中可以直接使用</li>
</ul>
</li>
<li>宽模型 + 深模型
<ul>
<li>wide&amp;deep,DeepFM</li>
<li>使用 TensorFlow 进行训练</li>
</ul>
</li>
<li>深模型：
<ul>
<li>DNN + 特征 embedding</li>
<li>使用 TensorFlow 进行训练</li>
</ul>
</li>
</ul>
<p>特征包含：用户画像关键词 10+文章画像关键词 10+channel_id(25, onehot)+文章主题词向量(concat, 100)</p>
<pre class="highlight"><code class="python">cols = [<span class="hljs-string">'article_id'</span>, <span class="hljs-string">'user_id'</span>, <span class="hljs-string">'channel_id'</span>, <span class="hljs-string">'articlevector'</span>, <span class="hljs-string">'weights'</span>, <span class="hljs-string">'article_weights'</span>, <span class="hljs-string">'clicked'</span>]

train_version_two = VectorAssembler().setInputCols(cols[<span class="hljs-number">2</span>:<span class="hljs-number">6</span>]).setOutputCol(<span class="hljs-string">"features"</span>).transform(train)
</code></pre>
<p><img src="/2023/02/13/%E5%A4%B4%E6%9D%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E9%A1%B9%E7%9B%AE/image-20230212102837399.png" alt=""><br>
训练线性回归模型，可以服务于在线召回</p>
<pre class="highlight"><code class="python">lr = LogisticRegression()
model = lr.setLabelCol(<span class="hljs-string">"clicked"</span>).setFeaturesCol(<span class="hljs-string">"features"</span>).fit(train_version_two)
model.save(<span class="hljs-string">"hdfs://hadoop-master:9000/headlines/models/lr.obj"</span>)
</code></pre>
<p>定期重新训练</p>
<h1 id="实时计算业务"><a class="markdownIt-Anchor" href="#实时计算业务"></a> 实时计算业务</h1>
<p>实时（在线）计算：</p>
<ul>
<li>解决用户冷启动问题</li>
<li>实时计算能够根据用户的点击实时反馈，快速跟踪用户的喜好</li>
</ul>
<p>日志数据我们已经收集到 hadoop 中，但是做实时分析的时候，我们需要将每个时刻用户产生的点击行为收集到 KAFKA 当中，等待 spark streaming 程序去消费。</p>
<h2 id="kafka-简介"><a class="markdownIt-Anchor" href="#kafka-简介"></a> Kafka 简介</h2>
<p><strong>Kafka</strong>是由<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Apache%E8%BD%AF%E4%BB%B6%E5%9F%BA%E9%87%91%E4%BC%9A" title="Apache软件基金会">Apache 软件基金会</a>开发的一个<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%BC%80%E6%BA%90" title="开源">开源</a><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%B5%81%E5%A4%84%E7%90%86" title="流处理">流处理</a>平台，由<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Scala" title="Scala">Scala</a>和<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Java" title="Java">Java</a>编写。该项目的目标是为处理实时数据提供一个统一、高吞吐、低延迟的平台。其持久化层本质上是一个“按照分布式事务日志架构的大规模发布/订阅消息队列”，这使它作为企业级基础设施来处理流式数据非常有价值。</p>
<h2 id="flume-收集日志到-kafka"><a class="markdownIt-Anchor" href="#flume-收集日志到-kafka"></a> flume 收集日志到 kafka</h2>
<p>开启 zookeeper,需要在一直在服务器端实时运行，以守护进程运行</p>
<pre class="highlight"><code class="shell">/root/bigdata/kafka/bin/zookeeper-server-start.sh -daemon /root/bigdata/kafka/config/zookeeper.properties
</code></pre>
<p>以及 kafka</p>
<pre class="highlight"><code class="">/root/bigdata/kafka/bin/kafka-server-start.sh /root/bigdata/kafka/config/server.properties
</code></pre>
<p>测试</p>
<pre class="highlight"><code class="shell"><span class="hljs-meta prompt_"> #</span><span class="language-bash">开启消息生产者</span>
/root/bigdata/kafka/bin/kafka-console-producer.sh --broker-list 192.168.19.137:9092 --sync --topic click-trace
<span class="hljs-meta prompt_"> #</span><span class="language-bash">开启消费者</span>
/root/bigdata/kafka/bin/kafka-console-consumer.sh --bootstrap-server 192.168.19.137:9092 --topic  click-trace
<span class="hljs-meta prompt_">#</span><span class="language-bash">在生产者窗口输入任意内容测试</span>
</code></pre>
<p>修改原来收集日志的文件，添加 flume 收集日志行为到 kafka 的 source, channel, sink</p>
<pre class="highlight"><code class="">a1.sources = s1
a1.sinks = k1 k2
a1.channels = c1 c2

a1.sources.s1.channels= c1 c2
a1.sources.s1.type = exec
a1.sources.s1.command = tail -F /root/logs/userClick.log
a1.sources.s1.interceptors=i1 i2
a1.sources.s1.interceptors.i1.type=regex_filter
a1.sources.r1.interceptors.i1.excludeEvents = false
a1.sources.s1.interceptors.i1.regex=\\{.*\\}
a1.sources.s1.interceptors.i2.type=timestamp

# channel1
a1.channels.c1.type=memory
a1.channels.c1.capacity=30000
a1.channels.c1.transactionCapacity=1000

# channel2
a1.channels.c2.type=memory
a1.channels.c2.capacity=30000
a1.channels.c2.transactionCapacity=1000

# k1
a1.sinks.k1.type=hdfs
a1.sinks.k1.channel=c1
a1.sinks.k1.hdfs.path=hdfs://192.168.19.137:9000/user/hive/warehouse/profile.db/user_action/%Y-%m-%d
a1.sinks.k1.hdfs.useLocalTimeStamp = true
a1.sinks.k1.hdfs.fileType=DataStream
a1.sinks.k1.hdfs.writeFormat=Text
a1.sinks.k1.hdfs.rollInterval=0
a1.sinks.k1.hdfs.rollSize=10240
a1.sinks.k1.hdfs.rollCount=0
a1.sinks.k1.hdfs.idleTimeout=60

# k2
a1.sinks.k2.channel=c2
a1.sinks.k2.type=org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k2.kafka.bootstrap.servers=192.168.19.137:9092
a1.sinks.k2.kafka.topic=click-trace
a1.sinks.k2.kafka.batchSize=20
a1.sinks.k2.kafka.producer.requiredAcks=1
</code></pre>
<p>添加 supervisor 配置</p>
<pre class="highlight"><code class="">[program:kafka]
command=/bin/bash /root/toutiao_project/scripts/start_kafka.sh
user=root
autorestart=true
redirect_stderr=true
stdout_logfile=/root/logs/kafka.log
loglevel=info
stopsignal=KILL
stopasgroup=true
killasgroup=true
</code></pre>
<p>用 supervisorctl 启动后测试</p>
<h2 id="实时召回集业务"><a class="markdownIt-Anchor" href="#实时召回集业务"></a> 实时召回集业务</h2>
<p>实时召回基于相似度的文章推荐</p>
<p>创建 online 文件夹，建立在线实时处理程序</p>
<ul>
<li>目的：对用户日志进行处理，实时达到求出相似文章，放入用户召回集合中</li>
<li>步骤：
<ul>
<li>1、配置 spark streaming 信息</li>
<li>2、读取点击行为日志数据，获取相似文章列表</li>
<li>3、过滤历史文章集合</li>
<li>4、存入召回结果以及历史记录结果</li>
</ul>
</li>
</ul>
<p>happybase 和 kafka 对接 spark streaming 的配置</p>
<pre class="highlight"><code class="python"><span class="hljs-comment"># 增加spark online 启动配置</span>
<span class="hljs-keyword">class</span> <span class="hljs-title class_">DefaultConfig</span>(<span class="hljs-title class_ inherited__">object</span>):
    <span class="hljs-string">"""默认的一些配置信息
    """</span>
    SPARK_ONLINE_CONFIG = (
        (<span class="hljs-string">"spark.app.name"</span>, <span class="hljs-string">"onlineUpdate"</span>),  <span class="hljs-comment"># 设置启动的spark的app名称，没有提供，将随机产生一个名称</span>
        (<span class="hljs-string">"spark.master"</span>, <span class="hljs-string">"yarn"</span>),
        (<span class="hljs-string">"spark.executor.instances"</span>, <span class="hljs-number">4</span>)
    )
<span class="hljs-comment"># 添加sparkstreaming启动对接kafka的配置</span>

<span class="hljs-keyword">from</span> pyspark <span class="hljs-keyword">import</span> SparkConf
<span class="hljs-keyword">from</span> pyspark.sql <span class="hljs-keyword">import</span> SparkSession
<span class="hljs-keyword">from</span> pyspark <span class="hljs-keyword">import</span> SparkContext
<span class="hljs-keyword">from</span> pyspark.streaming <span class="hljs-keyword">import</span> StreamingContext
<span class="hljs-keyword">from</span> pyspark.streaming.kafka <span class="hljs-keyword">import</span> KafkaUtils
<span class="hljs-keyword">from</span> setting.default <span class="hljs-keyword">import</span> DefaultConfig

<span class="hljs-keyword">import</span> happybase

<span class="hljs-comment">#  用于读取hbase缓存结果配置</span>
pool = happybase.ConnectionPool(size=<span class="hljs-number">10</span>, host=<span class="hljs-string">'hadoop-master'</span>, port=<span class="hljs-number">9090</span>)
<span class="hljs-comment"># 1、创建conf</span>
conf = SparkConf()
conf.setAll(DefaultConfig.SPARK_ONLINE_CONFIG)
<span class="hljs-comment"># 建立spark session以及spark streaming context</span>
sc = SparkContext(conf=conf)
<span class="hljs-comment"># 创建Streaming Context</span>
stream_c = StreamingContext(sc, <span class="hljs-number">60</span>)

<span class="hljs-comment"># KAFKA配置</span>
KAFKA_SERVER = <span class="hljs-string">"192.168.19.137:9092"</span>
<span class="hljs-comment"># 基于内容召回配置，用于收集用户行为，获取相似文章实时推荐</span>
similar_kafkaParams = {<span class="hljs-string">"metadata.broker.list"</span>: DefaultConfig.KAFKA_SERVER, <span class="hljs-string">"group.id"</span>: <span class="hljs-string">'similar'</span>}
SIMILAR_DS = KafkaUtils.createDirectStream(stream_c, [<span class="hljs-string">'click-trace'</span>], similar_kafkaParams)
</code></pre>
<p>主代码</p>
<pre class="highlight"><code class="python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">OnlineRecall</span>(<span class="hljs-title class_ inherited__">object</span>):
<span class="hljs-string">"""在线处理计算平台
"""</span>
	<span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
		<span class="hljs-keyword">pass</span>
	
	<span class="hljs-keyword">def</span> <span class="hljs-title function_">_update_online_cb</span>(<span class="hljs-params">self</span>):
			<span class="hljs-string">"""
			通过点击行为更新用户的cb召回表中的online召回结果
			:return:
			"""</span>
			<span class="hljs-keyword">def</span> <span class="hljs-title function_">foreachFunc</span>(<span class="hljs-params">rdd</span>):
	
				<span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> rdd.collect():
					logger.info(
						<span class="hljs-string">"{}, INFO: rdd filter"</span>.<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>)))
					<span class="hljs-comment"># 判断日志行为类型，只处理点击流日志</span>
					<span class="hljs-keyword">if</span> data[<span class="hljs-string">"param"</span>][<span class="hljs-string">"action"</span>] <span class="hljs-keyword">in</span> [<span class="hljs-string">"click"</span>, <span class="hljs-string">"collect"</span>, <span class="hljs-string">"share"</span>]:
						<span class="hljs-comment"># print(data)</span>
						<span class="hljs-keyword">with</span> pool.connection() <span class="hljs-keyword">as</span> conn:
							<span class="hljs-keyword">try</span>:
								<span class="hljs-comment"># 相似文章表</span>
								sim_table = conn.table(<span class="hljs-string">"article_similar"</span>)
	
								<span class="hljs-comment"># 根据用户点击流日志涉及文章找出与之最相似文章(基于内容的相似)，选取TOP-k相似的作为召回推荐结果</span>
								_dic = sim_table.row(<span class="hljs-built_in">str</span>(data[<span class="hljs-string">"param"</span>][<span class="hljs-string">"articleId"</span>]).encode(), columns=[<span class="hljs-string">b"similar"</span>])
								_srt = <span class="hljs-built_in">sorted</span>(_dic.items(), key=<span class="hljs-keyword">lambda</span> obj: obj[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 按相似度排序</span>
								<span class="hljs-keyword">if</span> _srt:
	
									topKSimIds = [<span class="hljs-built_in">int</span>(i[<span class="hljs-number">0</span>].split(<span class="hljs-string">b":"</span>)[<span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> _srt[:self.k]]
	
									<span class="hljs-comment"># 根据历史推荐集过滤，已经给用户推荐过的文章</span>
									history_table = conn.table(<span class="hljs-string">"history_recall"</span>)
	
									_history_data = history_table.cells(
										<span class="hljs-string">b"reco:his:%s"</span> % data[<span class="hljs-string">"param"</span>][<span class="hljs-string">"userId"</span>].encode(),
										<span class="hljs-string">b"channel:%d"</span> % data[<span class="hljs-string">"channelId"</span>]
									)
									<span class="hljs-comment"># print("_history_data: ", _history_data)</span>
	
									history = []
									<span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(data) &gt;= <span class="hljs-number">2</span>:
										<span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> data[:-<span class="hljs-number">1</span>]:
											history.extend(<span class="hljs-built_in">eval</span>(l))
									<span class="hljs-keyword">else</span>:
										history = []
	
									<span class="hljs-comment"># 根据历史召回记录，过滤召回结果</span>
									recall_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(topKSimIds) - <span class="hljs-built_in">set</span>(history_data))
	
									<span class="hljs-comment"># print("recall_list: ", recall_list)</span>
									logger.info(<span class="hljs-string">"{}, INFO: store user:{} cb_recall data"</span>.<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), data[<span class="hljs-string">"param"</span>][<span class="hljs-string">"userId"</span>]))
									<span class="hljs-keyword">if</span> recall_list:
										<span class="hljs-comment"># 如果有推荐结果集，那么将数据添加到cb_recall表中，同时记录到历史记录表中</span>
										logger.info(
											<span class="hljs-string">"{}, INFO: get online-recall data"</span>.<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>)))
										recall_table = conn.table(<span class="hljs-string">"cb_recall"</span>)
	
										recall_table.put(
											<span class="hljs-string">b"recall:user:%s"</span> % data[<span class="hljs-string">"param"</span>][<span class="hljs-string">"userId"</span>].encode(),
											{<span class="hljs-string">b"online:%d"</span> % data[<span class="hljs-string">"channelId"</span>]: <span class="hljs-built_in">str</span>(recall_list).encode()}
										)
	
										history_table.put(
											<span class="hljs-string">b"reco:his:%s"</span> % data[<span class="hljs-string">"param"</span>][<span class="hljs-string">"userId"</span>].encode(),
											{<span class="hljs-string">b"channel:%d"</span> % data[<span class="hljs-string">"channelId"</span>]: <span class="hljs-built_in">str</span>(recall_list).encode()}
										)
							<span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
								logger.info(<span class="hljs-string">"{}, WARN: {}"</span>.<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), e))
							<span class="hljs-keyword">finally</span>:
								conn.close()
	
			SIMILAR_DS.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: json.loads(x[<span class="hljs-number">1</span>])).foreachRDD(foreachFunc)
	
			<span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>
</code></pre>
<h1 id="推荐业务流实现与-ab-测试"><a class="markdownIt-Anchor" href="#推荐业务流实现与-ab-测试"></a> 推荐业务流实现与 AB 测试</h1>
<ul>
<li>
<p>逻辑流程</p>
<ul>
<li>1、后端发送推荐请求，实时推荐系统拿到请求参数
<ul>
<li>grpc对接</li>
</ul>
</li>
<li>2、根据用户进行ABTest分流
<ul>
<li>ABTest实验中心，用于进行分流任务，方便测试调整不同的模型上线</li>
</ul>
</li>
<li>3、推荐中心服务
<ul>
<li>根据用户在ABTest分配的算法进行召回服务和排序服务读取返回结果</li>
</ul>
</li>
<li>4、返回推荐结果和埋点参数封装</li>
</ul>
</li>
</ul>
<p><img src="/2023/02/13/%E5%A4%B4%E6%9D%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E9%A1%B9%E7%9B%AE/image-20230212160039176.png" alt=""></p>
<h2 id="grpc"><a class="markdownIt-Anchor" href="#grpc"></a> gRPC</h2>
<ul>
<li>gRPC是由Google公司开源的高性能RPC框架。</li>
<li>gRPC支持多语言<br>
gRPC原生使用C、Java、Go进行了三种实现，而C语言实现的版本进行封装后又支持C++、C#、Node、ObjC、 Python、Ruby、PHP等开发语言</li>
<li>gRPC支持多平台<br>
支持的平台包括：Linux、Android、iOS、MacOS、Windows</li>
<li>gRPC的消息协议使用Google自家开源的Protocol Buffers协议机制（proto3） 序列化</li>
<li>gRPC的传输使用HTTP/2标准，支持双向流和连接多路复用</li>
</ul>
<h3 id="创建user_recoproto协议文件"><a class="markdownIt-Anchor" href="#创建user_recoproto协议文件"></a> 创建user_reco.proto协议文件</h3>
<ul>
<li>用户刷新feed流接口
<ul>
<li>user_recommend(User) returns (Track)</li>
</ul>
</li>
<li>文章相似(猜你喜欢)接口
<ul>
<li>article_recommend(Article) returns(Similar)</li>
</ul>
</li>
</ul>
<p>编写grpc_tools.protoc</p>
<pre class="highlight"><code class="shell">syntax = "proto3";

message User {

    string user_id = 1;
    int32 channel_id = 2;
    int32 article_num = 3;
    int64 time_stamp = 4;
}
// int32 ---&gt; int64 article_id
message Article {

    int64 article_id = 1;
    int32 article_num = 2;

}

message param2 {
    string click = 1;
    string collect = 2;
    string share = 3;
    string read = 4;
}

message param1 {
    int64 article_id = 1;
    param2 params = 2;
}

message Track {
    string exposure = 1;
    repeated param1 recommends = 2;
    int64 time_stamp = 3;
}

message Similar {
    repeated int64 article_id = 1;
}

service UserRecommend {
    // feed recommend
    rpc user_recommend(User) returns (Track) {}
    rpc article_recommend(Article) returns(Similar) {}
}
</code></pre>
<p>通过命令生成</p>
<pre class="highlight"><code class="shell">python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. user_reco.proto
</code></pre>
<h3 id="服务端编写"><a class="markdownIt-Anchor" href="#服务端编写"></a> 服务端编写</h3>
<pre class="highlight"><code class="python"><span class="hljs-comment"># route.py</span>
<span class="hljs-comment"># 基于用户推荐的rpc服务推荐</span>
<span class="hljs-comment"># 定义指定的rpc服务输入输出参数格式proto</span>
RPC_SERVER = <span class="hljs-string">'192.168.19.137:9999'</span>
<span class="hljs-keyword">class</span> <span class="hljs-title class_">UserRecommendServicer</span>(user_reco_pb2_grpc.UserRecommendServicer):
    <span class="hljs-string">"""
    对用户进行技术文章推荐
    """</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">user_recommend</span>(<span class="hljs-params">self, request, context</span>):
        <span class="hljs-string">"""
        用户feed流推荐
        :param request:
        :param context:
        :return:
        """</span>
        <span class="hljs-comment"># 选择C4组合</span>
        user_id = request.user_id
        channel_id = request.channel_id
        article_num = request.article_num
        time_stamp = request.time_stamp

        <span class="hljs-comment"># 解析参数，并进行推荐中心推荐(暂时使用假数据替代)</span>
        <span class="hljs-keyword">class</span> <span class="hljs-title class_">Temp</span>(<span class="hljs-title class_ inherited__">object</span>):
            user_id = -<span class="hljs-number">10</span>
            algo = <span class="hljs-string">'test'</span>
            time_stamp = -<span class="hljs-number">10</span>

        tp = Temp()
        tp.user_id = user_id
        tp.time_stamp = time_stamp
        _track = add_track([], tp)

        <span class="hljs-comment"># 解析返回参数到rpc结果参数</span>
        <span class="hljs-comment"># 参数如下</span>
        <span class="hljs-comment"># [       {"article_id": 1, "param": {"click": "", "collect": "", "share": "", 'detentionTime':''}},</span>
        <span class="hljs-comment">#         {"article_id": 2, "param": {"click": "", "collect": "", "share": "", 'detentionTime':''}},</span>
        <span class="hljs-comment">#         {"article_id": 3, "param": {"click": "", "collect": "", "share": "", 'detentionTime':''}},</span>
        <span class="hljs-comment">#         {"article_id": 4, "param": {"click": "", "collect": "", "share": "", 'detentionTime':''}}</span>
        <span class="hljs-comment">#     ]</span>
        <span class="hljs-comment"># 第二个rpc参数</span>
        _param1 = []
        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> _track[<span class="hljs-string">'recommends'</span>]:
            <span class="hljs-comment"># param的封装</span>
            _params = user_reco_pb2.param2(click=_[<span class="hljs-string">'param'</span>][<span class="hljs-string">'click'</span>],
                                           collect=_[<span class="hljs-string">'param'</span>][<span class="hljs-string">'collect'</span>],
                                           share=_[<span class="hljs-string">'param'</span>][<span class="hljs-string">'share'</span>],
                                           read=_[<span class="hljs-string">'param'</span>][<span class="hljs-string">'read'</span>])
            _p2 = user_reco_pb2.param1(article_id=_[<span class="hljs-string">'article_id'</span>], params=_params)
            _param1.append(_p2)
        <span class="hljs-comment"># param</span>
        <span class="hljs-keyword">return</span> user_reco_pb2.Track(exposure=_track[<span class="hljs-string">'param'</span>], recommends=_param1, time_stamp=_track[<span class="hljs-string">'timestamp'</span>])

<span class="hljs-comment">#    def article_recommend(self, request, context):</span>
<span class="hljs-comment">#        """</span>
<span class="hljs-comment">#       文章相似推荐</span>
<span class="hljs-comment">#       :param request:</span>
<span class="hljs-comment">#       :param context:</span>
<span class="hljs-comment">#       :return:</span>
<span class="hljs-comment">#       """</span>
<span class="hljs-comment">#       # 获取web参数</span>
<span class="hljs-comment">#       article_id = request.article_id</span>
<span class="hljs-comment">#       article_num = request.article_num</span>
<span class="hljs-comment">#</span>
<span class="hljs-comment">#        # 进行文章相似推荐,调用推荐中心的文章相似</span>
<span class="hljs-comment">#       _article_list = article_reco_list(article_id, article_num, 105)</span>
<span class="hljs-comment">#</span>
<span class="hljs-comment">#       # rpc参数封装</span>
<span class="hljs-comment">#       return user_reco_pb2.Similar(article_id=_article_list)</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">add_track</span>(<span class="hljs-params">res, temp</span>):
    <span class="hljs-string">"""
    封装埋点参数
    :param res: 推荐文章id列表
    :param cb: 合并参数
    :param rpc_param: rpc参数
    :return: 埋点参数
        文章列表参数
        单文章参数
    """</span>
    <span class="hljs-comment"># 添加埋点参数</span>
    track = {}

    <span class="hljs-comment"># 准备曝光参数</span>
    <span class="hljs-comment"># 全部字符串形式提供，在hive端不会解析问题</span>
    _exposure = {<span class="hljs-string">"action"</span>: <span class="hljs-string">"exposure"</span>, <span class="hljs-string">"userId"</span>: temp.user_id, <span class="hljs-string">"articleId"</span>: json.dumps(res),
                 <span class="hljs-string">"algorithmCombine"</span>: temp.algo}

    track[<span class="hljs-string">'param'</span>] = json.dumps(_exposure)
    track[<span class="hljs-string">'recommends'</span>] = []

    <span class="hljs-comment"># 准备其它点击参数</span>
    <span class="hljs-keyword">for</span> _<span class="hljs-built_in">id</span> <span class="hljs-keyword">in</span> res:
        <span class="hljs-comment"># 构造字典</span>
        _dic = {}
        _dic[<span class="hljs-string">'article_id'</span>] = _<span class="hljs-built_in">id</span>
        _dic[<span class="hljs-string">'param'</span>] = {}

        <span class="hljs-comment"># 准备click参数</span>
        _p = {<span class="hljs-string">"action"</span>: <span class="hljs-string">"click"</span>, <span class="hljs-string">"userId"</span>: temp.user_id, <span class="hljs-string">"articleId"</span>: <span class="hljs-built_in">str</span>(_<span class="hljs-built_in">id</span>),
              <span class="hljs-string">"algorithmCombine"</span>: temp.algo}

        _dic[<span class="hljs-string">'param'</span>][<span class="hljs-string">'click'</span>] = json.dumps(_p)
        <span class="hljs-comment"># 准备collect参数</span>
        _p[<span class="hljs-string">"action"</span>] = <span class="hljs-string">'collect'</span>
        _dic[<span class="hljs-string">'param'</span>][<span class="hljs-string">'collect'</span>] = json.dumps(_p)
        <span class="hljs-comment"># 准备share参数</span>
        _p[<span class="hljs-string">"action"</span>] = <span class="hljs-string">'share'</span>
        _dic[<span class="hljs-string">'param'</span>][<span class="hljs-string">'share'</span>] = json.dumps(_p)
        <span class="hljs-comment"># 准备detentionTime参数</span>
        _p[<span class="hljs-string">"action"</span>] = <span class="hljs-string">'read'</span>
        _dic[<span class="hljs-string">'param'</span>][<span class="hljs-string">'read'</span>] = json.dumps(_p)

        track[<span class="hljs-string">'recommends'</span>].append(_dic)

    track[<span class="hljs-string">'timestamp'</span>] = temp.time_stamp
    <span class="hljs-keyword">return</span> track


<span class="hljs-keyword">def</span> <span class="hljs-title function_">serve</span>():

    <span class="hljs-comment"># 多线程服务器</span>
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=<span class="hljs-number">10</span>))
    <span class="hljs-comment"># 注册本地服务</span>
    user_reco_pb2_grpc.add_UserRecommendServicer_to_server(UserRecommendServicer(), server)
    <span class="hljs-comment"># 监听端口</span>
    server.add_insecure_port(DefaultConfig.RPC_SERVER)

    <span class="hljs-comment"># 开始接收请求进行服务</span>
    server.start()
    <span class="hljs-comment"># 使用 ctrl+c 可以退出服务</span>
    _ONE_DAY_IN_SECONDS = <span class="hljs-number">60</span> * <span class="hljs-number">60</span> * <span class="hljs-number">24</span>
    <span class="hljs-keyword">try</span>:
        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:
            time.sleep(_ONE_DAY_IN_SECONDS)
    <span class="hljs-keyword">except</span> KeyboardInterrupt:
        server.stop(<span class="hljs-number">0</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    <span class="hljs-comment"># 测试grpc服务</span>
    serve()
</code></pre>
<p>客户端测试代码：</p>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> sys

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(<span class="hljs-number">0</span>, os.path.join(BASE_DIR))
<span class="hljs-keyword">from</span> abtest <span class="hljs-keyword">import</span> user_reco_pb2_grpc
<span class="hljs-keyword">from</span> abtest <span class="hljs-keyword">import</span> user_reco_pb2
<span class="hljs-keyword">import</span> grpc
<span class="hljs-keyword">from</span> setting.default <span class="hljs-keyword">import</span> DefaultConfig
<span class="hljs-keyword">import</span> time


<span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():
    article_dict = {}
    <span class="hljs-comment"># 构造传入数据</span>

    req_article = user_reco_pb2.User()
    req_article.user_id = <span class="hljs-string">'1115629498121846784'</span>
    req_article.channel_id = <span class="hljs-number">18</span>
    req_article.article_num = <span class="hljs-number">10</span>
    req_article.time_stamp = <span class="hljs-built_in">int</span>(time.time() * <span class="hljs-number">1000</span>)
    <span class="hljs-comment"># req_article.time_stamp = 1555573069870</span>

    <span class="hljs-keyword">with</span> grpc.insecure_channel(DefaultConfig.RPC_SERVER) <span class="hljs-keyword">as</span> rpc_cli:
        <span class="hljs-built_in">print</span>(<span class="hljs-string">''''''</span>)
        <span class="hljs-keyword">try</span>:
            stub = user_reco_pb2_grpc.UserRecommendStub(rpc_cli)
            resp = stub.user_recommend(req_article)
        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
            <span class="hljs-built_in">print</span>(e)
            article_dict[<span class="hljs-string">'param'</span>] = []
        <span class="hljs-keyword">else</span>:

            <span class="hljs-comment"># 解析返回结果参数</span>
            article_dict[<span class="hljs-string">'exposure_param'</span>] = resp.exposure

            reco_arts = resp.recommends

            reco_art_param = []
            reco_list = []
            <span class="hljs-keyword">for</span> art <span class="hljs-keyword">in</span> reco_arts:
                reco_art_param.append({
                    <span class="hljs-string">'artcle_id'</span>: art.article_id,
                    <span class="hljs-string">'params'</span>: {
                        <span class="hljs-string">'click'</span>: art.params.click,
                        <span class="hljs-string">'collect'</span>: art.params.collect,
                        <span class="hljs-string">'share'</span>: art.params.share,
                        <span class="hljs-string">'read'</span>: art.params.read
                    }
                })

                reco_list.append(art.article_id)
            article_dict[<span class="hljs-string">'param'</span>] = reco_art_param

            <span class="hljs-comment"># 文章列表以及参数（曝光参数 以及 每篇文章的点击等参数）</span>
            <span class="hljs-built_in">print</span>(reco_list, article_dict)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    test()
</code></pre>
<h2 id="通过哈希分桶进行流量切分"><a class="markdownIt-Anchor" href="#通过哈希分桶进行流量切分"></a> 通过哈希分桶进行流量切分</h2>
<pre class="highlight"><code class="python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">feed_recommend</span>(<span class="hljs-params">user_id, channel_id, article_num, time_stamp</span>):
    <span class="hljs-string">"""
    1、根据web提供的参数，进行分流
    2、找到对应的算法组合之后，去推荐中心调用不同的召回和排序服务
    3、进行埋点参数封装
    :param user_id:用户id
    :param article_num:推荐文章个数
    :return: track:埋点参数结果: 参考上面埋点参数组合
    """</span>

    <span class="hljs-comment">#  产品前期推荐由于较少的点击行为，所以去做 用户冷启动 + 文章冷启动</span>
    <span class="hljs-comment"># 用户冷启动：'推荐'频道：热门频道的召回+用户实时行为画像召回（在线的不保存画像）  'C2'组合</span>
    <span class="hljs-comment">#            # 其它频道：热门召回 + 新文章召回   'C1'组合</span>
    <span class="hljs-comment"># 定义返回参数的类</span>
    <span class="hljs-keyword">class</span> <span class="hljs-title class_">TempParam</span>(<span class="hljs-title class_ inherited__">object</span>):
        user_id = -<span class="hljs-number">10</span>
        channel_id = -<span class="hljs-number">10</span>
        article_num = -<span class="hljs-number">10</span>
        time_stamp = -<span class="hljs-number">10</span>
        algo = <span class="hljs-string">""</span>

    temp = TempParam()
    temp.user_id = user_id
    temp.channel_id = channel_id
    temp.article_num = article_num
    <span class="hljs-comment"># 请求的时间戳大小</span>
    temp.time_stamp = time_stamp

    <span class="hljs-comment"># 先读取缓存数据redis+待推荐hbase结果</span>
    <span class="hljs-comment"># 如果有返回并加上埋点参数</span>
    <span class="hljs-comment"># 并且写入hbase 当前推荐时间戳用户（登录和匿名）的历史推荐文章列表</span>

    <span class="hljs-comment"># 传入用户id为空的直接召回结果</span>
    <span class="hljs-keyword">if</span> temp.user_id == <span class="hljs-string">""</span>:
        temp.algo = <span class="hljs-string">""</span>
        <span class="hljs-keyword">return</span> add_track([], temp)
    <span class="hljs-comment"># 进行分桶实现分流，制定不同的实验策略</span>
    bucket = hashlib.md5(user_id.encode()).hexdigest()[:<span class="hljs-number">1</span>]
    <span class="hljs-keyword">if</span> bucket <span class="hljs-keyword">in</span> RAParam.BYPASS[<span class="hljs-number">0</span>][<span class="hljs-string">'Bucket'</span>]:
        temp.algo = RAParam.BYPASS[<span class="hljs-number">0</span>][<span class="hljs-string">'Strategy'</span>]
    <span class="hljs-keyword">else</span>:
        temp.algo = RAParam.BYPASS[<span class="hljs-number">1</span>][<span class="hljs-string">'Strategy'</span>]

    <span class="hljs-comment"># 推荐服务中心推荐结果(这里做测试)</span>
    track = add_track([], temp)

    <span class="hljs-keyword">return</span> track
</code></pre>
<h2 id="推荐服务中心"><a class="markdownIt-Anchor" href="#推荐服务中心"></a> 推荐服务中心</h2>
<ul>
<li>根据时间戳
<ul>
<li>时间戳T小于HBASE历史推荐记录，则获取历史记录，返回该时间戳T上次的时间戳T-1</li>
<li>时间戳T大于HBASE历史推荐记录，则获取新推荐，则获取HBASE数据库中最近的一次时间戳
<ul>
<li>如果有缓存，从缓存中拿，并且写入推荐历史表中</li>
<li>如果没有缓存，就进行一次指定算法组合的召回结果读取，排序，然后写入待推荐wait_recommend中，其中推荐出去的放入历史推荐表中</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="推荐中心业务逻辑"><a class="markdownIt-Anchor" href="#推荐中心业务逻辑"></a> 推荐中心业务逻辑</h3>
<pre class="highlight"><code class="python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">feed_recommend_logic</span>(<span class="hljs-params">self, temp</span>):
	<span class="hljs-string">"""推荐流业务逻辑
	:param temp:ABTest传入的业务请求参数
	"""</span>

	<span class="hljs-comment"># 判断用请求的时间戳大小决定获取历史记录还是刷新推荐文章</span>
	<span class="hljs-keyword">try</span>:
		last_stamp = self.hbu.get_table_row(<span class="hljs-string">'history_recommend'</span>, <span class="hljs-string">'reco:his:{}'</span>.<span class="hljs-built_in">format</span>(temp.user_id).encode(),
											<span class="hljs-string">'channel:{}'</span>.<span class="hljs-built_in">format</span>(temp.channel_id).encode(), include_timestamp=<span class="hljs-literal">True</span>)[<span class="hljs-number">1</span>]
		logger.info(<span class="hljs-string">"{} INFO get user_id:{} channel:{} history last_stamp"</span>.<span class="hljs-built_in">format</span>(
			datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), temp.user_id, temp.channel_id))
	<span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
		logger.warning(<span class="hljs-string">"{} WARN read history recommend exception:{}"</span>.<span class="hljs-built_in">format</span>(
			datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), e))
		last_stamp = <span class="hljs-number">0</span>

	<span class="hljs-comment"># 如果小于，走一遍正常的推荐流程，缓存或者召回排序</span>
	logger.info(<span class="hljs-string">"{} INFO history last_stamp:{},temp.time_stamp:{}"</span>.
				<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), last_stamp, temp.time_stamp))
	<span class="hljs-keyword">if</span> last_stamp &lt; temp.time_stamp:

		<span class="hljs-comment"># 获取</span>
		res = redis_cache.get_reco_from_cache(temp, self.hbu)

		<span class="hljs-comment"># 如果没有，然后走一遍算法推荐 召回+排序，同时写入到hbase待推荐结果列表</span>
		<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> res:
			logger.info(<span class="hljs-string">"{} INFO get user_id:{} channel:{} recall/sort data"</span>.
						<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), temp.user_id, temp.channel_id))

			res = self.user_reco_list(temp)

		temp.time_stamp = <span class="hljs-built_in">int</span>(last_stamp)

		track = add_track(res, temp)

	<span class="hljs-keyword">else</span>:

		logger.info(<span class="hljs-string">"{} INFO read user_id:{} channel:{} history recommend data"</span>.<span class="hljs-built_in">format</span>(
			datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), temp.user_id, temp.channel_id))

		<span class="hljs-keyword">try</span>:
			row = self.hbu.get_table_cells(<span class="hljs-string">'history_recommend'</span>,
									  <span class="hljs-string">'reco:his:{}'</span>.<span class="hljs-built_in">format</span>(temp.user_id).encode(),
									  <span class="hljs-string">'channel:{}'</span>.<span class="hljs-built_in">format</span>(temp.channel_id).encode(),
									  timestamp=temp.time_stamp + <span class="hljs-number">1</span>,
									  include_timestamp=<span class="hljs-literal">True</span>)
		<span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
			logger.warning(<span class="hljs-string">"{} WARN read history recommend exception:{}"</span>.<span class="hljs-built_in">format</span>(
				datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), e))
			row = []
			res = []

		<span class="hljs-comment"># 1、如果没有历史数据，返回时间戳0以及结果空列表</span>
		<span class="hljs-comment"># 2、如果历史数据只有一条，返回这一条历史数据以及时间戳正好为请求时间戳，修改时间戳为0</span>
		<span class="hljs-comment"># 3、如果历史数据多条，返回最近一条历史数据，然后返回</span>
		<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> row:
			temp.time_stamp = <span class="hljs-number">0</span>
			res = []
		<span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(row) == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> row[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>] == temp.time_stamp:
			res = <span class="hljs-built_in">eval</span>(row[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])
			temp.time_stamp = <span class="hljs-number">0</span>
		<span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(row) &gt;= <span class="hljs-number">2</span>:
			res = <span class="hljs-built_in">eval</span>(row[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])
			temp.time_stamp = <span class="hljs-built_in">int</span>(row[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>])

		res = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, res))
		logger.info(
			<span class="hljs-string">"{} INFO history:{}, {}"</span>.<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), res, temp.time_stamp))
		track = add_track(res, temp)
		<span class="hljs-comment"># 曝光参数设置为空</span>
		track[<span class="hljs-string">'param'</span>] = <span class="hljs-string">''</span>
	<span class="hljs-keyword">return</span> track
</code></pre>
<h3 id="获取用户召回结果"><a class="markdownIt-Anchor" href="#获取用户召回结果"></a> 获取用户召回结果</h3>
<pre class="highlight"><code class="python">  <span class="hljs-keyword">def</span> <span class="hljs-title function_">user_reco_list</span>(<span class="hljs-params">self, temp</span>):
        <span class="hljs-string">"""
        获取用户的召回结果进行推荐
        :param temp:
        :return:
        """</span>
        reco_set = []
        <span class="hljs-comment"># 1、循环算法组合参数，遍历不同召回结果进行过滤</span>
        <span class="hljs-keyword">for</span> _num <span class="hljs-keyword">in</span> RAParam.COMBINE[temp.algo][<span class="hljs-number">1</span>]:
            <span class="hljs-comment"># 进行每个召回结果的读取100,101,102,103,104</span>
            <span class="hljs-keyword">if</span> _num == <span class="hljs-number">103</span>:
                <span class="hljs-comment"># 新文章召回读取</span>
                _res = self.recall_service.read_redis_new_article(temp.channel_id)
                reco_set = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(reco_set).union(<span class="hljs-built_in">set</span>(_res)))
            <span class="hljs-keyword">elif</span> _num == <span class="hljs-number">104</span>:
                <span class="hljs-comment"># 热门文章召回读取</span>
                _res = self.recall_service.read_redis_hot_article(temp.channel_id)
                reco_set = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(reco_set).union(<span class="hljs-built_in">set</span>(_res)))
            <span class="hljs-keyword">else</span>:
                _res = self.recall_service.\
                    read_hbase_recall_data(RAParam.RECALL[_num][<span class="hljs-number">0</span>],
                                           <span class="hljs-string">'recall:user:{}'</span>.<span class="hljs-built_in">format</span>(temp.user_id).encode(),
                                           <span class="hljs-string">'{}:{}'</span>.<span class="hljs-built_in">format</span>(RAParam.RECALL[_num][<span class="hljs-number">1</span>], temp.channel_id).encode())
                <span class="hljs-comment"># 进行合并某个协同过滤召回的结果</span>
                reco_set = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(reco_set).union(<span class="hljs-built_in">set</span>(_res)))

        <span class="hljs-comment"># reco_set都是新推荐的结果，进行过滤</span>
        history_list = []
        <span class="hljs-keyword">try</span>:
            data = self.hbu.get_table_cells(<span class="hljs-string">'history_recommend'</span>,
                                            <span class="hljs-string">'reco:his:{}'</span>.<span class="hljs-built_in">format</span>(temp.user_id).encode(),
                                            <span class="hljs-string">'channel:{}'</span>.<span class="hljs-built_in">format</span>(temp.channel_id).encode())
            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> data:
                history_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(history_list).union(<span class="hljs-built_in">set</span>(<span class="hljs-built_in">eval</span>(_))))

            logger.info(<span class="hljs-string">"{} INFO filter user_id:{} channel:{} history data"</span>.<span class="hljs-built_in">format</span>(
                datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), temp.user_id, temp.channel_id))
        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
            logger.warning(
                <span class="hljs-string">"{} WARN filter history article exception:{}"</span>.<span class="hljs-built_in">format</span>(datetime.now().
                                                                     strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), e))

        <span class="hljs-comment"># 如果0号频道有历史记录，也需要过滤</span>

        <span class="hljs-keyword">try</span>:
            data = self.hbu.get_table_cells(<span class="hljs-string">'history_recommend'</span>,
                                            <span class="hljs-string">'reco:his:{}'</span>.<span class="hljs-built_in">format</span>(temp.user_id).encode(),
                                            <span class="hljs-string">'channel:{}'</span>.<span class="hljs-built_in">format</span>(<span class="hljs-number">0</span>).encode())
            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> data:
                history_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(history_list).union(<span class="hljs-built_in">set</span>(<span class="hljs-built_in">eval</span>(_))))

            logger.info(<span class="hljs-string">"{} INFO filter user_id:{} channel:{} history data"</span>.<span class="hljs-built_in">format</span>(
                datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), temp.user_id, <span class="hljs-number">0</span>))
        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
            logger.warning(
                <span class="hljs-string">"{} WARN filter history article exception:{}"</span>.<span class="hljs-built_in">format</span>(datetime.now().
                                                                     strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), e))

        <span class="hljs-comment"># 过滤操作 reco_set 与history_list进行过滤</span>
        reco_set = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(reco_set).difference(<span class="hljs-built_in">set</span>(history_list)))

        <span class="hljs-comment"># 排序代码逻辑</span>
        <span class="hljs-comment"># _sort_num = RAParam.COMBINE[temp.algo][2][0]</span>
        <span class="hljs-comment"># reco_set = sort_dict[RAParam.SORT[_sort_num]](reco_set, temp, self.hbu)</span>

        <span class="hljs-comment"># 如果没有内容，直接返回</span>
        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> reco_set:
            <span class="hljs-keyword">return</span> reco_set
        <span class="hljs-keyword">else</span>:

            <span class="hljs-comment"># 类型进行转换</span>
            reco_set = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, reco_set))

            <span class="hljs-comment"># 跟后端需要推荐的文章数量进行比对 article_num</span>
            <span class="hljs-comment"># article_num &gt; reco_set</span>
            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(reco_set) &lt;= temp.article_num:
                res = reco_set
            <span class="hljs-keyword">else</span>:
                <span class="hljs-comment"># 之取出推荐出去的内容</span>
                res = reco_set[:temp.article_num]
                <span class="hljs-comment"># 剩下的推荐结果放入wait_recommend等待下次帅新的时候直接推荐</span>
                self.hbu.get_table_put(<span class="hljs-string">'wait_recommend'</span>,
                                       <span class="hljs-string">'reco:{}'</span>.<span class="hljs-built_in">format</span>(temp.user_id).encode(),
                                       <span class="hljs-string">'channel:{}'</span>.<span class="hljs-built_in">format</span>(temp.channel_id).encode(),
                                       <span class="hljs-built_in">str</span>(reco_set[temp.article_num:]).encode(),
                                       timestamp=temp.time_stamp)
                logger.info(
                    <span class="hljs-string">"{} INFO put user_id:{} channel:{} wait data"</span>.<span class="hljs-built_in">format</span>(
                        datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), temp.user_id, temp.channel_id))

            <span class="hljs-comment"># 放入历史记录表当中</span>
            self.hbu.get_table_put(<span class="hljs-string">'history_recommend'</span>,
                                   <span class="hljs-string">'reco:his:{}'</span>.<span class="hljs-built_in">format</span>(temp.user_id).encode(),
                                   <span class="hljs-string">'channel:{}'</span>.<span class="hljs-built_in">format</span>(temp.channel_id).encode(),
                                   <span class="hljs-built_in">str</span>(res).encode(),
                                   timestamp=temp.time_stamp)
            <span class="hljs-comment"># 放入历史记录日志</span>
            logger.info(
                <span class="hljs-string">"{} INFO store recall/sorted user_id:{} channel:{} history_recommend data"</span>.<span class="hljs-built_in">format</span>(
                    datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), temp.user_id, temp.channel_id))

            <span class="hljs-keyword">return</span> res
</code></pre>
<h3 id="在线预测"><a class="markdownIt-Anchor" href="#在线预测"></a> 在线预测</h3>
<p>除了对召回集进行排序以外，还可以在在线平台上使用离线训练好的点击率模型，得到高点击召回集。</p>
<pre class="highlight"><code class="python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">lr_sort_service</span>(<span class="hljs-params">reco_set, temp, hbu</span>):
    <span class="hljs-string">"""
    排序返回推荐文章
    :param reco_set:召回合并过滤后的结果
    :param temp: 参数
    :param hbu: Hbase工具
    :return:
    """</span>
    <span class="hljs-comment"># 排序</span>
    <span class="hljs-comment"># 1、读取用户特征中心特征</span>
    <span class="hljs-keyword">try</span>:
        user_feature = <span class="hljs-built_in">eval</span>(hbu.get_table_row(<span class="hljs-string">'ctr_feature_user'</span>,
                                              <span class="hljs-string">'{}'</span>.<span class="hljs-built_in">format</span>(temp.user_id).encode(),
                                              <span class="hljs-string">'channel:{}'</span>.<span class="hljs-built_in">format</span>(temp.channel_id).encode()))
        logger.info(<span class="hljs-string">"{} INFO get user user_id:{} channel:{} profile data"</span>.<span class="hljs-built_in">format</span>(
            datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), temp.user_id, temp.channel_id))
    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
        user_feature = []

    <span class="hljs-keyword">if</span> user_feature:
        <span class="hljs-comment"># 2、读取文章特征中心特征</span>
        result = []

        <span class="hljs-keyword">for</span> article_id <span class="hljs-keyword">in</span> reco_set:
            <span class="hljs-keyword">try</span>:
                article_feature = <span class="hljs-built_in">eval</span>(hbu.get_table_row(<span class="hljs-string">'ctr_feature_article'</span>,
                                                         <span class="hljs-string">'{}'</span>.<span class="hljs-built_in">format</span>(article_id).encode(),
                                                         <span class="hljs-string">'article:{}'</span>.<span class="hljs-built_in">format</span>(article_id).encode()))
            <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:

                article_feature = [<span class="hljs-number">0.0</span>] * <span class="hljs-number">111</span>
            f = []
            <span class="hljs-comment"># 第一个channel_id</span>
            f.extend([article_feature[<span class="hljs-number">0</span>]])
            <span class="hljs-comment"># 第二个article_vector</span>
            f.extend(article_feature[<span class="hljs-number">11</span>:])
            <span class="hljs-comment"># 第三个用户权重特征</span>
            f.extend(user_feature)
            <span class="hljs-comment"># 第四个文章权重特征</span>
            f.extend(article_feature[<span class="hljs-number">1</span>:<span class="hljs-number">11</span>])
            vector = DenseVector(f)
            result.append([temp.user_id, article_id, vector])

        <span class="hljs-comment"># 4、预测并进行排序是筛选</span>
        df = pd.DataFrame(result, columns=[<span class="hljs-string">"user_id"</span>, <span class="hljs-string">"article_id"</span>, <span class="hljs-string">"features"</span>])
        test = SORT_SPARK.createDataFrame(df)

        <span class="hljs-comment"># 加载逻辑回归模型</span>
        model = LogisticRegressionModel.load(<span class="hljs-string">"hdfs://hadoop-master:9000/headlines/models/LR.obj"</span>)
        predict = model.transform(test)

        <span class="hljs-keyword">def</span> <span class="hljs-title function_">vector_to_double</span>(<span class="hljs-params">row</span>):
            <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(row.article_id), <span class="hljs-built_in">float</span>(row.probability[<span class="hljs-number">1</span>])

        res = predict.select([<span class="hljs-string">'article_id'</span>, <span class="hljs-string">'probability'</span>]).rdd.<span class="hljs-built_in">map</span>(vector_to_double).toDF(
            [<span class="hljs-string">'article_id'</span>, <span class="hljs-string">'probability'</span>]).sort(<span class="hljs-string">'probability'</span>, ascending=<span class="hljs-literal">False</span>)
        article_list = [i.article_id <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> res.collect()]
        logger.info(<span class="hljs-string">"{} INFO sorting user_id:{} recommend article"</span>.<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>),
                                                                          temp.user_id))
        <span class="hljs-comment"># 排序后，只将排名在前100个文章ID返回给用户推荐</span>
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(article_list) &gt; <span class="hljs-number">100</span>:
            article_list = article_list[:<span class="hljs-number">100</span>]
        reco_set = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, article_list))

    <span class="hljs-keyword">return</span> reco_set
</code></pre>
<h3 id="多路召回"><a class="markdownIt-Anchor" href="#多路召回"></a> 多路召回</h3>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> sys
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(<span class="hljs-number">0</span>, os.path.join(BASE_DIR))

<span class="hljs-keyword">from</span> server <span class="hljs-keyword">import</span> redis_client
<span class="hljs-keyword">from</span> server <span class="hljs-keyword">import</span> pool
<span class="hljs-keyword">import</span> logging
<span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime
<span class="hljs-keyword">from</span> abtest.utils <span class="hljs-keyword">import</span> HBaseUtils

logger = logging.getLogger(<span class="hljs-string">'recommend'</span>)


<span class="hljs-keyword">class</span> <span class="hljs-title class_">ReadRecall</span>(<span class="hljs-title class_ inherited__">object</span>):
    <span class="hljs-string">"""读取召回集的结果
    """</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
        self.client = redis_client
        self.hbu = HBaseUtils(pool)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">read_hbase_recall_data</span>(<span class="hljs-params">self, table_name, key_format, column_format</span>):
        <span class="hljs-string">"""获取指定用户的对应频道的召回结果,在线画像召回，离线画像召回，离线协同召回
        :return:
        """</span>
        <span class="hljs-comment"># 获取family对应的值</span>
        <span class="hljs-comment"># 数据库中的键都是bytes类型，所以需要进行编码相加</span>
        <span class="hljs-comment"># 读取召回结果多个版本合并</span>
        recall_list = []
        <span class="hljs-keyword">try</span>:

            data = self.hbu.get_table_cells(table_name, key_format, column_format)
            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> data:
                recall_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(recall_list).union(<span class="hljs-built_in">set</span>(<span class="hljs-built_in">eval</span>(_))))

            <span class="hljs-comment"># 读取所有这个用户的在线推荐的版本，清空该频道的数据</span>
            <span class="hljs-comment"># self.hbu.get_table_delete(table_name, key_format, column_format)</span>
        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
            logger.warning(
                <span class="hljs-string">"{} WARN read recall data exception:{}"</span>.<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), e))
        <span class="hljs-keyword">return</span> recall_list

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">read_redis_new_data</span>(<span class="hljs-params">self, channel_id</span>):
        <span class="hljs-string">"""获取redis新文章结果
        :param channel_id:
        :return:
        """</span>
        <span class="hljs-comment"># format结果</span>
        logger.info(<span class="hljs-string">"{} INFO read channel:{} new recommend data"</span>.<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), channel_id))
        _key = <span class="hljs-string">"ch:{}:new"</span>.<span class="hljs-built_in">format</span>(channel_id)
        <span class="hljs-keyword">try</span>:
            res = self.client.zrevrange(_key, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>)
        <span class="hljs-keyword">except</span> redis.exceptions.ResponseError <span class="hljs-keyword">as</span> e:
            logger.warning(<span class="hljs-string">"{} WARN read new article exception:{}"</span>.<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), e))
            res = []
        <span class="hljs-keyword">return</span> <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, res))

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">read_redis_hot_data</span>(<span class="hljs-params">self, channel_id</span>):
        <span class="hljs-string">"""获取redis热门文章结果
        :param channel_id:
        :return:
        """</span>
        <span class="hljs-comment"># format结果</span>
        logger.info(<span class="hljs-string">"{} INFO read channel:{} hot recommend data"</span>.<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), channel_id))
        _key = <span class="hljs-string">"ch:{}:hot"</span>.<span class="hljs-built_in">format</span>(channel_id)
        <span class="hljs-keyword">try</span>:
            _res = self.client.zrevrange(_key, <span class="hljs-number">0</span>, -<span class="hljs-number">1</span>)
        <span class="hljs-keyword">except</span> redis.exceptions.ResponseError <span class="hljs-keyword">as</span> e:
            logger.warning(<span class="hljs-string">"{} WARN read hot article exception:{}"</span>.<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), e))
            _res = []
        <span class="hljs-comment"># 每次返回前50热门文章</span>
        res = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">int</span>, _res))
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(res) &gt; <span class="hljs-number">50</span>:
            res = res[:<span class="hljs-number">50</span>]
        <span class="hljs-keyword">return</span> res

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">read_hbase_article_similar</span>(<span class="hljs-params">self, table_name, key_format, article_num</span>):
        <span class="hljs-string">"""获取文章相似结果
        :param article_id: 文章id
        :param article_num: 文章数量
        :return:
        """</span>
        <span class="hljs-comment"># 第一种表结构方式测试：</span>
        <span class="hljs-comment"># create 'article_similar', 'similar'</span>
        <span class="hljs-comment"># put 'article_similar', '1', 'similar:1', 0.2</span>
        <span class="hljs-comment"># put 'article_similar', '1', 'similar:2', 0.34</span>
        <span class="hljs-keyword">try</span>:
            _dic = self.hbu.get_table_row(table_name, key_format)

            res = []
            _srt = <span class="hljs-built_in">sorted</span>(_dic.items(), key=<span class="hljs-keyword">lambda</span> obj: obj[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)
            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(_srt) &gt; article_num:
                _srt = _srt[:article_num]
            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> _srt:
                res.append(<span class="hljs-built_in">int</span>(_[<span class="hljs-number">0</span>].decode().split(<span class="hljs-string">':'</span>)[<span class="hljs-number">1</span>]))
        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
            logger.error(<span class="hljs-string">"{} ERROR read similar article exception: {}"</span>.<span class="hljs-built_in">format</span>(datetime.now().strftime(<span class="hljs-string">'%Y-%m-%d %H:%M:%S'</span>), e))
            res = []
        <span class="hljs-keyword">return</span> res


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:

    rr = ReadRecall()
    <span class="hljs-built_in">print</span>(rr.read_hbase_article_similar(<span class="hljs-string">'article_similar'</span>, <span class="hljs-string">b'13342'</span>, <span class="hljs-number">10</span>))
    <span class="hljs-built_in">print</span>(rr.read_hbase_recall_data(<span class="hljs-string">'cb_recall'</span>, <span class="hljs-string">b'recall:user:1115629498121846784'</span>, <span class="hljs-string">b'als:18'</span>))

    <span class="hljs-comment"># rr = ReadRecall()</span>
    <span class="hljs-comment"># print(rr.read_redis_new_data(18))</span>
</code></pre>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/2023/02/13/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A5%E9%97%A8/" title="数据库入门"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">Previous: 数据库入门</span></a><a class="button is-default" href="/2023/02/13/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A1%86%E6%9E%B6%E7%AE%80%E4%BB%8B/" title="大数据框架简介"><span class="has-text-weight-semibold">Next: 大数据框架简介</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="rockcor/blog-comment" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/rockcor"><i class="iconfont icon-github"></i></a><!-- Ins--><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--></section><p><span>Copyright ©</span><span> Rockcor 2024</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/jquery-3.6.1.min.js"></script><script src="/js/jquery-fancybox.min.js"></script><script src="/js/img_zoom.js"></script><script src="/js/post.js"></script></body></html>