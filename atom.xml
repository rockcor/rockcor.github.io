<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-03-07T14:38:33.601Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/day1_%E8%AF%BE%E5%A0%82%E7%BA%AA%E8%A6%81/"/>
    <id>http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/day1_%E8%AF%BE%E5%A0%82%E7%BA%AA%E8%A6%81/</id>
    <published>2023-02-13T05:36:26.147Z</published>
    <updated>2021-03-07T14:38:33.601Z</updated>
    
    <content type="html"><![CDATA[<p>7天 基础</p><ul><li>推荐系统相关概念 基本算法</li><li>推荐算法<ul><li>原生python 实现推荐算法</li></ul></li><li>lambda架构 5天<ul><li>hadoop</li><li>hive hbase</li><li>spark core</li><li>spark sql spark streaming</li><li>案例 基于电商用户行为</li></ul></li></ul><p>7天 项目</p><h3 id="推荐概念"><a href="#推荐概念" class="headerlink" title="推荐概念"></a>推荐概念</h3><ul><li>信息过滤系统 解决 信息过载 用户需求不明确的问题<ul><li>利用一定的规则将物品排序 展示给需求不明确的用户</li></ul></li><li>推荐 搜索区别<ul><li>推荐个性化较强，用户被动的接受，希望能够提供持续的服务</li><li>搜索个性化弱，用户主动搜索，快速满足用户的需求</li></ul></li><li>推荐和 web项目区别<ul><li>构建稳定的信息流通通道</li><li>推荐 信息过滤系统</li><li>web 对结果有明确预期</li><li>推荐 结果是概率问题</li></ul></li></ul><h3 id="Lambda-架构介绍"><a href="#Lambda-架构介绍" class="headerlink" title="Lambda 架构介绍"></a>Lambda 架构介绍</h3><ul><li>离线计算和实时计算共同提供服务的问题</li><li>离线计算优缺点<ul><li>优点 能够处理的数据量可以很大 比如pb级别</li><li>缺点 速度比较慢 分钟级别的延迟</li></ul></li><li>实时计算<ul><li>优点 响应快 来一条数据处理一条 ms级别响应</li><li>缺点 处理的数据量小一些</li></ul></li><li>离线计算的框架<ul><li>hadoop hdfs mapreduce</li><li>spark core , spark sql</li><li>hive</li></ul></li><li>实时计算框架<ul><li>spark streaming</li><li>storm</li><li>flink</li></ul></li><li>消息中间件<ul><li>flume 日志采集系统</li><li>kafka 消息队列</li></ul></li><li>存储相关<ul><li>hbase nosql数据库</li><li>hive  sql操作hdfs数据</li></ul></li></ul><h3 id="推荐算法架构"><a href="#推荐算法架构" class="headerlink" title="推荐算法架构"></a>推荐算法架构</h3><ul><li><p>召回</p><ul><li><p>协同过滤  算相似度 memory base</p><p>​                  基于模型的 model base  矩阵分解</p></li><li><p>基于内容</p><ul><li>分词</li><li>词权重（提取关键词） tf-idf</li><li>word2Vec 词向量</li><li>物品向量</li></ul></li></ul></li><li><p>排序</p><ul><li>逻辑回归</li></ul></li><li><p>策略调整</p></li></ul><h3 id="推荐模型构建流程"><a href="#推荐模型构建流程" class="headerlink" title="推荐模型构建流程"></a>推荐模型构建流程</h3><ul><li><p>数据收集</p><ul><li>显性评分</li><li>隐性数据</li></ul></li><li><p>特征工程</p><ul><li>协同过滤：用户-物品 评分矩阵</li><li>基于内容：分词 tf-idf word2Vec</li></ul></li><li><p>训练模型</p><ul><li>协同过滤<ul><li>kNN</li><li>矩阵分解 梯度下降 ALS</li></ul></li></ul></li><li><p>评估、模型上线</p></li></ul><h3 id="协同过滤思路介绍"><a href="#协同过滤思路介绍" class="headerlink" title="协同过滤思路介绍"></a>协同过滤思路介绍</h3><ul><li>CF 物以类聚人以群分</li><li>做协同过滤的话 首先特征工程把 用户-物品的评分矩阵创建出来</li><li>基于用户的协同过滤<ul><li>给用户A 找到最相似的N个用户</li><li>N个用户消费过哪些物品</li><li>N个用户消费过的物品中-A用户消费过的就是推荐结果</li></ul></li><li>基于物品的协同过滤<ul><li>给物品A 找到最相似的N个物品</li><li>A用户消费记录 找到这些物品的相似物品</li><li>从这些相似物品先去重-A用户消费过的就是推荐结果</li></ul></li></ul><h3 id="相似度计算"><a href="#相似度计算" class="headerlink" title="相似度计算"></a>相似度计算</h3><ul><li>余弦相似度、皮尔逊相关系数<ul><li>向量的夹角余弦值</li><li>皮尔逊会对向量的每一个分量做中心化</li><li>余弦只考虑方向 不考虑向量长度</li><li>如果评分数据是连续的数值比较适合中余弦、皮尔逊计算相似度</li></ul></li><li>杰卡德相似度<ul><li>交集/并集</li><li>计算评分是0 1 布尔值的相似度</li></ul></li></ul><h3 id="使用不同相似度计算方式实现协同过滤"><a href="#使用不同相似度计算方式实现协同过滤" class="headerlink" title="使用不同相似度计算方式实现协同过滤"></a>使用不同相似度计算方式实现协同过滤</h3><ul><li><p>如果 买/没买 点/没点数据 0/1 适合使用杰卡德相似度</p><ul><li>from sklearn.metrics import jaccard_similarity_score</li><li>jaccard_similarity_score(df[‘Item A’],df[‘Item B’])</li><li>from sklearn.metrics.pairwise import pairwise_distances</li><li>user_similar = 1-pairwise_distances(df,metric=’jaccard’)</li></ul></li><li><p>一般用评分去做协同过滤 推荐使用皮尔逊相关系数</p><ul><li><p>评分预测</p></li><li><p>$$<br> pred(u,i)=\hat{r}<em>{ui}=\cfrac{\sum</em>{v\in U}sim(u,v)*r_{vi}}{\sum_{v\in U}|sim(u,v)|}<br>$$</p></li></ul></li><li><p>基于用户和基于物品的协同过滤 严格上说，属于两种算法，实践中可以都做出来，对比效果，选择最靠谱的</p></li></ul><h3 id="协同过滤-基于模型的算法"><a href="#协同过滤-基于模型的算法" class="headerlink" title="协同过滤 基于模型的算法"></a>协同过滤 基于模型的算法</h3><ul><li>用户-物品矩阵比较稀疏的时候 直接去取物品向量 用户向量计算相似度 不太适合</li><li>基于模型的方法可以解决用户-物品矩阵比较稀疏的问题</li><li>矩阵分解<ul><li>把大的矩阵拆成两个小的 用户矩阵 物品矩阵  MXN 大矩阵   M X K    K X N  K&lt;&lt;M  k&lt;&lt;N</li><li>大矩阵 约等于 用户矩阵 乘 物品矩阵</li><li>使用als 交替最小二乘法来优化损失 spark ML  recommandation 包封装了als</li><li>优化之后的用户矩阵  取出用户向量</li><li>优化之后的物品矩阵  取出物品向量</li><li>用户向量点乘物品向量 得到最终评分的预测</li></ul></li></ul><h3 id="推荐系统的评价"><a href="#推荐系统的评价" class="headerlink" title="推荐系统的评价"></a>推荐系统的评价</h3><ul><li><p>准确率 覆盖率</p><ul><li>准确率<ul><li>学术  rmse mas   点击率预估 精准率</li><li>工程  A/B test 对比不同的算法 在线上运行对关键指标的影响 <ul><li>baseline 基准线 热门排行  </li><li>灰度发布</li></ul></li></ul></li></ul></li><li><p>EE</p><ul><li>Exploitation &amp; Exploration 探索与利用问题</li><li>Exploitation 利用用户的历史行为 只给他曾经看过的/消费过的相似物品</li><li>Exploration(探测 搜索) 发现用户的新兴趣</li><li>ee问题 实际上是矛盾</li></ul></li><li><p>评估手段</p><ul><li>离线评估和在线评估结合, 定期做问卷调查<ul><li>在线评估<ul><li>灰度发布 &amp; A/B测试</li></ul></li></ul></li></ul></li></ul><h3 id="推荐系统的冷启动"><a href="#推荐系统的冷启动" class="headerlink" title="推荐系统的冷启动"></a>推荐系统的冷启动</h3><ul><li>用户冷启动<ul><li>尽可能收集用户信息 构建用户画像（打标签）</li><li>根据用户的标签可以做人群聚类 用以有用户的行为做推荐</li><li>更多的使用流行度推荐</li></ul></li><li>物品冷启动<ul><li>物品打标签 构建物品画像</li><li>基于内容的推荐</li></ul></li><li>系统冷启动<ul><li>如果应用缺少用户行为数据-&gt;基于内容的推荐</li><li>随着用户行为积累的越来越多-&gt;协同过滤</li><li>基于内容和协同过滤共同工作</li></ul></li></ul><h3 id="基于内容的推荐"><a href="#基于内容的推荐" class="headerlink" title="基于内容的推荐"></a>基于内容的推荐</h3><ul><li>给物品打标签<ul><li>系统自己提取从业务数据库中提取（商品的标题副标题等）</li><li>用户填写</li><li>中文分词 利用算法计算词的权重 <ul><li>tf-idf  tf term frequency 词频  5/100 *2 <ul><li>idf 逆文档频率 log 10   文本库篇数/出现关键词的文章篇数</li><li>1000 10python  1000/10 100   2</li><li>1000/1000 log(1) = 0</li></ul></li><li>textrank</li></ul></li></ul></li><li>利用标签的文字 转换成词向量<ul><li>word2Vec 词-&gt;向量</li><li>用向量来表示语义</li><li>如果两个词的词向量相似度比较高 认为这两个词的语义相近</li></ul></li><li>利用词向量 构建物品的向量<ul><li>一个物品有N个关键词 每一个关键词对应一个词向量</li><li>求和（权重*词向量）/N</li><li>利用N个关键词的词向量获取物品向量</li></ul></li><li>通过物品向量计算相似度<ul><li>皮尔逊 相关系数 计算物品向量的相似度</li></ul></li></ul><h3 id="基于内容的推荐-基于物品的协同过滤-区别"><a href="#基于内容的推荐-基于物品的协同过滤-区别" class="headerlink" title="基于内容的推荐 基于物品的协同过滤 区别"></a>基于内容的推荐 基于物品的协同过滤 区别</h3><ul><li>content_base ：词向量-&gt;物品向量-&gt;计算相似度</li><li>item_based cf :user-item matrix-&gt;物品向量-&gt;相似度</li><li>content_base  item_based cf 不一样<ul><li>物品向量构建过程有区别</li><li>基于内容的推荐<ul><li>物品向量 文本（物品描述信息，系统填标签，用户填标签）</li></ul></li><li>基于物品的协同过滤<ul><li>用户对物品的评分矩阵 用户的行为数据中来</li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;7天 基础&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;推荐系统相关概念 基本算法&lt;/li&gt;
&lt;li&gt;推荐算法&lt;ul&gt;
&lt;li&gt;原生python 实现推荐算法&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;lambda架构 5天&lt;ul&gt;
&lt;li&gt;hadoop&lt;/li&gt;
&lt;li&gt;hive hbas</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/08_%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%EF%BC%9AItem-Based%20CF%20%E9%A2%84%E6%B5%8B%E8%AF%84%E5%88%86/"/>
    <id>http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/08_%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%EF%BC%9AItem-Based%20CF%20%E9%A2%84%E6%B5%8B%E8%AF%84%E5%88%86/</id>
    <published>2023-02-13T05:36:26.144Z</published>
    <updated>2021-03-07T14:38:33.471Z</updated>
    
    <content type="html"><![CDATA[<h2 id="案例–算法实现：Item-Based-CF-预测评分"><a href="#案例–算法实现：Item-Based-CF-预测评分" class="headerlink" title="案例–算法实现：Item-Based CF 预测评分"></a>案例–算法实现：Item-Based CF 预测评分</h2><p><strong>评分预测公式：</strong><br>$$<br>pred(u,i)=\hat{r}<em>{ui}=\cfrac{\sum</em>{j\in I_{rated}}sim(i,j)*r_{uj}}{\sum_{j\in I_{rated}}sim(i,j)}<br>$$</p><h4 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h4><ul><li><p>实现评分预测方法：<code>predict</code></p><ul><li><p>方法说明：</p><p>利用原始评分矩阵、以及物品间两两相似度，预测指定用户对指定物品的评分。</p><p>如果无法预测，则抛出异常</p></li></ul><pre><code class="python"># ......def predict(uid, iid, ratings_matrix, item_similar):    '''    预测给定用户对给定物品的评分值    :param uid: 用户ID    :param iid: 物品ID    :param ratings_matrix: 用户-物品评分矩阵    :param item_similar: 物品两两相似度矩阵    :return: 预测的评分值    '''    print("开始预测用户&lt;%d&gt;对电影&lt;%d&gt;的评分..."%(uid, iid))    # 1. 找出iid物品的相似物品    similar_items = item_similar[iid].drop([iid]).dropna()    # 相似物品筛选规则：正相关的物品    similar_items = similar_items.where(similar_items&gt;0).dropna()    if similar_items.empty is True:        raise Exception("物品&lt;%d&gt;没有相似的物品" %id)    # 2. 从iid物品的近邻相似物品中筛选出uid用户评分过的物品    ids = set(ratings_matrix.loc[uid].dropna().index)&amp;set(similar_items.index)    finally_similar_items = similar_items.loc[list(ids)]    # 3. 结合iid物品与其相似物品的相似度和uid用户对其相似物品的评分，预测uid对iid的评分    sum_up = 0    # 评分预测公式的分子部分的值    sum_down = 0    # 评分预测公式的分母部分的值    for sim_iid, similarity in finally_similar_items.iteritems():        # 近邻物品的评分数据        sim_item_rated_movies = ratings_matrix[sim_iid].dropna()        # uid用户对相似物品物品的评分        sim_item_rating_from_user = sim_item_rated_movies[uid]        # 计算分子的值        sum_up += similarity * sim_item_rating_from_user        # 计算分母的值        sum_down += similarity    # 计算预测的评分值并返回    predict_rating = sum_up/sum_down    print("预测出用户&lt;%d&gt;对电影&lt;%d&gt;的评分：%0.2f" % (uid, iid, predict_rating))    return round(predict_rating, 2)if __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    item_similar = compute_pearson_similarity(ratings_matrix, based="item")    # 预测用户1对物品1的评分    predict(1, 1, ratings_matrix, item_similar)    # 预测用户1对物品2的评分    predict(1, 2, ratings_matrix, item_similar)</code></pre></li><li><p>实现预测全部评分方法：<code>predict_all</code></p><pre><code class="python"># ......def predict_all(uid, ratings_matrix, item_similar):    '''    预测全部评分    :param uid: 用户id    :param ratings_matrix: 用户-物品打分矩阵    :param item_similar: 物品两两间的相似度    :return: 生成器，逐个返回预测评分    '''    # 准备要预测的物品的id列表    item_ids = ratings_matrix.columns    # 逐个预测    for iid in item_ids:        try:            rating = predict(uid, iid, ratings_matrix, item_similar)        except Exception as e:            print(e)        else:            yield uid, iid, ratingif __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    item_similar = compute_pearson_similarity(ratings_matrix, based="item")    for i in predict_all(1, ratings_matrix, item_similar):        pass</code></pre></li><li><p>添加过滤规则</p><pre><code class="python">def _predict_all(uid, item_ids,ratings_matrix, item_similar):    '''    预测全部评分    :param uid: 用户id    :param item_ids: 要预测物品id列表    :param ratings_matrix: 用户-物品打分矩阵    :param item_similar: 物品两两间的相似度    :return: 生成器，逐个返回预测评分    '''    # 逐个预测    for iid in item_ids:        try:            rating = predict(uid, iid, ratings_matrix, item_similar)        except Exception as e:            print(e)        else:            yield uid, iid, ratingdef predict_all(uid, ratings_matrix, item_similar, filter_rule=None):    '''    预测全部评分，并可根据条件进行前置过滤    :param uid: 用户ID    :param ratings_matrix: 用户-物品打分矩阵    :param item_similar: 物品两两间的相似度    :param filter_rule: 过滤规则，只能是四选一，否则将抛异常："unhot","rated",["unhot","rated"],None    :return: 生成器，逐个返回预测评分    '''    if not filter_rule:        item_ids = ratings_matrix.columns    elif isinstance(filter_rule, str) and filter_rule == "unhot":        '''过滤非热门电影'''        # 统计每部电影的评分数        count = ratings_matrix.count()        # 过滤出评分数高于10的电影，作为热门电影        item_ids = count.where(count&gt;10).dropna().index    elif isinstance(filter_rule, str) and filter_rule == "rated":        '''过滤用户评分过的电影'''        # 获取用户对所有电影的评分记录        user_ratings = ratings_matrix.loc[uid]        # 评分范围是1-5，小于6的都是评分过的，除此以外的都是没有评分的        _ = user_ratings&lt;6        item_ids = _.where(_==False).dropna().index    elif isinstance(filter_rule, list) and set(filter_rule) == set(["unhot", "rated"]):        '''过滤非热门和用户已经评分过的电影'''        count = ratings_matrix.count()        ids1 = count.where(count &gt; 10).dropna().index        user_ratings = ratings_matrix.loc[uid]        _ = user_ratings &lt; 6        ids2 = _.where(_ == False).dropna().index        # 取二者交集        item_ids = set(ids1)&amp;set(ids2)    else:        raise Exception("无效的过滤参数")    yield from _predict_all(uid, item_ids, ratings_matrix, item_similar)if __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    item_similar = compute_pearson_similarity(ratings_matrix, based="item")    for result in predict_all(1, ratings_matrix, item_similar, filter_rule=["unhot", "rated"]):        print(result)</code></pre></li><li><p>为指定用户推荐TOP-N结果</p><pre><code class="python"># ......def top_k_rs_result(k):    ratings_matrix = load_data(DATA_PATH)    item_similar = compute_pearson_similarity(ratings_matrix, based="item")    results = predict_all(1, ratings_matrix, item_similar, filter_rule=["unhot", "rated"])    return sorted(results, key=lambda x: x[2], reverse=True)[:k]if __name__ == '__main__':    from pprint import pprint    result = top_k_rs_result(20)    pprint(result)</code></pre></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;案例–算法实现：Item-Based-CF-预测评分&quot;&gt;&lt;a href=&quot;#案例–算法实现：Item-Based-CF-预测评分&quot; class=&quot;headerlink&quot; title=&quot;案例–算法实现：Item-Based CF 预测评分&quot;&gt;&lt;/a&gt;案例–算法实现：</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/07_%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%EF%BC%9AUser-Based%20CF%20%E9%A2%84%E6%B5%8B%E8%AF%84%E5%88%86/"/>
    <id>http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/07_%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%EF%BC%9AUser-Based%20CF%20%E9%A2%84%E6%B5%8B%E8%AF%84%E5%88%86/</id>
    <published>2023-02-13T05:36:26.142Z</published>
    <updated>2021-03-07T14:38:33.407Z</updated>
    
    <content type="html"><![CDATA[<h2 id="案例–算法实现：User-Based-CF-预测评分"><a href="#案例–算法实现：User-Based-CF-预测评分" class="headerlink" title="案例–算法实现：User-Based CF 预测评分"></a>案例–算法实现：User-Based CF 预测评分</h2><p><strong>评分预测公式：</strong><br>$$<br>pred(u,i)=\hat{r}<em>{ui}=\cfrac{\sum</em>{v\in U}sim(u,v)*r_{vi}}{\sum_{v\in U}|sim(u,v)|}<br>$$</p><h4 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h4><ul><li><p>实现评分预测方法：<code>predict</code></p><pre><code class="python"># ......def predict(uid, iid, ratings_matrix, user_similar):    '''    预测给定用户对给定物品的评分值    :param uid: 用户ID    :param iid: 物品ID    :param ratings_matrix: 用户-物品评分矩阵    :param user_similar: 用户两两相似度矩阵    :return: 预测的评分值    '''    print("开始预测用户&lt;%d&gt;对电影&lt;%d&gt;的评分..."%(uid, iid))    # 1. 找出uid用户的相似用户    similar_users = user_similar[uid].drop([uid]).dropna()    # 相似用户筛选规则：正相关的用户，负数就抛弃掉    similar_users = similar_users.where(similar_users&gt;0).dropna()    if similar_users.empty is True:        raise Exception("用户&lt;%d&gt;没有相似的用户" % uid)    # 2. 从uid用户的近邻相似用户中筛选出对iid物品有评分记录的近邻用户，也就是消费过iid物品的用户都拿出来    ids = set(ratings_matrix[iid].dropna().index)&amp;set(similar_users.index)    finally_similar_users = similar_users.ix[list(ids)]    # 3. 结合uid用户与其近邻用户的相似度预测uid用户对iid物品的评分    sum_up = 0    # 评分预测公式的分子部分的值    sum_down = 0    # 评分预测公式的分母部分的值    for sim_uid, similarity in finally_similar_users.iteritems():        # 近邻用户的评分数据        sim_user_rated_movies = ratings_matrix.ix[sim_uid].dropna()        # 近邻用户对iid物品的评分        sim_user_rating_for_item = sim_user_rated_movies[iid]        # 计算分子的值        sum_up += similarity * sim_user_rating_for_item        # 计算分母的值        sum_down += similarity    # 计算预测的评分值并返回    predict_rating = sum_up/sum_down    print("预测出用户&lt;%d&gt;对电影&lt;%d&gt;的评分：%0.2f" % (uid, iid, predict_rating))    return round(predict_rating, 2)if __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    user_similar = compute_pearson_similarity(ratings_matrix, based="user")    # 预测用户1对物品1的评分    predict(1, 1, ratings_matrix, user_similar)    # 预测用户1对物品2的评分    predict(1, 2, ratings_matrix, user_similar)</code></pre></li><li><p>实现预测全部评分方法：<code>predict_all</code></p><pre><code class="python"># ......def predict_all(uid, ratings_matrix, user_similar):    '''    预测全部评分    :param uid: 用户id    :param ratings_matrix: 用户-物品打分矩阵    :param user_similar: 用户两两间的相似度    :return: 生成器，逐个返回预测评分    '''    # 准备要预测的物品的id列表    item_ids = ratings_matrix.columns    # 逐个预测    for iid in item_ids:        try:            rating = predict(uid, iid, ratings_matrix, user_similar)        except Exception as e:            print(e)        else:            yield uid, iid, ratingif __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    user_similar = compute_pearson_similarity(ratings_matrix, based="user")    for i in predict_all(1, ratings_matrix, user_similar):        pass</code></pre></li><li><p>添加过滤规则</p><pre><code class="python">def _predict_all(uid, item_ids, ratings_matrix, user_similar):    '''    预测全部评分    :param uid: 用户id    :param item_ids: 要预测的物品id列表    :param ratings_matrix: 用户-物品打分矩阵    :param user_similar: 用户两两间的相似度    :return: 生成器，逐个返回预测评分    '''    # 逐个预测    for iid in item_ids:        try:            rating = predict(uid, iid, ratings_matrix, user_similar)        except Exception as e:            print(e)        else:            yield uid, iid, ratingdef predict_all(uid, ratings_matrix, user_similar, filter_rule=None):    '''    预测全部评分，并可根据条件进行前置过滤    :param uid: 用户ID    :param ratings_matrix: 用户-物品打分矩阵    :param user_similar: 用户两两间的相似度    :param filter_rule: 过滤规则，只能是四选一，否则将抛异常："unhot","rated",["unhot","rated"],None    :return: 生成器，逐个返回预测评分    '''    if not filter_rule:        item_ids = ratings_matrix.columns    elif isinstance(filter_rule, str) and filter_rule == "unhot":        '''过滤非热门电影'''        # 统计每部电影的评分数        count = ratings_matrix.count()        # 过滤出评分数高于10的电影，作为热门电影        item_ids = count.where(count&gt;10).dropna().index    elif isinstance(filter_rule, str) and filter_rule == "rated":        '''过滤用户评分过的电影'''        # 获取用户对所有电影的评分记录        user_ratings = ratings_matrix.loc[uid]        # 评分范围是1-5，小于6的都是评分过的，除此以外的都是没有评分的        _ = user_ratings&lt;6        item_ids = _.where(_==False).dropna().index    elif isinstance(filter_rule, list) and set(filter_rule) == set(["unhot", "rated"]):        '''过滤非热门和用户已经评分过的电影'''        count = ratings_matrix.count()        ids1 = count.where(count &gt; 10).dropna().index        user_ratings = ratings_matrix.loc[uid]        _ = user_ratings &lt; 6        ids2 = _.where(_ == False).dropna().index        # 取二者交集        item_ids = set(ids1)&amp;set(ids2)    else:        raise Exception("无效的过滤参数")    yield from _predict_all(uid, item_ids, ratings_matrix, user_similar)if __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    user_similar = compute_pearson_similarity(ratings_matrix, based="user")    for result in predict_all(1, ratings_matrix, user_similar, filter_rule=["unhot", "rated"]):        print(result)</code></pre></li><li><p>根据预测评分为指定用户进行TOP-N推荐：</p><pre><code class="python"># ......def top_k_rs_result(k):    ratings_matrix = load_data(DATA_PATH)    user_similar = compute_pearson_similarity(ratings_matrix, based="user")    results = predict_all(1, ratings_matrix, user_similar, filter_rule=["unhot", "rated"])    return sorted(results, key=lambda x: x[2], reverse=True)[:k]if __name__ == '__main__':    from pprint import pprint    result = top_k_rs_result(20)    pprint(result)</code></pre></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;案例–算法实现：User-Based-CF-预测评分&quot;&gt;&lt;a href=&quot;#案例–算法实现：User-Based-CF-预测评分&quot; class=&quot;headerlink&quot; title=&quot;案例–算法实现：User-Based CF 预测评分&quot;&gt;&lt;/a&gt;案例–算法实现：</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/06_%E6%A1%88%E4%BE%8B--%E5%9F%BA%E4%BA%8E%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90/"/>
    <id>http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/06_%E6%A1%88%E4%BE%8B--%E5%9F%BA%E4%BA%8E%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90/</id>
    <published>2023-02-13T05:36:26.129Z</published>
    <updated>2021-03-07T14:38:33.531Z</updated>
    
    <content type="html"><![CDATA[<h2 id="案例–基于协同过滤的电影推荐"><a href="#案例–基于协同过滤的电影推荐" class="headerlink" title="案例–基于协同过滤的电影推荐"></a>案例–基于协同过滤的电影推荐</h2><p>前面我们已经基本掌握了协同过滤推荐算法，以及其中两种最基本的实现方案：User-Based CF和Item-Based CF，下面我们将利用真是的数据来进行实战演练。</p><p>案例需求 演示效果</p><p>分析案例</p><h4 id="数据集下载"><a href="#数据集下载" class="headerlink" title="数据集下载"></a>数据集下载</h4><p><a href="https://grouplens.org/datasets/movielens/latest/">MovieLens Latest Datasets Small</a></p><p>建议下载<a href="http://files.grouplens.org/datasets/movielens/ml-latest-small.zip">ml-latest-small.zip</a>，数据量小，便于我们单机使用和运行</p><p>目标：根据<code>ml-latest-small/ratings.csv</code>（用户-电影评分数据），分别实现User-Based CF和Item-Based CF，并进行电影评分的预测，然后为用户实现电影推荐</p><h4 id="数据集加载"><a href="#数据集加载" class="headerlink" title="数据集加载"></a>数据集加载</h4><ul><li><p>加载ratings.csv，并转换为用户-电影评分矩阵</p><pre><code class="python">import osimport pandas as pdimport numpy as npDATA_PATH = "./datasets/ml-latest-small/ratings.csv"CACHE_DIR = "./datasets/cache/"def load_data(data_path):    '''    加载数据    :param data_path: 数据集路径    :param cache_path: 数据集缓存路径    :return: 用户-物品评分矩阵    '''    # 数据集缓存地址    cache_path = os.path.join(CACHE_DIR, "ratings_matrix.cache")    print("开始加载数据集...")    if os.path.exists(cache_path):    # 判断是否存在缓存文件        print("加载缓存中...")        ratings_matrix = pd.read_pickle(cache_path)        print("从缓存加载数据集完毕")    else:        print("加载新数据中...")        # 设置要加载的数据字段的类型        dtype = {"userId": np.int32, "movieId": np.int32, "rating": np.float32}        # 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分        ratings = pd.read_csv(data_path, dtype=dtype, usecols=range(3))        # 透视表，将电影ID转换为列名称，转换成为一个User-Movie的评分矩阵        ratings_matrix = ratings.pivot_table(index=["userId"], columns=["movieId"], values="rating")        # 存入缓存文件        ratings_matrix.to_pickle(cache_path)        print("数据集加载完毕")    return  ratings_matrixif __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    print(ratings_matrix)</code></pre></li></ul><h4 id="相似度计算"><a href="#相似度计算" class="headerlink" title="相似度计算"></a>相似度计算</h4><ul><li><p>计算用户或物品两两相似度：</p><pre><code class="python"># ......def compute_pearson_similarity(ratings_matrix, based="user"):    '''    计算皮尔逊相关系数    :param ratings_matrix: 用户-物品评分矩阵    :param based: "user" or "item"    :return: 相似度矩阵    '''    user_similarity_cache_path = os.path.join(CACHE_DIR, "user_similarity.cache")    item_similarity_cache_path = os.path.join(CACHE_DIR, "item_similarity.cache")    # 基于皮尔逊相关系数计算相似度    # 用户相似度    if based == "user":        if os.path.exists(user_similarity_cache_path):            print("正从缓存加载用户相似度矩阵")            similarity = pd.read_pickle(user_similarity_cache_path)        else:            print("开始计算用户相似度矩阵")            similarity = ratings_matrix.T.corr()            similarity.to_pickle(user_similarity_cache_path)    elif based == "item":        if os.path.exists(item_similarity_cache_path):            print("正从缓存加载物品相似度矩阵")            similarity = pd.read_pickle(item_similarity_cache_path)        else:            print("开始计算物品相似度矩阵")            similarity = ratings_matrix.corr()            similarity.to_pickle(item_similarity_cache_path)    else:        raise Exception("Unhandled 'based' Value: %s"%based)    print("相似度矩阵计算/加载完毕")    return similarityif __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    user_similar = compute_pearson_similarity(ratings_matrix, based="user")    print(user_similar)    item_similar = compute_pearson_similarity(ratings_matrix, based="item")    print(item_similar)</code></pre></li></ul><h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><p>以上实现，仅用于实验阶段，因为工业上、或生产环境中，数据量是远超过我们本例中使用的数据量的，而pandas是无法支撑起大批量数据的运算的（上T的），因此工业上通常会使用spark、mapReduce等分布式计算框架来实现，我们后面的课程中也是建立在此基础上进行实践的。</p><p>但是正如前面所说，推荐算法的思想和理念都是统一的，不论使用什么平台工具、有多大的数据体量，其背后的实现原理都是不变的。</p><p>所以在本节，大家要深刻去学习的是推荐算法的业务流程，以及在具体的业务场景中，如本例的电影推荐，如何实现出推荐算法，并产生推荐结果。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;案例–基于协同过滤的电影推荐&quot;&gt;&lt;a href=&quot;#案例–基于协同过滤的电影推荐&quot; class=&quot;headerlink&quot; title=&quot;案例–基于协同过滤的电影推荐&quot;&gt;&lt;/a&gt;案例–基于协同过滤的电影推荐&lt;/h2&gt;&lt;p&gt;前面我们已经基本掌握了协同过滤推荐算法，以及</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/05_%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%86%B7%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/05_%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%86%B7%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98/</id>
    <published>2023-02-13T05:36:26.127Z</published>
    <updated>2021-08-06T12:09:59.832Z</updated>
    
    <content type="html"><![CDATA[<h3 id="推荐系统的冷启动问题"><a href="#推荐系统的冷启动问题" class="headerlink" title="推荐系统的冷启动问题"></a>推荐系统的冷启动问题</h3><ul><li><p>推荐系统冷启动概念</p><ul><li>⽤户冷启动：如何为新⽤户做个性化推荐</li><li>物品冷启动：如何将新物品推荐给⽤户（协同过滤）</li><li>系统冷启动：⽤户冷启动+物品冷启动</li><li>本质是推荐系统依赖历史数据，没有历史数据⽆法预测⽤户偏好</li></ul></li><li><p>用户冷启动</p><ul><li><p>1.收集⽤户特征</p><ul><li><p>⽤户注册信息：性别、年龄、地域（不能太多，不然用户不填写）</p></li><li><p>设备信息：定位、⼿机型号、app列表</p></li><li><p>社交信息、推⼴素材、安装来源</p><p><img src="/./img/recommend4.png"></p></li></ul></li><li><p>2 引导用户填写兴趣</p><p><img src="/./img/recommend5.png"></p></li><li><p>3 使用其它站点的行为数据, 例如腾讯视频&amp;QQ音乐 今日头条&amp;抖音</p></li><li><p>4 新老用户推荐策略的差异</p><ul><li>新⽤户在冷启动阶段更倾向于热门排⾏榜，⽼⽤户会更加需要长尾推荐</li><li>Explore Exploit⼒度（新用户探索是保守）</li><li>使⽤单独的特征和模型预估–新旧用户分离</li></ul></li><li><p>举例 性别与电视剧的关系</p></li></ul><p><img src="/./img/firststart.png"></p><p><img src="/./img/firststart1.png"></p><p><strong>用户冷启动</strong></p><ul><li>尽可能收集用户信息 构建用户画像（打标签）</li><li>根据用户的标签可以做人群聚类 用以有用户的行为做推荐</li><li>更多的使用流行度推荐</li></ul></li><li><p>物品冷启动</p><ul><li>给物品打标签</li><li>利用物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户。</li></ul><p><img src="/img/firststart2.png"></p><p>物品冷启动</p><ul><li>物品打标签 构建物品画像</li><li>基于内容的推荐</li></ul></li><li><p>系统冷启动</p><ul><li>基于内容的推荐 系统早期</li><li>基于内容的推荐逐渐过渡到协同过滤</li><li>基于内容的推荐和协同过滤的推荐结果都计算出来 加权求和得到最终推荐结果</li></ul></li></ul><h3 id="基于内容的推荐"><a href="#基于内容的推荐" class="headerlink" title="基于内容的推荐"></a>基于内容的推荐</h3><ul><li>给物品打标签<ul><li>系统自己提取从业务数据库中提取（商品的标题副标题等）</li><li>用户填写</li><li>中文分词 利用算法计算词的权重 <ul><li>tf-idf  tf term frequency 词频  5/100 *2 <ul><li>idf 逆文档频率 log 10   文本库篇数/出现关键词的文章篇数</li><li>1000 10python  1000/10 100   2</li><li>1000/1000 log(1) = 0</li></ul></li><li>textrank</li></ul></li></ul></li><li>利用标签的文字 转换成词向量<ul><li>word2Vec 词-&gt;向量</li><li>用向量来表示语义</li><li>如果两个词的词向量相似度比较高 认为这两个词的语义相近</li></ul></li><li>利用词向量 构建物品的向量<ul><li>一个物品有N个关键词 每一个关键词对应一个词向量</li><li>求和（权重*词向量）/N</li><li>利用N个关键词的词向量获取物品向量</li></ul></li><li>通过物品向量计算相似度<ul><li>皮尔逊 相关系数 计算物品向量的相似度</li></ul></li></ul><h3 id="基于内容的推荐-基于物品的协同过滤-区别"><a href="#基于内容的推荐-基于物品的协同过滤-区别" class="headerlink" title="基于内容的推荐 基于物品的协同过滤 区别"></a>基于内容的推荐 基于物品的协同过滤 区别</h3><ul><li>content_base ：词向量-&gt;物品向量-&gt;计算相似度</li><li>item_based cf :user-item matrix-&gt;物品向量-&gt;相似度</li><li>content_base  item_based cf 不一样<ul><li>物品向量构建过程有区别</li><li>基于内容的推荐<ul><li>物品向量 文本（物品描述信息，系统填标签，用户填标签）</li></ul></li><li>基于物品的协同过滤<ul><li>用户对物品的评分矩阵 用户的行为数据中来</li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;推荐系统的冷启动问题&quot;&gt;&lt;a href=&quot;#推荐系统的冷启动问题&quot; class=&quot;headerlink&quot; title=&quot;推荐系统的冷启动问题&quot;&gt;&lt;/a&gt;推荐系统的冷启动问题&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;推荐系统冷启动概念&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;⽤户冷启动：</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/04_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/04_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/</id>
    <published>2023-02-13T05:36:26.125Z</published>
    <updated>2021-08-06T08:14:18.344Z</updated>
    
    <content type="html"><![CDATA[<h2 id="推荐算法"><a href="#推荐算法" class="headerlink" title="推荐算法"></a>推荐算法</h2><ul><li>推荐模型构建流程</li><li>推荐算法概述</li><li>基于协同过滤的推荐算法</li><li>协同过滤实现</li></ul><h3 id="一-推荐模型构建流程"><a href="#一-推荐模型构建流程" class="headerlink" title="一 推荐模型构建流程"></a>一 推荐模型构建流程</h3><p>Data(数据)-&gt;Features(特征)-&gt;ML Algorithm(机器学习算法)-&gt;Prediction Output(预测输出)</p><ul><li>数据清洗/数据处理</li></ul><p><img src="/./img/algorithm1.png"></p><ul><li>数据来源<ul><li>显性数据<ul><li>Rating 打分</li><li>Comments 评论/评价</li></ul></li><li>隐形数据<ul><li> Order history 历史订单</li><li> Cart events    加购物车</li><li> Page views    页面浏览</li><li> Click-thru      点击</li><li> Search log     搜索记录</li></ul></li></ul></li><li>数据量/数据能否满足要求</li><li>特征工程</li></ul><p><img src="/./img/algorithm2.png"></p><ul><li>从数据中筛选特征<ul><li>一个给定的商品，可能被拥有类似品味或需求的用户购买</li><li>使用用户行为数据描述商品</li></ul></li></ul><p><img src="/./img/algorithm3.png"></p><ul><li><p>用数据表示特征</p><ul><li><p>将所有用户行为合并在一起 ，形成一个user-item 矩阵</p><p><img src="/./img/algorithm4.png" alt="1545452707102"></p></li></ul></li><li><p>选择合适的算法</p></li></ul><p><img src="/./img/algorithm5.png"></p><ul><li><p>产生推荐结果</p><p><img src="/./img/algorithm6.png"></p></li></ul><h3 id="二-最经典的推荐算法：协同过滤推荐算法（Collaborative-Filtering）"><a href="#二-最经典的推荐算法：协同过滤推荐算法（Collaborative-Filtering）" class="headerlink" title="二 最经典的推荐算法：协同过滤推荐算法（Collaborative Filtering）"></a>二 最经典的推荐算法：协同过滤推荐算法（Collaborative Filtering）</h3><p>算法思想：<strong>物以类聚，人以群分</strong></p><p>基本的协同过滤推荐算法基于以下假设：</p><ul><li>“跟你喜好<strong>相似的人</strong>喜欢的东西你也很有可能喜欢” ：基于用户的协同过滤推荐（User-based CF）</li><li>“跟你喜欢的东西<strong>相似的东西</strong>你也很有可能喜欢 ”：基于物品的协同过滤推荐（Item-based CF）</li></ul><p>实现协同过滤推荐有以下几个步骤：</p><ol><li><p><strong>找出最相似的人或物品：TOP-N相似的人或物品</strong></p><p>通过计算两两的相似度来进行排序，即可找出TOP-N相似的人或物品</p></li><li><p><strong>根据相似的人或物品产生推荐结果</strong></p><p>利用TOP-N结果生成初始推荐结果，然后过滤掉用户已经有过记录的物品或明确表示不感兴趣的物品</p></li></ol><p>以下是一个简单的示例，数据集相当于一个用户对物品的购买记录表：打勾表示用户对物品的有购买记录</p><ul><li><p>关于相似度计算这里先用一个简单的思想：如有两个同学X和Y，X同学爱好[足球、篮球、乒乓球]，Y同学爱好[网球、足球、篮球、羽毛球]，可见他们的共同爱好有2个，那么他们的相似度可以用：2/3 * 2/4 = 1/3 ≈ 0.33 来表示。</p><p>User-Based CF</p><p><img src="/./img/%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%901.png"></p><p>Item-Based CF</p><p><img src="/./img/%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%901.png"></p><p>通过前面两个demo，相信大家应该已经对协同过滤推荐算法的设计与实现有了比较清晰的认识。</p></li></ul><h3 id="三-相似度计算-Similarity-Calculation"><a href="#三-相似度计算-Similarity-Calculation" class="headerlink" title="三 相似度计算(Similarity Calculation)"></a>三 相似度计算(Similarity Calculation)</h3><p><img src="/./img/similarity_calc1.png"></p><ul><li><p>相似度的计算方法</p><ul><li>数据分类<ul><li>实数值(物品评分情况)</li><li>布尔值(用户的行为 是否点击 是否收藏)</li></ul></li><li>欧氏距离, 是一个欧式空间下度量距离的方法. 两个物体, 都在同一个空间下表示为两个点, 假如叫做p,q, 分别都是n个坐标, 那么欧式距离就是衡量这两个点之间的距离. <strong>欧氏距离不适用于布尔向量之间</strong></li></ul><p><img src="/./img/od.png" alt="1546159024305"></p><p>​欧氏距离的值是一个非负数, 最大值正无穷, 通常计算相似度的结果希望是[-1,1]或[0,1]之间,一般可以使用</p><p>​如下转化公式:<img src="/./img/od2.png"></p><p>​</p></li><li><p>杰卡德相似度&amp;余弦相似度&amp;皮尔逊相关系数</p><ul><li>余弦相似度<ul><li>度量的是两个向量之间的夹角, 用夹角的余弦值来度量相似的情况</li><li>两个向量的夹角为0是,余弦值为1, 当夹角为90度是余弦值为0,为180度是余弦值为-1</li><li>余弦相似度在度量文本相似度, 用户相似度 物品相似度的时候较为常用</li><li>余弦相似度的特点, 与向量长度无关,余弦相似度计算要对向量长度归一化, 两个向量只要方向一致,无论程度强弱, 都可以视为’相似’</li></ul></li><li>皮尔逊相关系数Pearson<ul><li>实际上也是一种余弦相似度, 不过先对向量做了中心化, 向量a b 各自<strong>减去向量的均值后, 再计算余弦相似度</strong></li><li>皮尔逊相似度计算结果在-1,1之间 -1表示负相关, 1表示正相关</li><li>度量两个变量是不是同增同减</li><li>皮尔逊相关系数度量的是两个变量的变化趋势是否一致, <strong>不适合计算布尔值向量之间的相关度</strong></li></ul></li><li>杰卡德相似度 Jaccard<ul><li>两个集合的交集元素个数在并集中所占的比例, 非常适用于布尔向量表示</li><li>分子是两个布尔向量做点积计算, 得到的就是交集元素的个数</li><li>分母是两个布尔向量做或运算, 再求元素和</li></ul></li><li>余弦相似度适合用户评分数据(实数值), 杰卡德相似度适用于隐式反馈数据(0,1布尔值)(是否收藏,是否点击,是否加购物车)</li></ul></li></ul><p><img src="/./img/similarity_calc2.png"></p><ul><li><p>余弦相似度</p><p><img src="/./img/similarity_calc5.png"></p></li><li><p>皮尔逊相关系数</p></li><li><p><img src="/img/image-20210806161414511.png" alt="image-20210806161414511"></p></li></ul><p><img src="/./img/similarity_calc3.png"></p><p><img src="/./img/similarity_calc4.png"></p><ul><li>计算出用户1和其它用户之间的相似度</li></ul><p><img src="/./img/similarity_calc6.png"></p><ul><li>按照相似度大小排序, K近邻 如K取4:</li></ul><p><img src="/./img/similarity_calc7.png"></p><ul><li>取出近邻用户的购物清单</li></ul><p><img src="/./img/similarity_calc8.png"></p><ul><li>去除用户1已经购买过的商品</li></ul><p><img src="/./img/similarity_calc9.png"></p><ul><li>在剩余的物品中根据评分排序</li></ul><p><img src="/./img/similarity_calc10.png"></p><ul><li>物品相似度计算<ul><li>余弦相似度对绝对值大小不敏感带来的问题<ul><li>用户A对两部电影评分分别是1分和2分, 用户B对同样这两部电影进行评分是4分,5分 用余弦相似度计算,两个用户的相似度达到0.98    </li><li>可以采用改进的余弦相似度, 先计算向量每个维度上的均值, 然后每个向量在各个维度上都减去均值后,在计算余弦相似度, 用调整的余弦相似度计算得到的相似度是-0.1</li></ul></li></ul></li></ul><p><img src="/./img/similarity_calc11.png"></p><ul><li>物品相似度计算案例</li></ul><p><img src="/./img/similarity_calc12.png"></p><ul><li>找出物品1的相似商品</li></ul><p><img src="/./img/similarity_calc13.png"></p><ul><li>选择最近似的物品</li></ul><p><img src="/./img/similarity_calc14.png"></p><ul><li>基于用户与物品的协同过滤比较</li></ul><p><img src="/./img/similarity_calc15.png"><img src="/./img/similarity_calc16.png"></p><h3 id="协同过滤推荐算法代码实现："><a href="#协同过滤推荐算法代码实现：" class="headerlink" title="协同过滤推荐算法代码实现："></a>协同过滤推荐算法代码实现：</h3><ul><li><p>构建数据集：</p><pre><code class="python">users = ["User1", "User2", "User3", "User4", "User5"]items = ["Item A", "Item B", "Item C", "Item D", "Item E"]# 构建数据集datasets = [    ["buy",None,"buy","buy",None],    ["buy",None,None,"buy","buy"],    ["buy",None,"buy",None,None],    [None,"buy",None,"buy","buy"],    ["buy","buy","buy",None,"buy"],]</code></pre></li><li><p>计算时我们数据通常都需要对数据进行处理，或者编码，目的是为了便于我们对数据进行运算处理，比如这里是比较简单的情形，我们用1、0分别来表示用户的是否购买过该物品，则我们的数据集其实应该是这样的：</p><pre><code class="python">users = ["User1", "User2", "User3", "User4", "User5"]items = ["Item A", "Item B", "Item C", "Item D", "Item E"]# 用户购买记录数据集datasets = [    [1,0,1,1,0],    [1,0,0,1,1],    [1,0,1,0,0],    [0,1,0,1,1],    [1,1,1,0,1],]import pandas as pddf = pd.DataFrame(datasets,                  columns=items,                  index=users)print(df)</code></pre></li><li><p>有了数据集，接下来我们就可以进行相似度的计算，不过对于相似度的计算其实是有很多专门的相似度计算方法的，比如余弦相似度、皮尔逊相关系数、杰卡德相似度等等。这里我们选择使用杰卡德相似系数[0,1]</p><pre><code class="python"># 直接计算某两项的杰卡德相似系数from sklearn.metrics import jaccard_score# 计算Item A 和Item B的相似度print(jaccard_score(df["Item A"], df["Item B"]))# 计算所有的数据两两的杰卡德相似系数from sklearn.metrics.pairwise import pairwise_distances# 计算用户间相似度，1减去杰卡德距离就是杰卡德相识度user_similar = 1 - pairwise_distances(df.values, metric="jaccard")user_similar = pd.DataFrame(user_similar, columns=users, index=users)print("用户之间的两两相似度：")print(user_similar)# 计算物品间相似度item_similar = 1 - pairwise_distances(df.T.values, metric="jaccard")item_similar = pd.DataFrame(item_similar, columns=items, index=items)print("物品之间的两两相似度：")print(item_similar)</code></pre><p>有了两两的相似度，接下来就可以筛选TOP-N相似结果，并进行推荐了</p></li><li><p>User-Based CF</p><pre><code class="python">import pandas as pdimport numpy as npfrom pprint import pprintusers = ["User1", "User2", "User3", "User4", "User5"]items = ["Item A", "Item B", "Item C", "Item D", "Item E"]# 用户购买记录数据集datasets = [    [1,0,1,1,0],    [1,0,0,1,1],    [1,0,1,0,0],    [0,1,0,1,1],    [1,1,1,0,1],]df = pd.DataFrame(datasets,                  columns=items,                  index=users)# 计算所有的数据两两的杰卡德相似系数from sklearn.metrics.pairwise import pairwise_distances# 计算用户间相似度user_similar = 1 - pairwise_distances(df, metric="jaccard")user_similar = pd.DataFrame(user_similar, columns=users, index=users)print("用户之间的两两相似度：")print(user_similar)topN_users = {}# 遍历每一行数据for i in user_similar.index:    # 取出每一列数据，并删除自身，然后排序数据    _df = user_similar.loc[i].drop([i])    _df_sorted = _df.sort_values(ascending=False)    top2 = list(_df_sorted.index[:2])    topN_users[i] = top2print("Top2相似用户：")pprint(topN_users)rs_results = {}# 构建推荐结果for user, sim_users in topN_users.items():    rs_result = set()    # 存储推荐结果    for sim_user in sim_users:        # 构建初始的推荐结果,要去重         rs_result = rs_result.union(set(df.loc[sim_user].replace(0,np.nan).dropna().index))    # 过滤掉已经购买过的物品    rs_result -= set(df.loc[user].replace(0,np.nan).dropna().index)    rs_results[user] = rs_resultprint("最终推荐结果：")pprint(rs_results)</code></pre></li><li><p>Item-Based CF</p><pre><code class="python">import pandas as pdimport numpy as npfrom pprint import pprintusers = ["User1", "User2", "User3", "User4", "User5"]items = ["Item A", "Item B", "Item C", "Item D", "Item E"]# 用户购买记录数据集datasets = [    [1,0,1,1,0],    [1,0,0,1,1],    [1,0,1,0,0],    [0,1,0,1,1],    [1,1,1,0,1],]df = pd.DataFrame(datasets,                  columns=items,                  index=users)# 计算所有的数据两两的杰卡德相似系数from sklearn.metrics.pairwise import pairwise_distances# 计算物品间相似度item_similar = 1 - pairwise_distances(df.T, metric="jaccard")item_similar = pd.DataFrame(item_similar, columns=items, index=items)print("物品之间的两两相似度：")print(item_similar)topN_items = {}# 遍历每一行数据for i in item_similar.index:    # 取出每一列数据，并删除自身，然后排序数据    _df = item_similar.loc[i].drop([i])    _df_sorted = _df.sort_values(ascending=False)    top2 = list(_df_sorted.index[:2])    topN_items[i] = top2print("Top2相似物品：")pprint(topN_items)rs_results = {}# 构建推荐结果for user in df.index:    # 遍历所有用户    rs_result = set()    for item in df.ix[user].replace(0,np.nan).dropna().index:   # 取出每个用户当前已购物品列表        # 根据每个物品找出最相似的TOP-N物品，构建初始推荐结果        rs_result = rs_result.union(topN_items[item])    # 过滤掉用户已购的物品    rs_result -= set(df.ix[user].replace(0,np.nan).dropna().index)    # 添加到结果中    rs_results[user] = rs_resultprint("最终推荐结果：")pprint(rs_results)</code></pre></li></ul><p><strong>关于协同过滤推荐算法使用的数据集</strong></p><p>在前面的demo中，我们只是使用用户对物品的一个购买记录，类似也可以是比如浏览点击记录、收听记录等等。这样数据我们预测的结果其实相当于是在预测用户是否对某物品感兴趣，对于喜好程度不能很好的预测。</p><p>因此在协同过滤推荐算法中其实会更多的利用用户对物品的“评分”数据来进行预测，通过评分数据集，我们可以预测用户对于他没有评分过的物品的评分。其实现原理和思想和都是一样的，只是使用的数据集是用户-物品的评分数据。</p><p><strong>关于用户-物品评分矩阵</strong></p><p>用户-物品的评分矩阵，根据评分矩阵的稀疏程度会有不同的解决方案</p><ul><li><p>稠密评分矩阵</p><p><img src="/./img/%E7%A8%A0%E5%AF%86%E8%AF%84%E5%88%86%E6%95%B0%E6%8D%AE%E9%9B%86.png"></p></li><li><p>稀疏评分矩阵</p><p><img src="/./img/%E7%A8%80%E7%96%8F%E8%AF%84%E5%88%86%E6%95%B0%E6%8D%AE%E9%9B%86.png"></p></li></ul><p>这里先介绍稠密评分矩阵的处理，稀疏矩阵的处理相对会复杂一些，我们到后面再来介绍。</p><h4 id="使用协同过滤推荐算法对用户进行评分预测"><a href="#使用协同过滤推荐算法对用户进行评分预测" class="headerlink" title="使用协同过滤推荐算法对用户进行评分预测"></a>使用协同过滤推荐算法对用户进行评分预测</h4><ul><li><p>数据集：<img src="/./img/%E7%A8%A0%E5%AF%86%E8%AF%84%E5%88%86%E6%95%B0%E6%8D%AE%E9%9B%86.png"></p><p><strong>目的：预测用户1对物品E的评分</strong></p></li><li><p>构建数据集：注意这里构建评分数据时，对于缺失的部分我们需要保留为None，如果设置为0那么会被当作评分值为0去对待</p><pre><code class="python">users = ["User1", "User2", "User3", "User4", "User5"]items = ["Item A", "Item B", "Item C", "Item D", "Item E"]# 用户购买记录数据集datasets = [    [5,3,4,4,None],    [3,1,2,3,3],    [4,3,4,3,5],    [3,3,1,5,4],    [1,5,5,2,1],]</code></pre></li><li><p>计算相似度：对于评分数据这里我们采用皮尔逊相关系数[-1,1]来计算，-1表示强负相关，+1表示强正相关</p><blockquote><p>pandas中corr方法可直接用于计算皮尔逊相关系数</p></blockquote><pre><code class="python">df = pd.DataFrame(datasets,                  columns=items,                  index=users)print("用户之间的两两相似度：")# 直接计算皮尔逊相关系数# 默认是按列进行计算，因此如果计算用户间的相似度，当前需要进行转置user_similar = df.T.corr()print(user_similar.round(4))print("物品之间的两两相似度：")item_similar = df.corr()print(item_similar.round(4))</code></pre><pre><code># 运行结果：用户之间的两两相似度：        User1   User2   User3   User4   User5User1  1.0000  0.8528  0.7071  0.0000 -0.7921User2  0.8528  1.0000  0.4677  0.4900 -0.9001User3  0.7071  0.4677  1.0000 -0.1612 -0.4666User4  0.0000  0.4900 -0.1612  1.0000 -0.6415User5 -0.7921 -0.9001 -0.4666 -0.6415  1.0000物品之间的两两相似度：        Item A  Item B  Item C  Item D  Item EItem A  1.0000 -0.4767 -0.1231  0.5322  0.9695Item B -0.4767  1.0000  0.6455 -0.3101 -0.4781Item C -0.1231  0.6455  1.0000 -0.7206 -0.4276Item D  0.5322 -0.3101 -0.7206  1.0000  0.5817Item E  0.9695 -0.4781 -0.4276  0.5817  1.0000</code></pre><p>可以看到与用户1最相似的是用户2和用户3；与物品A最相似的物品分别是物品E和物品D。</p><p><strong>注意：</strong>我们在预测评分时，往往是通过与其有正相关的用户或物品进行预测，如果不存在正相关的情况，那么将无法做出预测。这一点尤其是在稀疏评分矩阵中尤为常见，因为稀疏评分矩阵中很难得出正相关系数。</p></li><li><p><strong>评分预测：</strong></p><p><strong>User-Based CF 评分预测：使用用户间的相似度进行预测</strong></p><p>关于评分预测的方法也有比较多的方案，下面介绍一种效果比较好的方案，该方案考虑了用户本身的评分评分以及近邻用户的加权平均相似度打分来进行预测：<br>$$<br>pred(u,i)=\hat{r}<em>{ui}=\cfrac{\sum</em>{v\in U}sim(u,v)*r_{vi}}{\sum_{v\in U}|sim(u,v)|}<br>$$<br>我们要预测用户1对物品E的评分，那么可以根据与用户1最近邻的用户2和用户3进行预测，计算如下：</p><p>​<br>$$<br>pred(u_1, i_5) =\cfrac{0.85<em>3+0.71</em>5}{0.85+0.71} = 3.91<br>$$<br><strong>最终预测出用户1对物品5的评分为3.91</strong></p><p><strong>Item-Based CF 评分预测：使用物品间的相似度进行预测</strong></p><p>这里利用物品相似度预测的计算同上，同样考虑了用户自身的平均打分因素，结合预测物品与相似物品的加权平均相似度打分进行来进行预测<br>$$<br>pred(u,i)=\hat{r}<em>{ui}=\cfrac{\sum</em>{j\in I_{rated}}sim(i,j)<em>r_{uj}}{\sum_{j\in I_{rated}}sim(i,j)}<br>$$<br>我们要预测用户1对物品E的评分，那么可以根据与物品E最近邻的物品A和物品D进行预测，用相似度乘以用户1分别对物品A和物品D的评分，也就是5和4，计算如下：<br>$$<br>pred(u_1, i_5) = \cfrac {0.97</em>5+0.58*4}{0.97+0.58} = 4.63<br>$$<br>对比可见，User-Based CF预测评分和Item-Based CF的评分结果也是存在差异的，因为严格意义上他们其实应当属于两种不同的推荐算法，各自在不同的领域不同场景下，都会比另一种的效果更佳，但具体哪一种更佳，必须经过合理的效果评估，因此在实现推荐系统时这两种算法往往都是需要去实现的，然后对产生的推荐效果进行评估分析选出更优方案。</p><p>假如有几万种商品，而大部分商品用户都没有购买过怎么办？</p></li></ul><h3 id="基于模型的方法"><a href="#基于模型的方法" class="headerlink" title="基于模型的方法"></a>基于模型的方法</h3><ul><li><p>思想</p><ul><li>通过机器学习算法，在数据中找出模式，并将用户与物品间的互动方式模式化</li><li>基于模型的协同过滤方式是构建协同过滤更高级的算法</li></ul></li><li><p>近邻模型的问题</p><ul><li>物品之间存在相关性, 信息量并不随着向量维度增加而线性增加</li><li>矩阵元素稀疏, 计算结果不稳定,增减一个向量维度, 导致近邻结果差异很大的情况存在</li></ul></li><li><p>算法分类</p><ul><li>基于图的模型</li><li><strong>基于矩阵分解的方法</strong>（可以应用于稀疏）</li></ul></li><li><p>基于图的模型</p><ul><li>基于邻域的模型看做基于图的模型的简单形式</li></ul><p><img src="/./img/graph1.png"></p><ul><li>原理<ul><li>将用户的行为数据表示为二分图</li><li>基于二分图为用户进行推荐</li><li>根据两个顶点之间的路径数、路径长度和经过的顶点数来评价两个顶点的相关性</li></ul></li></ul></li><li><p>基于矩阵分解的模型</p><ul><li><p>原理</p><ul><li><p>根据用户与物品的潜在表现，我们就可以预测用户对未评分的物品的喜爱程度</p></li><li><p>把原来的大矩阵, 近似分解成两个小矩阵的乘积, 在实际推荐计算时不再使用大矩阵, 而是使用分解得到的两个小矩阵  </p></li><li><p>用户-物品评分矩阵A是M X N维, 即一共有M个用户, n个物品 我们选一个很小的数 K (K&lt;&lt; M, K&lt;&lt;N)<br><strong>K可以理解成会影响到用户对物品评分的特征</strong>，如果有30个特征会影响到，至少为30</p></li><li><p>通过计算得到两个矩阵U V  U是M * K矩阵 , 矩阵V是 N * K</p><p>$U_{m<em>k} V^{T}_{n</em>k} 约等于 A_{m*n}$</p><p>类似这样的计算过程就是矩阵分解</p></li></ul></li><li><p>基于矩阵分解的方法</p><ul><li>ALS交替最小二乘<ul><li>ALS-WR(加权正则化交替最小二乘法): alternating-least-squares with weighted-λ –regularization</li><li>将用户(user)对商品(item)的评分矩阵分解为两个矩阵：一个是用户对商品隐含特征的偏好矩阵，另一个是商品所包含的隐含特征的矩阵。<strong>在这个矩阵分解的过程中，评分缺失项得到了填充</strong>，也就是说我们可以基于这个填充的评分来给用户做商品推荐了。</li></ul></li><li>SVD奇异值分解矩阵</li></ul></li></ul></li><li><p>ALS方法</p><p><img src="/./img/als1.png"></p><ul><li><p>怎么去算，后面我们有实例</p></li><li><p>ALS的矩阵分解算法常应用于推荐系统中，将用户(user)对商品(item)的评分矩阵，分解为用户对商品隐含特征的偏好矩阵，和商品在隐含特征上的映射矩阵。</p></li><li><p>与传统的矩阵分解SVD方法来分解矩阵R(R∈ℝm×n)不同的是，ALS(alternating least squares)希望找到两个低维矩阵，以 R̃ =XY 来逼近矩阵R，其中 ，X∈ℝm×d，Y∈ℝd×n，这样，将问题的复杂度由O(m*n)转换为O((m+n)*d)。</p></li><li><p>计算X和Y过程：首先用一个小于1的随机数初始化Y，并根据公式求X，此时就可以得到初始的XY矩阵了，根据平方差和得到的X，重新计算并覆盖Y，计算差平方和，反复进行以上两步的计算，直到差平方和小于一个预设的数，或者迭代次数满足要求则停止</p><p>怎么做预测，从M*K矩阵中抽出一个用户，也就是一行，再去K*N矩阵中拿出1列，想乘就得到了一个评分</p></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;推荐算法&quot;&gt;&lt;a href=&quot;#推荐算法&quot; class=&quot;headerlink&quot; title=&quot;推荐算法&quot;&gt;&lt;/a&gt;推荐算法&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;推荐模型构建流程&lt;/li&gt;
&lt;li&gt;推荐算法概述&lt;/li&gt;
&lt;li&gt;基于协同过滤的推荐算法&lt;/li&gt;
&lt;li&gt;协</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/03_%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0/"/>
    <id>http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/03_%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0/</id>
    <published>2023-02-13T05:36:26.119Z</published>
    <updated>2023-02-05T04:31:46.919Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二-推荐系统评估"><a href="#二-推荐系统评估" class="headerlink" title="二 推荐系统评估"></a>二 推荐系统评估</h2><ul><li>好的推荐系统可以实现用户, 服务提供方, 内容提供方的共赢</li></ul><p><img src="/./img/recommend2.png"></p><ul><li><p>显示反馈和隐式反馈</p><table>  <tbody><tr>    <th></th>    <th>显式反馈</th>    <th>隐式反馈</th>  </tr>  <tr> <td> 例子 </td> <td> 电影/书籍评分  是否喜欢这个推荐 </td> <td> 播放/点击 评论 下载 购买 </td>  </tr>  <tr>    <td> 准确性 </td>    <td> 高 </td>    <td> 低 </td>  </tr>  <tr>    <td> 数量 </td>    <td> 少 </td>    <td> 多 </td>  </tr>  <tr>    <td> 获取成本 </td>    <td> 高 </td>    <td> 低 </td>  </tr></tbody></table></li><li><p>常用评估指标</p><p>• 准确性  • 信任度<br>• 满意度  • 实时性<br>• 覆盖率  • 鲁棒性<br>• 多样性  • 可扩展性<br>• 新颖性  • 商业⽬标<br>• 惊喜度  • ⽤户留存</p><ul><li>准确性 (理论角度) Netflix 美国录像带租赁<ul><li>评分预测<ul><li>RMSE   MAE  点击率预估 精准率</li></ul></li><li>topN推荐<ul><li>召回率 精准率</li></ul></li></ul></li><li>准确性 (业务角度)</li></ul><p><img src="/./img/recommend3.png"></p><ul><li>覆盖度<ul><li>信息熵 对于推荐越大越好，覆盖的商品越多</li><li>覆盖率</li></ul></li><li>多样性&amp;新颖性&amp;惊喜性<ul><li>多样性：推荐列表中两两物品的不相似性。（相似性如何度量？</li><li>新颖性：未曾关注的类别、作者；推荐结果的平均流⾏度</li><li>惊喜性：历史不相似（惊）但很满意（喜）</li><li>往往需要牺牲准确性</li><li>使⽤历史⾏为预测⽤户对某个物品的喜爱程度</li><li>系统过度强调实时性</li></ul></li><li>Exploitation &amp; Exploration 探索与利用问题<ul><li>Exploitation(开发 利用)：选择现在可能最佳的⽅案</li><li>Exploration(探测 搜索)：选择现在不确定的⼀些⽅案，但未来可能会有⾼收益的⽅案</li><li>在做两类决策的过程中，不断更新对所有决策的不确定性的认知，优化<br>长期的⽬标</li></ul></li><li>EE问题实践<ul><li>兴趣扩展: 相似话题, 搭配推荐</li><li>人群算法: userCF 用户聚类</li><li>平衡个性化推荐和热门推荐比例</li><li>随机丢弃用户行为历史</li><li>随机扰动模型参数</li></ul></li><li>EE可能带来的问题<ul><li>探索伤害用户体验, 可能导致用户流失</li><li>探索带来的长期收益(留存率)评估周期长, KPI压力大</li><li>如何平衡实时兴趣和长期兴趣</li><li>如何平衡短期产品体验和长期系统生态</li><li>如何平衡大众口味和小众需求</li></ul></li><li>评估方法<ul><li>问卷调查: 成本高</li><li>离线评估:<ul><li>只能在用户看到过的候选集上做评估, 且跟线上真实效果存在偏差</li><li>只能评估少数指标</li><li>速度快, 不损害用户体验</li></ul></li><li>在线评估: 灰度发布 &amp; A/B测试 50% 全量上线</li><li>实践: 离线评估和在线评估结合, 定期做问卷调查</li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二-推荐系统评估&quot;&gt;&lt;a href=&quot;#二-推荐系统评估&quot; class=&quot;headerlink&quot; title=&quot;二 推荐系统评估&quot;&gt;&lt;/a&gt;二 推荐系统评估&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;好的推荐系统可以实现用户, 服务提供方, 内容提供方的共赢&lt;/li&gt;
&lt;/ul&gt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/02_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    <id>http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/02_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</id>
    <published>2023-02-13T05:36:26.118Z</published>
    <updated>2023-02-03T12:24:44.106Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二-推荐系统设计"><a href="#二-推荐系统设计" class="headerlink" title="二 推荐系统设计"></a>二 推荐系统设计</h2><h3 id="2-1-推荐系统要素"><a href="#2-1-推荐系统要素" class="headerlink" title="2.1 推荐系统要素"></a>2.1 推荐系统要素</h3><ul><li>UI 和 UE(前端界面)</li><li>数据 (Lambda架构)</li><li>业务知识</li><li>算法</li></ul><h3 id="2-2-推荐系统架构"><a href="#2-2-推荐系统架构" class="headerlink" title="2.2 推荐系统架构"></a>2.2 推荐系统架构</h3><ul><li><p>推荐系统整体架构</p><p><img src="/./img/%E6%8E%A8%E8%8D%90%E6%B5%81%E7%A8%8B.png"></p></li><li><p>大数据Lambda架构</p><ul><li><p>由Twitter工程师Nathan Marz(storm项目发起人)提出</p></li><li><p>Lambda系统架构提供了一个结合实时数据和Hadoop预先计算的数据环境和混合平台, 提供一个实时的数据视图</p></li><li><p>分层架构</p><ul><li>批处理层<ul><li>数据不可变, 可进行任何计算, 可水平扩展</li><li>高延迟  几分钟~几小时(计算量和数据量不同)</li><li>日志收集 Flume</li><li>分布式存储 Hadoop hdfs</li><li>分布式计算 Hadoop MapReduce &amp; spark</li><li>视图存储数据库<ul><li>nosql(HBase/Cassandra)</li><li>Redis/memcache</li><li>MySQL</li></ul></li></ul></li><li>实时处理层<ul><li>流式处理, 持续计算</li><li>存储和分析某个窗口期内的数据</li><li>最终正确性(Eventual accuracy)</li><li>实时数据收集 flume &amp; kafka</li><li>实时数据分析  spark streaming/storm/flink</li></ul></li><li>服务层<ul><li>支持随机读</li><li>需要在非常短的时间内返回结果</li><li>读取批处理层和实时处理层结果并对其归并</li></ul></li></ul></li><li><p>Lambda架构图<br><img src="/./img/lambda3.png"></p></li></ul></li><li><p>推荐算法架构</p><ul><li>召回阶段(海选)<ul><li>召回决定了最终推荐结果的天花板</li><li>常用算法:<ul><li>协同过滤(基于用户 基于物品的)</li><li>基于内容 (根据用户行为总结出自己的偏好 根据偏好 通过文本挖掘技术找到内容上相似的商品)</li><li>基于隐语义</li></ul></li></ul></li><li>排序阶段<ul><li>召回决定了最终推荐结果的天花板, 排序逼近这个极限, 决定了最终的推荐效果</li><li>CTR预估 (点击率预估 使用LR算法)  估计用户是否会点击某个商品 需要用户的点击数据</li></ul></li><li>策略调整</li></ul></li></ul><p><img src="/./img/recommend7.jpeg"></p><ul><li><p>推荐系统的整体架构</p><p><img src="/./img/rs%E5%9F%BA%E7%A1%80%E4%B8%9A%E5%8A%A1%E6%9E%B6%E6%9E%84.png"></p><p><img src="/./img/rs%E5%9F%BA%E7%A1%80%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84.png"></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二-推荐系统设计&quot;&gt;&lt;a href=&quot;#二-推荐系统设计&quot; class=&quot;headerlink&quot; title=&quot;二 推荐系统设计&quot;&gt;&lt;/a&gt;二 推荐系统设计&lt;/h2&gt;&lt;h3 id=&quot;2-1-推荐系统要素&quot;&gt;&lt;a href=&quot;#2-1-推荐系统要素&quot; class=&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B/"/>
    <id>http://example.com/2023/02/13/day59/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B/</id>
    <published>2023-02-13T05:36:26.116Z</published>
    <updated>2021-08-06T04:03:16.626Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一-推荐系统简介"><a href="#一-推荐系统简介" class="headerlink" title="一 推荐系统简介"></a>一 推荐系统简介</h2><p>​        个性化推荐(推荐系统)经历了多年的发展，已经成为互联网产品的标配，也是AI成功落地的分支之一，在电商(淘宝/京东)、资讯(今日头条/微博)、音乐(网易云音乐/QQ音乐)、短视频(抖音/快手)等热门应用中,推荐系统都是核心组件之一。</p><ul><li><p>推荐系统产生背景</p><ul><li>信息过载 &amp; 用户需求不明确<ul><li>分类⽬录（1990s）：覆盖少量热门⽹站。Hao123 Yahoo</li><li>搜索引擎（2000s）：通过搜索词明确需求。Google Baidu</li><li>推荐系统（2010s）：不需要⽤户提供明确的需求，通过分析⽤<br>户的历史⾏为给⽤户的兴趣进⾏建模，从⽽主动给⽤户推荐能<br>够满⾜他们兴趣和需求的信息。</li></ul></li></ul></li><li><p>什么是推荐系统</p><ul><li>没有明确需求的用户访问了我们的服务, 且服务的物品对用户构成了信息过载, 系统通过一定的规则对物品进行排序,并将排在前面的物品展示给用户,这样的系统就是推荐系统</li></ul></li><li><p>推荐系统 V.S. 搜索引擎</p><table>  <tbody><tr>    <th></th>    <th>搜索</th>    <th>推荐</th>  </tr>  <tr>    <td> 行为方式 </td>    <td> 主动 </td>    <td> 被动 </td>  </tr>  <tr>    <td> 意图 </td>    <td> 明确 </td>    <td> 模糊 </td>  </tr>  <tr>    <td> 个性化 </td>    <td> 弱 </td>    <td> 强 </td>  </tr>  <tr>    <td> 流量分布 </td>    <td> 马太效应 </td>    <td> 长尾效应 </td>  </tr>  <tr>    <td> 目标 </td>    <td> 快速满足  </td>    <td> 持续服务 </td>  </tr>  <tr>    <td> 评估指标 </td>    <td> 简明 </td>    <td> 复杂 </td>  </tr></tbody></table></li><li><p>推荐系统的作用</p><ul><li>高效连接用户和物品, 发现长尾商品</li><li>留住用户和内容生产者, 实现商业目标</li></ul></li><li><p>推荐系统的工作原理</p><ul><li><strong>社会化推荐</strong> 向朋友咨询, 社会化推荐, 让好友给自己推荐物品</li><li><strong>基于内容的推荐</strong> 打开搜索引擎, 输入自己喜欢的演员的名字, 然后看看返回结果中还有什么电影是自己没看过的</li><li><strong>基于流行度的推荐</strong> 查看票房排行榜, </li><li><strong>基于协同过滤的推荐</strong> 找到和自己历史兴趣相似的用户, 看看他们最近在看什么电影</li></ul></li><li><p>推荐系统的应用场景 feed 流 信息流 </p><p><img src="/./img/recommend1.png"></p></li><li><p>推荐系统和Web项目的区别</p><ul><li>稳定的信息流通系统 V.S. 通过信息过滤实现目标提升 <ul><li>web项目: 处理复杂逻辑 处理高并发 实现高可用 为用户提供稳定服务, 构建一个稳定的信息流通的服务</li><li>推荐系统: 追求指标增长, 留存率/阅读时间/GMV (Gross Merchandise Volume电商网站成交金额)/视频网站VV (Video View)</li></ul></li><li>确定 V.S. 不确定思维<ul><li>web项目: 对结果有确定预期</li><li>推荐系统: 结果是概率问题</li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一-推荐系统简介&quot;&gt;&lt;a href=&quot;#一-推荐系统简介&quot; class=&quot;headerlink&quot; title=&quot;一 推荐系统简介&quot;&gt;&lt;/a&gt;一 推荐系统简介&lt;/h2&gt;&lt;p&gt;​        个性化推荐(推荐系统)经历了多年的发展，已经成为互联网产品的标配，也是AI</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/day1_%E8%AF%BE%E5%A0%82%E7%BA%AA%E8%A6%81/"/>
    <id>http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/day1_%E8%AF%BE%E5%A0%82%E7%BA%AA%E8%A6%81/</id>
    <published>2023-02-13T05:36:25.634Z</published>
    <updated>2021-03-07T14:38:33.601Z</updated>
    
    <content type="html"><![CDATA[<p>7天 基础</p><ul><li>推荐系统相关概念 基本算法</li><li>推荐算法<ul><li>原生python 实现推荐算法</li></ul></li><li>lambda架构 5天<ul><li>hadoop</li><li>hive hbase</li><li>spark core</li><li>spark sql spark streaming</li><li>案例 基于电商用户行为</li></ul></li></ul><p>7天 项目</p><h3 id="推荐概念"><a href="#推荐概念" class="headerlink" title="推荐概念"></a>推荐概念</h3><ul><li>信息过滤系统 解决 信息过载 用户需求不明确的问题<ul><li>利用一定的规则将物品排序 展示给需求不明确的用户</li></ul></li><li>推荐 搜索区别<ul><li>推荐个性化较强，用户被动的接受，希望能够提供持续的服务</li><li>搜索个性化弱，用户主动搜索，快速满足用户的需求</li></ul></li><li>推荐和 web项目区别<ul><li>构建稳定的信息流通通道</li><li>推荐 信息过滤系统</li><li>web 对结果有明确预期</li><li>推荐 结果是概率问题</li></ul></li></ul><h3 id="Lambda-架构介绍"><a href="#Lambda-架构介绍" class="headerlink" title="Lambda 架构介绍"></a>Lambda 架构介绍</h3><ul><li>离线计算和实时计算共同提供服务的问题</li><li>离线计算优缺点<ul><li>优点 能够处理的数据量可以很大 比如pb级别</li><li>缺点 速度比较慢 分钟级别的延迟</li></ul></li><li>实时计算<ul><li>优点 响应快 来一条数据处理一条 ms级别响应</li><li>缺点 处理的数据量小一些</li></ul></li><li>离线计算的框架<ul><li>hadoop hdfs mapreduce</li><li>spark core , spark sql</li><li>hive</li></ul></li><li>实时计算框架<ul><li>spark streaming</li><li>storm</li><li>flink</li></ul></li><li>消息中间件<ul><li>flume 日志采集系统</li><li>kafka 消息队列</li></ul></li><li>存储相关<ul><li>hbase nosql数据库</li><li>hive  sql操作hdfs数据</li></ul></li></ul><h3 id="推荐算法架构"><a href="#推荐算法架构" class="headerlink" title="推荐算法架构"></a>推荐算法架构</h3><ul><li><p>召回</p><ul><li><p>协同过滤  算相似度 memory base</p><p>​                  基于模型的 model base  矩阵分解</p></li><li><p>基于内容</p><ul><li>分词</li><li>词权重（提取关键词） tf-idf</li><li>word2Vec 词向量</li><li>物品向量</li></ul></li></ul></li><li><p>排序</p><ul><li>逻辑回归</li></ul></li><li><p>策略调整</p></li></ul><h3 id="推荐模型构建流程"><a href="#推荐模型构建流程" class="headerlink" title="推荐模型构建流程"></a>推荐模型构建流程</h3><ul><li><p>数据收集</p><ul><li>显性评分</li><li>隐性数据</li></ul></li><li><p>特征工程</p><ul><li>协同过滤：用户-物品 评分矩阵</li><li>基于内容：分词 tf-idf word2Vec</li></ul></li><li><p>训练模型</p><ul><li>协同过滤<ul><li>kNN</li><li>矩阵分解 梯度下降 ALS</li></ul></li></ul></li><li><p>评估、模型上线</p></li></ul><h3 id="协同过滤思路介绍"><a href="#协同过滤思路介绍" class="headerlink" title="协同过滤思路介绍"></a>协同过滤思路介绍</h3><ul><li>CF 物以类聚人以群分</li><li>做协同过滤的话 首先特征工程把 用户-物品的评分矩阵创建出来</li><li>基于用户的协同过滤<ul><li>给用户A 找到最相似的N个用户</li><li>N个用户消费过哪些物品</li><li>N个用户消费过的物品中-A用户消费过的就是推荐结果</li></ul></li><li>基于物品的协同过滤<ul><li>给物品A 找到最相似的N个物品</li><li>A用户消费记录 找到这些物品的相似物品</li><li>从这些相似物品先去重-A用户消费过的就是推荐结果</li></ul></li></ul><h3 id="相似度计算"><a href="#相似度计算" class="headerlink" title="相似度计算"></a>相似度计算</h3><ul><li>余弦相似度、皮尔逊相关系数<ul><li>向量的夹角余弦值</li><li>皮尔逊会对向量的每一个分量做中心化</li><li>余弦只考虑方向 不考虑向量长度</li><li>如果评分数据是连续的数值比较适合中余弦、皮尔逊计算相似度</li></ul></li><li>杰卡德相似度<ul><li>交集/并集</li><li>计算评分是0 1 布尔值的相似度</li></ul></li></ul><h3 id="使用不同相似度计算方式实现协同过滤"><a href="#使用不同相似度计算方式实现协同过滤" class="headerlink" title="使用不同相似度计算方式实现协同过滤"></a>使用不同相似度计算方式实现协同过滤</h3><ul><li><p>如果 买/没买 点/没点数据 0/1 适合使用杰卡德相似度</p><ul><li>from sklearn.metrics import jaccard_similarity_score</li><li>jaccard_similarity_score(df[‘Item A’],df[‘Item B’])</li><li>from sklearn.metrics.pairwise import pairwise_distances</li><li>user_similar = 1-pairwise_distances(df,metric=’jaccard’)</li></ul></li><li><p>一般用评分去做协同过滤 推荐使用皮尔逊相关系数</p><ul><li><p>评分预测</p></li><li><p>$$<br> pred(u,i)=\hat{r}<em>{ui}=\cfrac{\sum</em>{v\in U}sim(u,v)*r_{vi}}{\sum_{v\in U}|sim(u,v)|}<br>$$</p></li></ul></li><li><p>基于用户和基于物品的协同过滤 严格上说，属于两种算法，实践中可以都做出来，对比效果，选择最靠谱的</p></li></ul><h3 id="协同过滤-基于模型的算法"><a href="#协同过滤-基于模型的算法" class="headerlink" title="协同过滤 基于模型的算法"></a>协同过滤 基于模型的算法</h3><ul><li>用户-物品矩阵比较稀疏的时候 直接去取物品向量 用户向量计算相似度 不太适合</li><li>基于模型的方法可以解决用户-物品矩阵比较稀疏的问题</li><li>矩阵分解<ul><li>把大的矩阵拆成两个小的 用户矩阵 物品矩阵  MXN 大矩阵   M X K    K X N  K&lt;&lt;M  k&lt;&lt;N</li><li>大矩阵 约等于 用户矩阵 乘 物品矩阵</li><li>使用als 交替最小二乘法来优化损失 spark ML  recommandation 包封装了als</li><li>优化之后的用户矩阵  取出用户向量</li><li>优化之后的物品矩阵  取出物品向量</li><li>用户向量点乘物品向量 得到最终评分的预测</li></ul></li></ul><h3 id="推荐系统的评价"><a href="#推荐系统的评价" class="headerlink" title="推荐系统的评价"></a>推荐系统的评价</h3><ul><li><p>准确率 覆盖率</p><ul><li>准确率<ul><li>学术  rmse mas   点击率预估 精准率</li><li>工程  A/B test 对比不同的算法 在线上运行对关键指标的影响 <ul><li>baseline 基准线 热门排行  </li><li>灰度发布</li></ul></li></ul></li></ul></li><li><p>EE</p><ul><li>Exploitation &amp; Exploration 探索与利用问题</li><li>Exploitation 利用用户的历史行为 只给他曾经看过的/消费过的相似物品</li><li>Exploration(探测 搜索) 发现用户的新兴趣</li><li>ee问题 实际上是矛盾</li></ul></li><li><p>评估手段</p><ul><li>离线评估和在线评估结合, 定期做问卷调查<ul><li>在线评估<ul><li>灰度发布 &amp; A/B测试</li></ul></li></ul></li></ul></li></ul><h3 id="推荐系统的冷启动"><a href="#推荐系统的冷启动" class="headerlink" title="推荐系统的冷启动"></a>推荐系统的冷启动</h3><ul><li>用户冷启动<ul><li>尽可能收集用户信息 构建用户画像（打标签）</li><li>根据用户的标签可以做人群聚类 用以有用户的行为做推荐</li><li>更多的使用流行度推荐</li></ul></li><li>物品冷启动<ul><li>物品打标签 构建物品画像</li><li>基于内容的推荐</li></ul></li><li>系统冷启动<ul><li>如果应用缺少用户行为数据-&gt;基于内容的推荐</li><li>随着用户行为积累的越来越多-&gt;协同过滤</li><li>基于内容和协同过滤共同工作</li></ul></li></ul><h3 id="基于内容的推荐"><a href="#基于内容的推荐" class="headerlink" title="基于内容的推荐"></a>基于内容的推荐</h3><ul><li>给物品打标签<ul><li>系统自己提取从业务数据库中提取（商品的标题副标题等）</li><li>用户填写</li><li>中文分词 利用算法计算词的权重 <ul><li>tf-idf  tf term frequency 词频  5/100 *2 <ul><li>idf 逆文档频率 log 10   文本库篇数/出现关键词的文章篇数</li><li>1000 10python  1000/10 100   2</li><li>1000/1000 log(1) = 0</li></ul></li><li>textrank</li></ul></li></ul></li><li>利用标签的文字 转换成词向量<ul><li>word2Vec 词-&gt;向量</li><li>用向量来表示语义</li><li>如果两个词的词向量相似度比较高 认为这两个词的语义相近</li></ul></li><li>利用词向量 构建物品的向量<ul><li>一个物品有N个关键词 每一个关键词对应一个词向量</li><li>求和（权重*词向量）/N</li><li>利用N个关键词的词向量获取物品向量</li></ul></li><li>通过物品向量计算相似度<ul><li>皮尔逊 相关系数 计算物品向量的相似度</li></ul></li></ul><h3 id="基于内容的推荐-基于物品的协同过滤-区别"><a href="#基于内容的推荐-基于物品的协同过滤-区别" class="headerlink" title="基于内容的推荐 基于物品的协同过滤 区别"></a>基于内容的推荐 基于物品的协同过滤 区别</h3><ul><li>content_base ：词向量-&gt;物品向量-&gt;计算相似度</li><li>item_based cf :user-item matrix-&gt;物品向量-&gt;相似度</li><li>content_base  item_based cf 不一样<ul><li>物品向量构建过程有区别</li><li>基于内容的推荐<ul><li>物品向量 文本（物品描述信息，系统填标签，用户填标签）</li></ul></li><li>基于物品的协同过滤<ul><li>用户对物品的评分矩阵 用户的行为数据中来</li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;7天 基础&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;推荐系统相关概念 基本算法&lt;/li&gt;
&lt;li&gt;推荐算法&lt;ul&gt;
&lt;li&gt;原生python 实现推荐算法&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;lambda架构 5天&lt;ul&gt;
&lt;li&gt;hadoop&lt;/li&gt;
&lt;li&gt;hive hbas</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/08_%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%EF%BC%9AItem-Based%20CF%20%E9%A2%84%E6%B5%8B%E8%AF%84%E5%88%86/"/>
    <id>http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/08_%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%EF%BC%9AItem-Based%20CF%20%E9%A2%84%E6%B5%8B%E8%AF%84%E5%88%86/</id>
    <published>2023-02-13T05:36:25.632Z</published>
    <updated>2021-03-07T14:38:33.471Z</updated>
    
    <content type="html"><![CDATA[<h2 id="案例–算法实现：Item-Based-CF-预测评分"><a href="#案例–算法实现：Item-Based-CF-预测评分" class="headerlink" title="案例–算法实现：Item-Based CF 预测评分"></a>案例–算法实现：Item-Based CF 预测评分</h2><p><strong>评分预测公式：</strong><br>$$<br>pred(u,i)=\hat{r}<em>{ui}=\cfrac{\sum</em>{j\in I_{rated}}sim(i,j)*r_{uj}}{\sum_{j\in I_{rated}}sim(i,j)}<br>$$</p><h4 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h4><ul><li><p>实现评分预测方法：<code>predict</code></p><ul><li><p>方法说明：</p><p>利用原始评分矩阵、以及物品间两两相似度，预测指定用户对指定物品的评分。</p><p>如果无法预测，则抛出异常</p></li></ul><pre><code class="python"># ......def predict(uid, iid, ratings_matrix, item_similar):    '''    预测给定用户对给定物品的评分值    :param uid: 用户ID    :param iid: 物品ID    :param ratings_matrix: 用户-物品评分矩阵    :param item_similar: 物品两两相似度矩阵    :return: 预测的评分值    '''    print("开始预测用户&lt;%d&gt;对电影&lt;%d&gt;的评分..."%(uid, iid))    # 1. 找出iid物品的相似物品    similar_items = item_similar[iid].drop([iid]).dropna()    # 相似物品筛选规则：正相关的物品    similar_items = similar_items.where(similar_items&gt;0).dropna()    if similar_items.empty is True:        raise Exception("物品&lt;%d&gt;没有相似的物品" %id)    # 2. 从iid物品的近邻相似物品中筛选出uid用户评分过的物品    ids = set(ratings_matrix.loc[uid].dropna().index)&amp;set(similar_items.index)    finally_similar_items = similar_items.loc[list(ids)]    # 3. 结合iid物品与其相似物品的相似度和uid用户对其相似物品的评分，预测uid对iid的评分    sum_up = 0    # 评分预测公式的分子部分的值    sum_down = 0    # 评分预测公式的分母部分的值    for sim_iid, similarity in finally_similar_items.iteritems():        # 近邻物品的评分数据        sim_item_rated_movies = ratings_matrix[sim_iid].dropna()        # uid用户对相似物品物品的评分        sim_item_rating_from_user = sim_item_rated_movies[uid]        # 计算分子的值        sum_up += similarity * sim_item_rating_from_user        # 计算分母的值        sum_down += similarity    # 计算预测的评分值并返回    predict_rating = sum_up/sum_down    print("预测出用户&lt;%d&gt;对电影&lt;%d&gt;的评分：%0.2f" % (uid, iid, predict_rating))    return round(predict_rating, 2)if __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    item_similar = compute_pearson_similarity(ratings_matrix, based="item")    # 预测用户1对物品1的评分    predict(1, 1, ratings_matrix, item_similar)    # 预测用户1对物品2的评分    predict(1, 2, ratings_matrix, item_similar)</code></pre></li><li><p>实现预测全部评分方法：<code>predict_all</code></p><pre><code class="python"># ......def predict_all(uid, ratings_matrix, item_similar):    '''    预测全部评分    :param uid: 用户id    :param ratings_matrix: 用户-物品打分矩阵    :param item_similar: 物品两两间的相似度    :return: 生成器，逐个返回预测评分    '''    # 准备要预测的物品的id列表    item_ids = ratings_matrix.columns    # 逐个预测    for iid in item_ids:        try:            rating = predict(uid, iid, ratings_matrix, item_similar)        except Exception as e:            print(e)        else:            yield uid, iid, ratingif __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    item_similar = compute_pearson_similarity(ratings_matrix, based="item")    for i in predict_all(1, ratings_matrix, item_similar):        pass</code></pre></li><li><p>添加过滤规则</p><pre><code class="python">def _predict_all(uid, item_ids,ratings_matrix, item_similar):    '''    预测全部评分    :param uid: 用户id    :param item_ids: 要预测物品id列表    :param ratings_matrix: 用户-物品打分矩阵    :param item_similar: 物品两两间的相似度    :return: 生成器，逐个返回预测评分    '''    # 逐个预测    for iid in item_ids:        try:            rating = predict(uid, iid, ratings_matrix, item_similar)        except Exception as e:            print(e)        else:            yield uid, iid, ratingdef predict_all(uid, ratings_matrix, item_similar, filter_rule=None):    '''    预测全部评分，并可根据条件进行前置过滤    :param uid: 用户ID    :param ratings_matrix: 用户-物品打分矩阵    :param item_similar: 物品两两间的相似度    :param filter_rule: 过滤规则，只能是四选一，否则将抛异常："unhot","rated",["unhot","rated"],None    :return: 生成器，逐个返回预测评分    '''    if not filter_rule:        item_ids = ratings_matrix.columns    elif isinstance(filter_rule, str) and filter_rule == "unhot":        '''过滤非热门电影'''        # 统计每部电影的评分数        count = ratings_matrix.count()        # 过滤出评分数高于10的电影，作为热门电影        item_ids = count.where(count&gt;10).dropna().index    elif isinstance(filter_rule, str) and filter_rule == "rated":        '''过滤用户评分过的电影'''        # 获取用户对所有电影的评分记录        user_ratings = ratings_matrix.loc[uid]        # 评分范围是1-5，小于6的都是评分过的，除此以外的都是没有评分的        _ = user_ratings&lt;6        item_ids = _.where(_==False).dropna().index    elif isinstance(filter_rule, list) and set(filter_rule) == set(["unhot", "rated"]):        '''过滤非热门和用户已经评分过的电影'''        count = ratings_matrix.count()        ids1 = count.where(count &gt; 10).dropna().index        user_ratings = ratings_matrix.loc[uid]        _ = user_ratings &lt; 6        ids2 = _.where(_ == False).dropna().index        # 取二者交集        item_ids = set(ids1)&amp;set(ids2)    else:        raise Exception("无效的过滤参数")    yield from _predict_all(uid, item_ids, ratings_matrix, item_similar)if __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    item_similar = compute_pearson_similarity(ratings_matrix, based="item")    for result in predict_all(1, ratings_matrix, item_similar, filter_rule=["unhot", "rated"]):        print(result)</code></pre></li><li><p>为指定用户推荐TOP-N结果</p><pre><code class="python"># ......def top_k_rs_result(k):    ratings_matrix = load_data(DATA_PATH)    item_similar = compute_pearson_similarity(ratings_matrix, based="item")    results = predict_all(1, ratings_matrix, item_similar, filter_rule=["unhot", "rated"])    return sorted(results, key=lambda x: x[2], reverse=True)[:k]if __name__ == '__main__':    from pprint import pprint    result = top_k_rs_result(20)    pprint(result)</code></pre></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;案例–算法实现：Item-Based-CF-预测评分&quot;&gt;&lt;a href=&quot;#案例–算法实现：Item-Based-CF-预测评分&quot; class=&quot;headerlink&quot; title=&quot;案例–算法实现：Item-Based CF 预测评分&quot;&gt;&lt;/a&gt;案例–算法实现：</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/07_%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%EF%BC%9AUser-Based%20CF%20%E9%A2%84%E6%B5%8B%E8%AF%84%E5%88%86/"/>
    <id>http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/07_%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%EF%BC%9AUser-Based%20CF%20%E9%A2%84%E6%B5%8B%E8%AF%84%E5%88%86/</id>
    <published>2023-02-13T05:36:25.630Z</published>
    <updated>2021-03-07T14:38:33.407Z</updated>
    
    <content type="html"><![CDATA[<h2 id="案例–算法实现：User-Based-CF-预测评分"><a href="#案例–算法实现：User-Based-CF-预测评分" class="headerlink" title="案例–算法实现：User-Based CF 预测评分"></a>案例–算法实现：User-Based CF 预测评分</h2><p><strong>评分预测公式：</strong><br>$$<br>pred(u,i)=\hat{r}<em>{ui}=\cfrac{\sum</em>{v\in U}sim(u,v)*r_{vi}}{\sum_{v\in U}|sim(u,v)|}<br>$$</p><h4 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h4><ul><li><p>实现评分预测方法：<code>predict</code></p><pre><code class="python"># ......def predict(uid, iid, ratings_matrix, user_similar):    '''    预测给定用户对给定物品的评分值    :param uid: 用户ID    :param iid: 物品ID    :param ratings_matrix: 用户-物品评分矩阵    :param user_similar: 用户两两相似度矩阵    :return: 预测的评分值    '''    print("开始预测用户&lt;%d&gt;对电影&lt;%d&gt;的评分..."%(uid, iid))    # 1. 找出uid用户的相似用户    similar_users = user_similar[uid].drop([uid]).dropna()    # 相似用户筛选规则：正相关的用户，负数就抛弃掉    similar_users = similar_users.where(similar_users&gt;0).dropna()    if similar_users.empty is True:        raise Exception("用户&lt;%d&gt;没有相似的用户" % uid)    # 2. 从uid用户的近邻相似用户中筛选出对iid物品有评分记录的近邻用户，也就是消费过iid物品的用户都拿出来    ids = set(ratings_matrix[iid].dropna().index)&amp;set(similar_users.index)    finally_similar_users = similar_users.ix[list(ids)]    # 3. 结合uid用户与其近邻用户的相似度预测uid用户对iid物品的评分    sum_up = 0    # 评分预测公式的分子部分的值    sum_down = 0    # 评分预测公式的分母部分的值    for sim_uid, similarity in finally_similar_users.iteritems():        # 近邻用户的评分数据        sim_user_rated_movies = ratings_matrix.ix[sim_uid].dropna()        # 近邻用户对iid物品的评分        sim_user_rating_for_item = sim_user_rated_movies[iid]        # 计算分子的值        sum_up += similarity * sim_user_rating_for_item        # 计算分母的值        sum_down += similarity    # 计算预测的评分值并返回    predict_rating = sum_up/sum_down    print("预测出用户&lt;%d&gt;对电影&lt;%d&gt;的评分：%0.2f" % (uid, iid, predict_rating))    return round(predict_rating, 2)if __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    user_similar = compute_pearson_similarity(ratings_matrix, based="user")    # 预测用户1对物品1的评分    predict(1, 1, ratings_matrix, user_similar)    # 预测用户1对物品2的评分    predict(1, 2, ratings_matrix, user_similar)</code></pre></li><li><p>实现预测全部评分方法：<code>predict_all</code></p><pre><code class="python"># ......def predict_all(uid, ratings_matrix, user_similar):    '''    预测全部评分    :param uid: 用户id    :param ratings_matrix: 用户-物品打分矩阵    :param user_similar: 用户两两间的相似度    :return: 生成器，逐个返回预测评分    '''    # 准备要预测的物品的id列表    item_ids = ratings_matrix.columns    # 逐个预测    for iid in item_ids:        try:            rating = predict(uid, iid, ratings_matrix, user_similar)        except Exception as e:            print(e)        else:            yield uid, iid, ratingif __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    user_similar = compute_pearson_similarity(ratings_matrix, based="user")    for i in predict_all(1, ratings_matrix, user_similar):        pass</code></pre></li><li><p>添加过滤规则</p><pre><code class="python">def _predict_all(uid, item_ids, ratings_matrix, user_similar):    '''    预测全部评分    :param uid: 用户id    :param item_ids: 要预测的物品id列表    :param ratings_matrix: 用户-物品打分矩阵    :param user_similar: 用户两两间的相似度    :return: 生成器，逐个返回预测评分    '''    # 逐个预测    for iid in item_ids:        try:            rating = predict(uid, iid, ratings_matrix, user_similar)        except Exception as e:            print(e)        else:            yield uid, iid, ratingdef predict_all(uid, ratings_matrix, user_similar, filter_rule=None):    '''    预测全部评分，并可根据条件进行前置过滤    :param uid: 用户ID    :param ratings_matrix: 用户-物品打分矩阵    :param user_similar: 用户两两间的相似度    :param filter_rule: 过滤规则，只能是四选一，否则将抛异常："unhot","rated",["unhot","rated"],None    :return: 生成器，逐个返回预测评分    '''    if not filter_rule:        item_ids = ratings_matrix.columns    elif isinstance(filter_rule, str) and filter_rule == "unhot":        '''过滤非热门电影'''        # 统计每部电影的评分数        count = ratings_matrix.count()        # 过滤出评分数高于10的电影，作为热门电影        item_ids = count.where(count&gt;10).dropna().index    elif isinstance(filter_rule, str) and filter_rule == "rated":        '''过滤用户评分过的电影'''        # 获取用户对所有电影的评分记录        user_ratings = ratings_matrix.loc[uid]        # 评分范围是1-5，小于6的都是评分过的，除此以外的都是没有评分的        _ = user_ratings&lt;6        item_ids = _.where(_==False).dropna().index    elif isinstance(filter_rule, list) and set(filter_rule) == set(["unhot", "rated"]):        '''过滤非热门和用户已经评分过的电影'''        count = ratings_matrix.count()        ids1 = count.where(count &gt; 10).dropna().index        user_ratings = ratings_matrix.loc[uid]        _ = user_ratings &lt; 6        ids2 = _.where(_ == False).dropna().index        # 取二者交集        item_ids = set(ids1)&amp;set(ids2)    else:        raise Exception("无效的过滤参数")    yield from _predict_all(uid, item_ids, ratings_matrix, user_similar)if __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    user_similar = compute_pearson_similarity(ratings_matrix, based="user")    for result in predict_all(1, ratings_matrix, user_similar, filter_rule=["unhot", "rated"]):        print(result)</code></pre></li><li><p>根据预测评分为指定用户进行TOP-N推荐：</p><pre><code class="python"># ......def top_k_rs_result(k):    ratings_matrix = load_data(DATA_PATH)    user_similar = compute_pearson_similarity(ratings_matrix, based="user")    results = predict_all(1, ratings_matrix, user_similar, filter_rule=["unhot", "rated"])    return sorted(results, key=lambda x: x[2], reverse=True)[:k]if __name__ == '__main__':    from pprint import pprint    result = top_k_rs_result(20)    pprint(result)</code></pre></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;案例–算法实现：User-Based-CF-预测评分&quot;&gt;&lt;a href=&quot;#案例–算法实现：User-Based-CF-预测评分&quot; class=&quot;headerlink&quot; title=&quot;案例–算法实现：User-Based CF 预测评分&quot;&gt;&lt;/a&gt;案例–算法实现：</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/06_%E6%A1%88%E4%BE%8B--%E5%9F%BA%E4%BA%8E%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90/"/>
    <id>http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/06_%E6%A1%88%E4%BE%8B--%E5%9F%BA%E4%BA%8E%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%9A%84%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90/</id>
    <published>2023-02-13T05:36:25.619Z</published>
    <updated>2021-03-07T14:38:33.531Z</updated>
    
    <content type="html"><![CDATA[<h2 id="案例–基于协同过滤的电影推荐"><a href="#案例–基于协同过滤的电影推荐" class="headerlink" title="案例–基于协同过滤的电影推荐"></a>案例–基于协同过滤的电影推荐</h2><p>前面我们已经基本掌握了协同过滤推荐算法，以及其中两种最基本的实现方案：User-Based CF和Item-Based CF，下面我们将利用真是的数据来进行实战演练。</p><p>案例需求 演示效果</p><p>分析案例</p><h4 id="数据集下载"><a href="#数据集下载" class="headerlink" title="数据集下载"></a>数据集下载</h4><p><a href="https://grouplens.org/datasets/movielens/latest/">MovieLens Latest Datasets Small</a></p><p>建议下载<a href="http://files.grouplens.org/datasets/movielens/ml-latest-small.zip">ml-latest-small.zip</a>，数据量小，便于我们单机使用和运行</p><p>目标：根据<code>ml-latest-small/ratings.csv</code>（用户-电影评分数据），分别实现User-Based CF和Item-Based CF，并进行电影评分的预测，然后为用户实现电影推荐</p><h4 id="数据集加载"><a href="#数据集加载" class="headerlink" title="数据集加载"></a>数据集加载</h4><ul><li><p>加载ratings.csv，并转换为用户-电影评分矩阵</p><pre><code class="python">import osimport pandas as pdimport numpy as npDATA_PATH = "./datasets/ml-latest-small/ratings.csv"CACHE_DIR = "./datasets/cache/"def load_data(data_path):    '''    加载数据    :param data_path: 数据集路径    :param cache_path: 数据集缓存路径    :return: 用户-物品评分矩阵    '''    # 数据集缓存地址    cache_path = os.path.join(CACHE_DIR, "ratings_matrix.cache")    print("开始加载数据集...")    if os.path.exists(cache_path):    # 判断是否存在缓存文件        print("加载缓存中...")        ratings_matrix = pd.read_pickle(cache_path)        print("从缓存加载数据集完毕")    else:        print("加载新数据中...")        # 设置要加载的数据字段的类型        dtype = {"userId": np.int32, "movieId": np.int32, "rating": np.float32}        # 加载数据，我们只用前三列数据，分别是用户ID，电影ID，已经用户对电影的对应评分        ratings = pd.read_csv(data_path, dtype=dtype, usecols=range(3))        # 透视表，将电影ID转换为列名称，转换成为一个User-Movie的评分矩阵        ratings_matrix = ratings.pivot_table(index=["userId"], columns=["movieId"], values="rating")        # 存入缓存文件        ratings_matrix.to_pickle(cache_path)        print("数据集加载完毕")    return  ratings_matrixif __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    print(ratings_matrix)</code></pre></li></ul><h4 id="相似度计算"><a href="#相似度计算" class="headerlink" title="相似度计算"></a>相似度计算</h4><ul><li><p>计算用户或物品两两相似度：</p><pre><code class="python"># ......def compute_pearson_similarity(ratings_matrix, based="user"):    '''    计算皮尔逊相关系数    :param ratings_matrix: 用户-物品评分矩阵    :param based: "user" or "item"    :return: 相似度矩阵    '''    user_similarity_cache_path = os.path.join(CACHE_DIR, "user_similarity.cache")    item_similarity_cache_path = os.path.join(CACHE_DIR, "item_similarity.cache")    # 基于皮尔逊相关系数计算相似度    # 用户相似度    if based == "user":        if os.path.exists(user_similarity_cache_path):            print("正从缓存加载用户相似度矩阵")            similarity = pd.read_pickle(user_similarity_cache_path)        else:            print("开始计算用户相似度矩阵")            similarity = ratings_matrix.T.corr()            similarity.to_pickle(user_similarity_cache_path)    elif based == "item":        if os.path.exists(item_similarity_cache_path):            print("正从缓存加载物品相似度矩阵")            similarity = pd.read_pickle(item_similarity_cache_path)        else:            print("开始计算物品相似度矩阵")            similarity = ratings_matrix.corr()            similarity.to_pickle(item_similarity_cache_path)    else:        raise Exception("Unhandled 'based' Value: %s"%based)    print("相似度矩阵计算/加载完毕")    return similarityif __name__ == '__main__':    ratings_matrix = load_data(DATA_PATH)    user_similar = compute_pearson_similarity(ratings_matrix, based="user")    print(user_similar)    item_similar = compute_pearson_similarity(ratings_matrix, based="item")    print(item_similar)</code></pre></li></ul><h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><p>以上实现，仅用于实验阶段，因为工业上、或生产环境中，数据量是远超过我们本例中使用的数据量的，而pandas是无法支撑起大批量数据的运算的（上T的），因此工业上通常会使用spark、mapReduce等分布式计算框架来实现，我们后面的课程中也是建立在此基础上进行实践的。</p><p>但是正如前面所说，推荐算法的思想和理念都是统一的，不论使用什么平台工具、有多大的数据体量，其背后的实现原理都是不变的。</p><p>所以在本节，大家要深刻去学习的是推荐算法的业务流程，以及在具体的业务场景中，如本例的电影推荐，如何实现出推荐算法，并产生推荐结果。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;案例–基于协同过滤的电影推荐&quot;&gt;&lt;a href=&quot;#案例–基于协同过滤的电影推荐&quot; class=&quot;headerlink&quot; title=&quot;案例–基于协同过滤的电影推荐&quot;&gt;&lt;/a&gt;案例–基于协同过滤的电影推荐&lt;/h2&gt;&lt;p&gt;前面我们已经基本掌握了协同过滤推荐算法，以及</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/05_%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%86%B7%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/05_%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%86%B7%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98/</id>
    <published>2023-02-13T05:36:25.617Z</published>
    <updated>2021-08-06T12:09:59.832Z</updated>
    
    <content type="html"><![CDATA[<h3 id="推荐系统的冷启动问题"><a href="#推荐系统的冷启动问题" class="headerlink" title="推荐系统的冷启动问题"></a>推荐系统的冷启动问题</h3><ul><li><p>推荐系统冷启动概念</p><ul><li>⽤户冷启动：如何为新⽤户做个性化推荐</li><li>物品冷启动：如何将新物品推荐给⽤户（协同过滤）</li><li>系统冷启动：⽤户冷启动+物品冷启动</li><li>本质是推荐系统依赖历史数据，没有历史数据⽆法预测⽤户偏好</li></ul></li><li><p>用户冷启动</p><ul><li><p>1.收集⽤户特征</p><ul><li><p>⽤户注册信息：性别、年龄、地域（不能太多，不然用户不填写）</p></li><li><p>设备信息：定位、⼿机型号、app列表</p></li><li><p>社交信息、推⼴素材、安装来源</p><p><img src="/./img/recommend4.png"></p></li></ul></li><li><p>2 引导用户填写兴趣</p><p><img src="/./img/recommend5.png"></p></li><li><p>3 使用其它站点的行为数据, 例如腾讯视频&amp;QQ音乐 今日头条&amp;抖音</p></li><li><p>4 新老用户推荐策略的差异</p><ul><li>新⽤户在冷启动阶段更倾向于热门排⾏榜，⽼⽤户会更加需要长尾推荐</li><li>Explore Exploit⼒度（新用户探索是保守）</li><li>使⽤单独的特征和模型预估–新旧用户分离</li></ul></li><li><p>举例 性别与电视剧的关系</p></li></ul><p><img src="/./img/firststart.png"></p><p><img src="/./img/firststart1.png"></p><p><strong>用户冷启动</strong></p><ul><li>尽可能收集用户信息 构建用户画像（打标签）</li><li>根据用户的标签可以做人群聚类 用以有用户的行为做推荐</li><li>更多的使用流行度推荐</li></ul></li><li><p>物品冷启动</p><ul><li>给物品打标签</li><li>利用物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户。</li></ul><p><img src="/img/firststart2.png"></p><p>物品冷启动</p><ul><li>物品打标签 构建物品画像</li><li>基于内容的推荐</li></ul></li><li><p>系统冷启动</p><ul><li>基于内容的推荐 系统早期</li><li>基于内容的推荐逐渐过渡到协同过滤</li><li>基于内容的推荐和协同过滤的推荐结果都计算出来 加权求和得到最终推荐结果</li></ul></li></ul><h3 id="基于内容的推荐"><a href="#基于内容的推荐" class="headerlink" title="基于内容的推荐"></a>基于内容的推荐</h3><ul><li>给物品打标签<ul><li>系统自己提取从业务数据库中提取（商品的标题副标题等）</li><li>用户填写</li><li>中文分词 利用算法计算词的权重 <ul><li>tf-idf  tf term frequency 词频  5/100 *2 <ul><li>idf 逆文档频率 log 10   文本库篇数/出现关键词的文章篇数</li><li>1000 10python  1000/10 100   2</li><li>1000/1000 log(1) = 0</li></ul></li><li>textrank</li></ul></li></ul></li><li>利用标签的文字 转换成词向量<ul><li>word2Vec 词-&gt;向量</li><li>用向量来表示语义</li><li>如果两个词的词向量相似度比较高 认为这两个词的语义相近</li></ul></li><li>利用词向量 构建物品的向量<ul><li>一个物品有N个关键词 每一个关键词对应一个词向量</li><li>求和（权重*词向量）/N</li><li>利用N个关键词的词向量获取物品向量</li></ul></li><li>通过物品向量计算相似度<ul><li>皮尔逊 相关系数 计算物品向量的相似度</li></ul></li></ul><h3 id="基于内容的推荐-基于物品的协同过滤-区别"><a href="#基于内容的推荐-基于物品的协同过滤-区别" class="headerlink" title="基于内容的推荐 基于物品的协同过滤 区别"></a>基于内容的推荐 基于物品的协同过滤 区别</h3><ul><li>content_base ：词向量-&gt;物品向量-&gt;计算相似度</li><li>item_based cf :user-item matrix-&gt;物品向量-&gt;相似度</li><li>content_base  item_based cf 不一样<ul><li>物品向量构建过程有区别</li><li>基于内容的推荐<ul><li>物品向量 文本（物品描述信息，系统填标签，用户填标签）</li></ul></li><li>基于物品的协同过滤<ul><li>用户对物品的评分矩阵 用户的行为数据中来</li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;推荐系统的冷启动问题&quot;&gt;&lt;a href=&quot;#推荐系统的冷启动问题&quot; class=&quot;headerlink&quot; title=&quot;推荐系统的冷启动问题&quot;&gt;&lt;/a&gt;推荐系统的冷启动问题&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;推荐系统冷启动概念&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;⽤户冷启动：</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/04_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/04_%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/</id>
    <published>2023-02-13T05:36:25.616Z</published>
    <updated>2021-08-06T08:14:18.344Z</updated>
    
    <content type="html"><![CDATA[<h2 id="推荐算法"><a href="#推荐算法" class="headerlink" title="推荐算法"></a>推荐算法</h2><ul><li>推荐模型构建流程</li><li>推荐算法概述</li><li>基于协同过滤的推荐算法</li><li>协同过滤实现</li></ul><h3 id="一-推荐模型构建流程"><a href="#一-推荐模型构建流程" class="headerlink" title="一 推荐模型构建流程"></a>一 推荐模型构建流程</h3><p>Data(数据)-&gt;Features(特征)-&gt;ML Algorithm(机器学习算法)-&gt;Prediction Output(预测输出)</p><ul><li>数据清洗/数据处理</li></ul><p><img src="/./img/algorithm1.png"></p><ul><li>数据来源<ul><li>显性数据<ul><li>Rating 打分</li><li>Comments 评论/评价</li></ul></li><li>隐形数据<ul><li> Order history 历史订单</li><li> Cart events    加购物车</li><li> Page views    页面浏览</li><li> Click-thru      点击</li><li> Search log     搜索记录</li></ul></li></ul></li><li>数据量/数据能否满足要求</li><li>特征工程</li></ul><p><img src="/./img/algorithm2.png"></p><ul><li>从数据中筛选特征<ul><li>一个给定的商品，可能被拥有类似品味或需求的用户购买</li><li>使用用户行为数据描述商品</li></ul></li></ul><p><img src="/./img/algorithm3.png"></p><ul><li><p>用数据表示特征</p><ul><li><p>将所有用户行为合并在一起 ，形成一个user-item 矩阵</p><p><img src="/./img/algorithm4.png" alt="1545452707102"></p></li></ul></li><li><p>选择合适的算法</p></li></ul><p><img src="/./img/algorithm5.png"></p><ul><li><p>产生推荐结果</p><p><img src="/./img/algorithm6.png"></p></li></ul><h3 id="二-最经典的推荐算法：协同过滤推荐算法（Collaborative-Filtering）"><a href="#二-最经典的推荐算法：协同过滤推荐算法（Collaborative-Filtering）" class="headerlink" title="二 最经典的推荐算法：协同过滤推荐算法（Collaborative Filtering）"></a>二 最经典的推荐算法：协同过滤推荐算法（Collaborative Filtering）</h3><p>算法思想：<strong>物以类聚，人以群分</strong></p><p>基本的协同过滤推荐算法基于以下假设：</p><ul><li>“跟你喜好<strong>相似的人</strong>喜欢的东西你也很有可能喜欢” ：基于用户的协同过滤推荐（User-based CF）</li><li>“跟你喜欢的东西<strong>相似的东西</strong>你也很有可能喜欢 ”：基于物品的协同过滤推荐（Item-based CF）</li></ul><p>实现协同过滤推荐有以下几个步骤：</p><ol><li><p><strong>找出最相似的人或物品：TOP-N相似的人或物品</strong></p><p>通过计算两两的相似度来进行排序，即可找出TOP-N相似的人或物品</p></li><li><p><strong>根据相似的人或物品产生推荐结果</strong></p><p>利用TOP-N结果生成初始推荐结果，然后过滤掉用户已经有过记录的物品或明确表示不感兴趣的物品</p></li></ol><p>以下是一个简单的示例，数据集相当于一个用户对物品的购买记录表：打勾表示用户对物品的有购买记录</p><ul><li><p>关于相似度计算这里先用一个简单的思想：如有两个同学X和Y，X同学爱好[足球、篮球、乒乓球]，Y同学爱好[网球、足球、篮球、羽毛球]，可见他们的共同爱好有2个，那么他们的相似度可以用：2/3 * 2/4 = 1/3 ≈ 0.33 来表示。</p><p>User-Based CF</p><p><img src="/./img/%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%901.png"></p><p>Item-Based CF</p><p><img src="/./img/%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9A%84%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E6%8E%A8%E8%8D%901.png"></p><p>通过前面两个demo，相信大家应该已经对协同过滤推荐算法的设计与实现有了比较清晰的认识。</p></li></ul><h3 id="三-相似度计算-Similarity-Calculation"><a href="#三-相似度计算-Similarity-Calculation" class="headerlink" title="三 相似度计算(Similarity Calculation)"></a>三 相似度计算(Similarity Calculation)</h3><p><img src="/./img/similarity_calc1.png"></p><ul><li><p>相似度的计算方法</p><ul><li>数据分类<ul><li>实数值(物品评分情况)</li><li>布尔值(用户的行为 是否点击 是否收藏)</li></ul></li><li>欧氏距离, 是一个欧式空间下度量距离的方法. 两个物体, 都在同一个空间下表示为两个点, 假如叫做p,q, 分别都是n个坐标, 那么欧式距离就是衡量这两个点之间的距离. <strong>欧氏距离不适用于布尔向量之间</strong></li></ul><p><img src="/./img/od.png" alt="1546159024305"></p><p>​欧氏距离的值是一个非负数, 最大值正无穷, 通常计算相似度的结果希望是[-1,1]或[0,1]之间,一般可以使用</p><p>​如下转化公式:<img src="/./img/od2.png"></p><p>​</p></li><li><p>杰卡德相似度&amp;余弦相似度&amp;皮尔逊相关系数</p><ul><li>余弦相似度<ul><li>度量的是两个向量之间的夹角, 用夹角的余弦值来度量相似的情况</li><li>两个向量的夹角为0是,余弦值为1, 当夹角为90度是余弦值为0,为180度是余弦值为-1</li><li>余弦相似度在度量文本相似度, 用户相似度 物品相似度的时候较为常用</li><li>余弦相似度的特点, 与向量长度无关,余弦相似度计算要对向量长度归一化, 两个向量只要方向一致,无论程度强弱, 都可以视为’相似’</li></ul></li><li>皮尔逊相关系数Pearson<ul><li>实际上也是一种余弦相似度, 不过先对向量做了中心化, 向量a b 各自<strong>减去向量的均值后, 再计算余弦相似度</strong></li><li>皮尔逊相似度计算结果在-1,1之间 -1表示负相关, 1表示正相关</li><li>度量两个变量是不是同增同减</li><li>皮尔逊相关系数度量的是两个变量的变化趋势是否一致, <strong>不适合计算布尔值向量之间的相关度</strong></li></ul></li><li>杰卡德相似度 Jaccard<ul><li>两个集合的交集元素个数在并集中所占的比例, 非常适用于布尔向量表示</li><li>分子是两个布尔向量做点积计算, 得到的就是交集元素的个数</li><li>分母是两个布尔向量做或运算, 再求元素和</li></ul></li><li>余弦相似度适合用户评分数据(实数值), 杰卡德相似度适用于隐式反馈数据(0,1布尔值)(是否收藏,是否点击,是否加购物车)</li></ul></li></ul><p><img src="/./img/similarity_calc2.png"></p><ul><li><p>余弦相似度</p><p><img src="/./img/similarity_calc5.png"></p></li><li><p>皮尔逊相关系数</p></li><li><p><img src="/img/image-20210806161414511.png" alt="image-20210806161414511"></p></li></ul><p><img src="/./img/similarity_calc3.png"></p><p><img src="/./img/similarity_calc4.png"></p><ul><li>计算出用户1和其它用户之间的相似度</li></ul><p><img src="/./img/similarity_calc6.png"></p><ul><li>按照相似度大小排序, K近邻 如K取4:</li></ul><p><img src="/./img/similarity_calc7.png"></p><ul><li>取出近邻用户的购物清单</li></ul><p><img src="/./img/similarity_calc8.png"></p><ul><li>去除用户1已经购买过的商品</li></ul><p><img src="/./img/similarity_calc9.png"></p><ul><li>在剩余的物品中根据评分排序</li></ul><p><img src="/./img/similarity_calc10.png"></p><ul><li>物品相似度计算<ul><li>余弦相似度对绝对值大小不敏感带来的问题<ul><li>用户A对两部电影评分分别是1分和2分, 用户B对同样这两部电影进行评分是4分,5分 用余弦相似度计算,两个用户的相似度达到0.98    </li><li>可以采用改进的余弦相似度, 先计算向量每个维度上的均值, 然后每个向量在各个维度上都减去均值后,在计算余弦相似度, 用调整的余弦相似度计算得到的相似度是-0.1</li></ul></li></ul></li></ul><p><img src="/./img/similarity_calc11.png"></p><ul><li>物品相似度计算案例</li></ul><p><img src="/./img/similarity_calc12.png"></p><ul><li>找出物品1的相似商品</li></ul><p><img src="/./img/similarity_calc13.png"></p><ul><li>选择最近似的物品</li></ul><p><img src="/./img/similarity_calc14.png"></p><ul><li>基于用户与物品的协同过滤比较</li></ul><p><img src="/./img/similarity_calc15.png"><img src="/./img/similarity_calc16.png"></p><h3 id="协同过滤推荐算法代码实现："><a href="#协同过滤推荐算法代码实现：" class="headerlink" title="协同过滤推荐算法代码实现："></a>协同过滤推荐算法代码实现：</h3><ul><li><p>构建数据集：</p><pre><code class="python">users = ["User1", "User2", "User3", "User4", "User5"]items = ["Item A", "Item B", "Item C", "Item D", "Item E"]# 构建数据集datasets = [    ["buy",None,"buy","buy",None],    ["buy",None,None,"buy","buy"],    ["buy",None,"buy",None,None],    [None,"buy",None,"buy","buy"],    ["buy","buy","buy",None,"buy"],]</code></pre></li><li><p>计算时我们数据通常都需要对数据进行处理，或者编码，目的是为了便于我们对数据进行运算处理，比如这里是比较简单的情形，我们用1、0分别来表示用户的是否购买过该物品，则我们的数据集其实应该是这样的：</p><pre><code class="python">users = ["User1", "User2", "User3", "User4", "User5"]items = ["Item A", "Item B", "Item C", "Item D", "Item E"]# 用户购买记录数据集datasets = [    [1,0,1,1,0],    [1,0,0,1,1],    [1,0,1,0,0],    [0,1,0,1,1],    [1,1,1,0,1],]import pandas as pddf = pd.DataFrame(datasets,                  columns=items,                  index=users)print(df)</code></pre></li><li><p>有了数据集，接下来我们就可以进行相似度的计算，不过对于相似度的计算其实是有很多专门的相似度计算方法的，比如余弦相似度、皮尔逊相关系数、杰卡德相似度等等。这里我们选择使用杰卡德相似系数[0,1]</p><pre><code class="python"># 直接计算某两项的杰卡德相似系数from sklearn.metrics import jaccard_score# 计算Item A 和Item B的相似度print(jaccard_score(df["Item A"], df["Item B"]))# 计算所有的数据两两的杰卡德相似系数from sklearn.metrics.pairwise import pairwise_distances# 计算用户间相似度，1减去杰卡德距离就是杰卡德相识度user_similar = 1 - pairwise_distances(df.values, metric="jaccard")user_similar = pd.DataFrame(user_similar, columns=users, index=users)print("用户之间的两两相似度：")print(user_similar)# 计算物品间相似度item_similar = 1 - pairwise_distances(df.T.values, metric="jaccard")item_similar = pd.DataFrame(item_similar, columns=items, index=items)print("物品之间的两两相似度：")print(item_similar)</code></pre><p>有了两两的相似度，接下来就可以筛选TOP-N相似结果，并进行推荐了</p></li><li><p>User-Based CF</p><pre><code class="python">import pandas as pdimport numpy as npfrom pprint import pprintusers = ["User1", "User2", "User3", "User4", "User5"]items = ["Item A", "Item B", "Item C", "Item D", "Item E"]# 用户购买记录数据集datasets = [    [1,0,1,1,0],    [1,0,0,1,1],    [1,0,1,0,0],    [0,1,0,1,1],    [1,1,1,0,1],]df = pd.DataFrame(datasets,                  columns=items,                  index=users)# 计算所有的数据两两的杰卡德相似系数from sklearn.metrics.pairwise import pairwise_distances# 计算用户间相似度user_similar = 1 - pairwise_distances(df, metric="jaccard")user_similar = pd.DataFrame(user_similar, columns=users, index=users)print("用户之间的两两相似度：")print(user_similar)topN_users = {}# 遍历每一行数据for i in user_similar.index:    # 取出每一列数据，并删除自身，然后排序数据    _df = user_similar.loc[i].drop([i])    _df_sorted = _df.sort_values(ascending=False)    top2 = list(_df_sorted.index[:2])    topN_users[i] = top2print("Top2相似用户：")pprint(topN_users)rs_results = {}# 构建推荐结果for user, sim_users in topN_users.items():    rs_result = set()    # 存储推荐结果    for sim_user in sim_users:        # 构建初始的推荐结果,要去重         rs_result = rs_result.union(set(df.loc[sim_user].replace(0,np.nan).dropna().index))    # 过滤掉已经购买过的物品    rs_result -= set(df.loc[user].replace(0,np.nan).dropna().index)    rs_results[user] = rs_resultprint("最终推荐结果：")pprint(rs_results)</code></pre></li><li><p>Item-Based CF</p><pre><code class="python">import pandas as pdimport numpy as npfrom pprint import pprintusers = ["User1", "User2", "User3", "User4", "User5"]items = ["Item A", "Item B", "Item C", "Item D", "Item E"]# 用户购买记录数据集datasets = [    [1,0,1,1,0],    [1,0,0,1,1],    [1,0,1,0,0],    [0,1,0,1,1],    [1,1,1,0,1],]df = pd.DataFrame(datasets,                  columns=items,                  index=users)# 计算所有的数据两两的杰卡德相似系数from sklearn.metrics.pairwise import pairwise_distances# 计算物品间相似度item_similar = 1 - pairwise_distances(df.T, metric="jaccard")item_similar = pd.DataFrame(item_similar, columns=items, index=items)print("物品之间的两两相似度：")print(item_similar)topN_items = {}# 遍历每一行数据for i in item_similar.index:    # 取出每一列数据，并删除自身，然后排序数据    _df = item_similar.loc[i].drop([i])    _df_sorted = _df.sort_values(ascending=False)    top2 = list(_df_sorted.index[:2])    topN_items[i] = top2print("Top2相似物品：")pprint(topN_items)rs_results = {}# 构建推荐结果for user in df.index:    # 遍历所有用户    rs_result = set()    for item in df.ix[user].replace(0,np.nan).dropna().index:   # 取出每个用户当前已购物品列表        # 根据每个物品找出最相似的TOP-N物品，构建初始推荐结果        rs_result = rs_result.union(topN_items[item])    # 过滤掉用户已购的物品    rs_result -= set(df.ix[user].replace(0,np.nan).dropna().index)    # 添加到结果中    rs_results[user] = rs_resultprint("最终推荐结果：")pprint(rs_results)</code></pre></li></ul><p><strong>关于协同过滤推荐算法使用的数据集</strong></p><p>在前面的demo中，我们只是使用用户对物品的一个购买记录，类似也可以是比如浏览点击记录、收听记录等等。这样数据我们预测的结果其实相当于是在预测用户是否对某物品感兴趣，对于喜好程度不能很好的预测。</p><p>因此在协同过滤推荐算法中其实会更多的利用用户对物品的“评分”数据来进行预测，通过评分数据集，我们可以预测用户对于他没有评分过的物品的评分。其实现原理和思想和都是一样的，只是使用的数据集是用户-物品的评分数据。</p><p><strong>关于用户-物品评分矩阵</strong></p><p>用户-物品的评分矩阵，根据评分矩阵的稀疏程度会有不同的解决方案</p><ul><li><p>稠密评分矩阵</p><p><img src="/./img/%E7%A8%A0%E5%AF%86%E8%AF%84%E5%88%86%E6%95%B0%E6%8D%AE%E9%9B%86.png"></p></li><li><p>稀疏评分矩阵</p><p><img src="/./img/%E7%A8%80%E7%96%8F%E8%AF%84%E5%88%86%E6%95%B0%E6%8D%AE%E9%9B%86.png"></p></li></ul><p>这里先介绍稠密评分矩阵的处理，稀疏矩阵的处理相对会复杂一些，我们到后面再来介绍。</p><h4 id="使用协同过滤推荐算法对用户进行评分预测"><a href="#使用协同过滤推荐算法对用户进行评分预测" class="headerlink" title="使用协同过滤推荐算法对用户进行评分预测"></a>使用协同过滤推荐算法对用户进行评分预测</h4><ul><li><p>数据集：<img src="/./img/%E7%A8%A0%E5%AF%86%E8%AF%84%E5%88%86%E6%95%B0%E6%8D%AE%E9%9B%86.png"></p><p><strong>目的：预测用户1对物品E的评分</strong></p></li><li><p>构建数据集：注意这里构建评分数据时，对于缺失的部分我们需要保留为None，如果设置为0那么会被当作评分值为0去对待</p><pre><code class="python">users = ["User1", "User2", "User3", "User4", "User5"]items = ["Item A", "Item B", "Item C", "Item D", "Item E"]# 用户购买记录数据集datasets = [    [5,3,4,4,None],    [3,1,2,3,3],    [4,3,4,3,5],    [3,3,1,5,4],    [1,5,5,2,1],]</code></pre></li><li><p>计算相似度：对于评分数据这里我们采用皮尔逊相关系数[-1,1]来计算，-1表示强负相关，+1表示强正相关</p><blockquote><p>pandas中corr方法可直接用于计算皮尔逊相关系数</p></blockquote><pre><code class="python">df = pd.DataFrame(datasets,                  columns=items,                  index=users)print("用户之间的两两相似度：")# 直接计算皮尔逊相关系数# 默认是按列进行计算，因此如果计算用户间的相似度，当前需要进行转置user_similar = df.T.corr()print(user_similar.round(4))print("物品之间的两两相似度：")item_similar = df.corr()print(item_similar.round(4))</code></pre><pre><code># 运行结果：用户之间的两两相似度：        User1   User2   User3   User4   User5User1  1.0000  0.8528  0.7071  0.0000 -0.7921User2  0.8528  1.0000  0.4677  0.4900 -0.9001User3  0.7071  0.4677  1.0000 -0.1612 -0.4666User4  0.0000  0.4900 -0.1612  1.0000 -0.6415User5 -0.7921 -0.9001 -0.4666 -0.6415  1.0000物品之间的两两相似度：        Item A  Item B  Item C  Item D  Item EItem A  1.0000 -0.4767 -0.1231  0.5322  0.9695Item B -0.4767  1.0000  0.6455 -0.3101 -0.4781Item C -0.1231  0.6455  1.0000 -0.7206 -0.4276Item D  0.5322 -0.3101 -0.7206  1.0000  0.5817Item E  0.9695 -0.4781 -0.4276  0.5817  1.0000</code></pre><p>可以看到与用户1最相似的是用户2和用户3；与物品A最相似的物品分别是物品E和物品D。</p><p><strong>注意：</strong>我们在预测评分时，往往是通过与其有正相关的用户或物品进行预测，如果不存在正相关的情况，那么将无法做出预测。这一点尤其是在稀疏评分矩阵中尤为常见，因为稀疏评分矩阵中很难得出正相关系数。</p></li><li><p><strong>评分预测：</strong></p><p><strong>User-Based CF 评分预测：使用用户间的相似度进行预测</strong></p><p>关于评分预测的方法也有比较多的方案，下面介绍一种效果比较好的方案，该方案考虑了用户本身的评分评分以及近邻用户的加权平均相似度打分来进行预测：<br>$$<br>pred(u,i)=\hat{r}<em>{ui}=\cfrac{\sum</em>{v\in U}sim(u,v)*r_{vi}}{\sum_{v\in U}|sim(u,v)|}<br>$$<br>我们要预测用户1对物品E的评分，那么可以根据与用户1最近邻的用户2和用户3进行预测，计算如下：</p><p>​<br>$$<br>pred(u_1, i_5) =\cfrac{0.85<em>3+0.71</em>5}{0.85+0.71} = 3.91<br>$$<br><strong>最终预测出用户1对物品5的评分为3.91</strong></p><p><strong>Item-Based CF 评分预测：使用物品间的相似度进行预测</strong></p><p>这里利用物品相似度预测的计算同上，同样考虑了用户自身的平均打分因素，结合预测物品与相似物品的加权平均相似度打分进行来进行预测<br>$$<br>pred(u,i)=\hat{r}<em>{ui}=\cfrac{\sum</em>{j\in I_{rated}}sim(i,j)<em>r_{uj}}{\sum_{j\in I_{rated}}sim(i,j)}<br>$$<br>我们要预测用户1对物品E的评分，那么可以根据与物品E最近邻的物品A和物品D进行预测，用相似度乘以用户1分别对物品A和物品D的评分，也就是5和4，计算如下：<br>$$<br>pred(u_1, i_5) = \cfrac {0.97</em>5+0.58*4}{0.97+0.58} = 4.63<br>$$<br>对比可见，User-Based CF预测评分和Item-Based CF的评分结果也是存在差异的，因为严格意义上他们其实应当属于两种不同的推荐算法，各自在不同的领域不同场景下，都会比另一种的效果更佳，但具体哪一种更佳，必须经过合理的效果评估，因此在实现推荐系统时这两种算法往往都是需要去实现的，然后对产生的推荐效果进行评估分析选出更优方案。</p><p>假如有几万种商品，而大部分商品用户都没有购买过怎么办？</p></li></ul><h3 id="基于模型的方法"><a href="#基于模型的方法" class="headerlink" title="基于模型的方法"></a>基于模型的方法</h3><ul><li><p>思想</p><ul><li>通过机器学习算法，在数据中找出模式，并将用户与物品间的互动方式模式化</li><li>基于模型的协同过滤方式是构建协同过滤更高级的算法</li></ul></li><li><p>近邻模型的问题</p><ul><li>物品之间存在相关性, 信息量并不随着向量维度增加而线性增加</li><li>矩阵元素稀疏, 计算结果不稳定,增减一个向量维度, 导致近邻结果差异很大的情况存在</li></ul></li><li><p>算法分类</p><ul><li>基于图的模型</li><li><strong>基于矩阵分解的方法</strong>（可以应用于稀疏）</li></ul></li><li><p>基于图的模型</p><ul><li>基于邻域的模型看做基于图的模型的简单形式</li></ul><p><img src="/./img/graph1.png"></p><ul><li>原理<ul><li>将用户的行为数据表示为二分图</li><li>基于二分图为用户进行推荐</li><li>根据两个顶点之间的路径数、路径长度和经过的顶点数来评价两个顶点的相关性</li></ul></li></ul></li><li><p>基于矩阵分解的模型</p><ul><li><p>原理</p><ul><li><p>根据用户与物品的潜在表现，我们就可以预测用户对未评分的物品的喜爱程度</p></li><li><p>把原来的大矩阵, 近似分解成两个小矩阵的乘积, 在实际推荐计算时不再使用大矩阵, 而是使用分解得到的两个小矩阵  </p></li><li><p>用户-物品评分矩阵A是M X N维, 即一共有M个用户, n个物品 我们选一个很小的数 K (K&lt;&lt; M, K&lt;&lt;N)<br><strong>K可以理解成会影响到用户对物品评分的特征</strong>，如果有30个特征会影响到，至少为30</p></li><li><p>通过计算得到两个矩阵U V  U是M * K矩阵 , 矩阵V是 N * K</p><p>$U_{m<em>k} V^{T}_{n</em>k} 约等于 A_{m*n}$</p><p>类似这样的计算过程就是矩阵分解</p></li></ul></li><li><p>基于矩阵分解的方法</p><ul><li>ALS交替最小二乘<ul><li>ALS-WR(加权正则化交替最小二乘法): alternating-least-squares with weighted-λ –regularization</li><li>将用户(user)对商品(item)的评分矩阵分解为两个矩阵：一个是用户对商品隐含特征的偏好矩阵，另一个是商品所包含的隐含特征的矩阵。<strong>在这个矩阵分解的过程中，评分缺失项得到了填充</strong>，也就是说我们可以基于这个填充的评分来给用户做商品推荐了。</li></ul></li><li>SVD奇异值分解矩阵</li></ul></li></ul></li><li><p>ALS方法</p><p><img src="/./img/als1.png"></p><ul><li><p>怎么去算，后面我们有实例</p></li><li><p>ALS的矩阵分解算法常应用于推荐系统中，将用户(user)对商品(item)的评分矩阵，分解为用户对商品隐含特征的偏好矩阵，和商品在隐含特征上的映射矩阵。</p></li><li><p>与传统的矩阵分解SVD方法来分解矩阵R(R∈ℝm×n)不同的是，ALS(alternating least squares)希望找到两个低维矩阵，以 R̃ =XY 来逼近矩阵R，其中 ，X∈ℝm×d，Y∈ℝd×n，这样，将问题的复杂度由O(m*n)转换为O((m+n)*d)。</p></li><li><p>计算X和Y过程：首先用一个小于1的随机数初始化Y，并根据公式求X，此时就可以得到初始的XY矩阵了，根据平方差和得到的X，重新计算并覆盖Y，计算差平方和，反复进行以上两步的计算，直到差平方和小于一个预设的数，或者迭代次数满足要求则停止</p><p>怎么做预测，从M*K矩阵中抽出一个用户，也就是一行，再去K*N矩阵中拿出1列，想乘就得到了一个评分</p></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;推荐算法&quot;&gt;&lt;a href=&quot;#推荐算法&quot; class=&quot;headerlink&quot; title=&quot;推荐算法&quot;&gt;&lt;/a&gt;推荐算法&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;推荐模型构建流程&lt;/li&gt;
&lt;li&gt;推荐算法概述&lt;/li&gt;
&lt;li&gt;基于协同过滤的推荐算法&lt;/li&gt;
&lt;li&gt;协</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/03_%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0/"/>
    <id>http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/03_%20%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E4%BC%B0/</id>
    <published>2023-02-13T05:36:25.609Z</published>
    <updated>2021-08-06T02:50:06.890Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二-推荐系统评估"><a href="#二-推荐系统评估" class="headerlink" title="二 推荐系统评估"></a>二 推荐系统评估</h2><ul><li>好的推荐系统可以实现用户, 服务提供方, 内容提供方的共赢</li></ul><p><img src="/img/recommend2.png"></p><ul><li><p>显示反馈和隐式反馈</p><table>  <tbody><tr>    <th></th>    <th>显式反馈</th>    <th>隐式反馈</th>  </tr>  <tr> <td> 例子 </td> <td> 电影/书籍评分  是否喜欢这个推荐 </td> <td> 播放/点击 评论 下载 购买 </td>  </tr>  <tr>    <td> 准确性 </td>    <td> 高 </td>    <td> 低 </td>  </tr>  <tr>    <td> 数量 </td>    <td> 少 </td>    <td> 多 </td>  </tr>  <tr>    <td> 获取成本 </td>    <td> 高 </td>    <td> 低 </td>  </tr></tbody></table></li><li><p>常用评估指标</p><p>• 准确性  • 信任度<br>• 满意度  • 实时性<br>• 覆盖率  • 鲁棒性<br>• 多样性  • 可扩展性<br>• 新颖性  • 商业⽬标<br>• 惊喜度  • ⽤户留存</p><ul><li>准确性 (理论角度) Netflix 美国录像带租赁<ul><li>评分预测<ul><li>RMSE   MAE  点击率预估 精准率</li></ul></li><li>topN推荐<ul><li>召回率 精准率</li></ul></li></ul></li><li>准确性 (业务角度)</li></ul><p><img src="/./img/recommend3.png"></p><ul><li>覆盖度<ul><li>信息熵 对于推荐越大越好，覆盖的商品越多</li><li>覆盖率</li></ul></li><li>多样性&amp;新颖性&amp;惊喜性<ul><li>多样性：推荐列表中两两物品的不相似性。（相似性如何度量？</li><li>新颖性：未曾关注的类别、作者；推荐结果的平均流⾏度</li><li>惊喜性：历史不相似（惊）但很满意（喜）</li><li>往往需要牺牲准确性</li><li>使⽤历史⾏为预测⽤户对某个物品的喜爱程度</li><li>系统过度强调实时性</li></ul></li><li>Exploitation &amp; Exploration 探索与利用问题<ul><li>Exploitation(开发 利用)：选择现在可能最佳的⽅案</li><li>Exploration(探测 搜索)：选择现在不确定的⼀些⽅案，但未来可能会有⾼收益的⽅案</li><li>在做两类决策的过程中，不断更新对所有决策的不确定性的认知，优化<br>长期的⽬标</li></ul></li><li>EE问题实践<ul><li>兴趣扩展: 相似话题, 搭配推荐</li><li>人群算法: userCF 用户聚类</li><li>平衡个性化推荐和热门推荐比例</li><li>随机丢弃用户行为历史</li><li>随机扰动模型参数</li></ul></li><li>EE可能带来的问题<ul><li>探索伤害用户体验, 可能导致用户流失</li><li>探索带来的长期收益(留存率)评估周期长, KPI压力大</li><li>如何平衡实时兴趣和长期兴趣</li><li>如何平衡短期产品体验和长期系统生态</li><li>如何平衡大众口味和小众需求</li></ul></li><li>评估方法<ul><li>问卷调查: 成本高</li><li>离线评估:<ul><li>只能在用户看到过的候选集上做评估, 且跟线上真实效果存在偏差</li><li>只能评估少数指标</li><li>速度快, 不损害用户体验</li></ul></li><li>在线评估: 灰度发布 &amp; A/B测试 50% 全量上线</li><li>实践: 离线评估和在线评估结合, 定期做问卷调查</li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二-推荐系统评估&quot;&gt;&lt;a href=&quot;#二-推荐系统评估&quot; class=&quot;headerlink&quot; title=&quot;二 推荐系统评估&quot;&gt;&lt;/a&gt;二 推荐系统评估&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;好的推荐系统可以实现用户, 服务提供方, 内容提供方的共赢&lt;/li&gt;
&lt;/ul&gt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/02_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    <id>http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/02_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</id>
    <published>2023-02-13T05:36:25.607Z</published>
    <updated>2023-02-11T03:06:47.844Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二-推荐系统设计"><a href="#二-推荐系统设计" class="headerlink" title="二 推荐系统设计"></a>二 推荐系统设计</h2><h3 id="2-1-推荐系统要素"><a href="#2-1-推荐系统要素" class="headerlink" title="2.1 推荐系统要素"></a>2.1 推荐系统要素</h3><ul><li>UI 和 UE(前端界面)</li><li>数据 (Lambda架构)</li><li>业务知识</li><li>算法</li></ul><h3 id="2-2-推荐系统架构"><a href="#2-2-推荐系统架构" class="headerlink" title="2.2 推荐系统架构"></a>2.2 推荐系统架构</h3><ul><li><p>推荐系统整体架构</p><p><img src="/../img/%E6%8E%A8%E8%8D%90%E6%B5%81%E7%A8%8B.png"></p></li><li><p>大数据Lambda架构</p><ul><li><p>由Twitter工程师Nathan Marz(storm项目发起人)提出</p></li><li><p>Lambda系统架构提供了一个结合实时数据和Hadoop预先计算的数据环境和混合平台, 提供一个实时的数据视图</p></li><li><p>分层架构</p><ul><li>批处理层<ul><li>数据不可变, 可进行任何计算, 可水平扩展</li><li>高延迟  几分钟~几小时(计算量和数据量不同)</li><li>日志收集 Flume</li><li>分布式存储 Hadoop hdfs</li><li>分布式计算 Hadoop MapReduce &amp; spark</li><li>视图存储数据库<ul><li>nosql(HBase/Cassandra)</li><li>Redis/memcache</li><li>MySQL</li></ul></li></ul></li><li>实时处理层<ul><li>流式处理, 持续计算</li><li>存储和分析某个窗口期内的数据</li><li>最终正确性(Eventual accuracy)</li><li>实时数据收集 flume &amp; kafka</li><li>实时数据分析  spark streaming/storm/flink</li></ul></li><li>服务层<ul><li>支持随机读</li><li>需要在非常短的时间内返回结果</li><li>读取批处理层和实时处理层结果并对其归并</li></ul></li></ul></li><li><p>Lambda架构图</p><p><img src="/./img/lambda3.png"></p></li></ul></li><li><p>推荐算法架构</p><ul><li>召回阶段(海选)<ul><li>召回决定了最终推荐结果的天花板</li><li>常用算法:<ul><li>协同过滤(基于用户 基于物品的)</li><li>基于内容 (根据用户行为总结出自己的偏好 根据偏好 通过文本挖掘技术找到内容上相似的商品)</li><li>基于隐语义</li></ul></li></ul></li><li>排序阶段<ul><li>召回决定了最终推荐结果的天花板, 排序逼近这个极限, 决定了最终的推荐效果</li><li>CTR预估 (点击率预估 使用LR算法)  估计用户是否会点击某个商品 需要用户的点击数据</li></ul></li><li>策略调整</li></ul></li></ul><p><img src="/../img/recommend7.jpeg"></p><ul><li><p>推荐系统的整体架构</p><p><img src="/./img/rs%E5%9F%BA%E7%A1%80%E4%B8%9A%E5%8A%A1%E6%9E%B6%E6%9E%84.png"></p><p><img src="/../img/rs%E5%9F%BA%E7%A1%80%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84.png"></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;二-推荐系统设计&quot;&gt;&lt;a href=&quot;#二-推荐系统设计&quot; class=&quot;headerlink&quot; title=&quot;二 推荐系统设计&quot;&gt;&lt;/a&gt;二 推荐系统设计&lt;/h2&gt;&lt;h3 id=&quot;2-1-推荐系统要素&quot;&gt;&lt;a href=&quot;#2-1-推荐系统要素&quot; class=&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B/"/>
    <id>http://example.com/2023/02/13/day01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/01_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B/</id>
    <published>2023-02-13T05:36:25.605Z</published>
    <updated>2023-02-11T03:05:42.664Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一-推荐系统简介"><a href="#一-推荐系统简介" class="headerlink" title="一 推荐系统简介"></a>一 推荐系统简介</h2><p>​        个性化推荐(推荐系统)经历了多年的发展，已经成为互联网产品的标配，也是AI成功落地的分支之一，在电商(淘宝/京东)、资讯(今日头条/微博)、音乐(网易云音乐/QQ音乐)、短视频(抖音/快手)等热门应用中,推荐系统都是核心组件之一。</p><ul><li><p>推荐系统产生背景</p><ul><li>信息过载 &amp; 用户需求不明确<ul><li>分类⽬录（1990s）：覆盖少量热门⽹站。Hao123 Yahoo</li><li>搜索引擎（2000s）：通过搜索词明确需求。Google Baidu</li><li>推荐系统（2010s）：不需要⽤户提供明确的需求，通过分析⽤<br>户的历史⾏为给⽤户的兴趣进⾏建模，从⽽主动给⽤户推荐能<br>够满⾜他们兴趣和需求的信息。</li></ul></li></ul></li><li><p>什么是推荐系统</p><ul><li>没有明确需求的用户访问了我们的服务, 且服务的物品对用户构成了信息过载, 系统通过一定的规则对物品进行排序,并将排在前面的物品展示给用户,这样的系统就是推荐系统</li></ul></li><li><p>推荐系统 V.S. 搜索引擎</p><table>  <tbody><tr>    <th></th>    <th>搜索</th>    <th>推荐</th>  </tr>  <tr>    <td> 行为方式 </td>    <td> 主动 </td>    <td> 被动 </td>  </tr>  <tr>    <td> 意图 </td>    <td> 明确 </td>    <td> 模糊 </td>  </tr>  <tr>    <td> 个性化 </td>    <td> 弱 </td>    <td> 强 </td>  </tr>  <tr>    <td> 流量分布 </td>    <td> 马太效应 </td>    <td> 长尾效应 </td>  </tr>  <tr>    <td> 目标 </td>    <td> 快速满足  </td>    <td> 持续服务 </td>  </tr>  <tr>    <td> 评估指标 </td>    <td> 简明 </td>    <td> 复杂 </td>  </tr></tbody></table></li><li><p>推荐系统的作用</p><ul><li>高效连接用户和物品, 发现长尾商品</li><li>留住用户和内容生产者, 实现商业目标</li></ul></li><li><p>推荐系统的工作原理</p><ul><li><strong>社会化推荐</strong> 向朋友咨询, 社会化推荐, 让好友给自己推荐物品</li><li><strong>基于内容的推荐</strong> 打开搜索引擎, 输入自己喜欢的演员的名字, 然后看看返回结果中还有什么电影是自己没看过的</li><li><strong>基于流行度的推荐</strong> 查看票房排行榜, </li><li><strong>基于协同过滤的推荐</strong> 找到和自己历史兴趣相似的用户, 看看他们最近在看什么电影</li></ul></li><li><p>推荐系统的应用场景 feed 流 信息流 </p><p><img src="/./img/recommend1.png"></p></li><li><p>推荐系统和Web项目的区别</p><ul><li>稳定的信息流通系统 V.S. 通过信息过滤实现目标提升 <ul><li>web项目: 处理复杂逻辑 处理高并发 实现高可用 为用户提供稳定服务, 构建一个稳定的信息流通的服务</li><li>推荐系统: 追求指标增长, 留存率/阅读时间/GMV (Gross Merchandise Volume电商网站成交金额)/视频网站VV (Video View)</li></ul></li><li>确定 V.S. 不确定思维<ul><li>web项目: 对结果有确定预期</li><li>推荐系统: 结果是概率问题</li></ul></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;一-推荐系统简介&quot;&gt;&lt;a href=&quot;#一-推荐系统简介&quot; class=&quot;headerlink&quot; title=&quot;一 推荐系统简介&quot;&gt;&lt;/a&gt;一 推荐系统简介&lt;/h2&gt;&lt;p&gt;​        个性化推荐(推荐系统)经历了多年的发展，已经成为互联网产品的标配，也是AI</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/%E6%8A%95%E8%B5%84%E7%9A%84%E5%BF%83%E6%80%81/"/>
    <id>http://example.com/2023/02/13/%E6%8A%95%E8%B5%84%E7%9A%84%E5%BF%83%E6%80%81/</id>
    <published>2023-02-13T05:36:25.489Z</published>
    <updated>2023-02-02T12:44:28.979Z</updated>
    
    <content type="html"><![CDATA[<p>普通投资者把精力花在学习投资知识和策略上，有什么意义呢？什么是健康的投资心态？从投资这件事上如何历练正确的积极的心态，以对我们的人生有所帮助？</p><h2 id="避免的陷阱"><a href="#避免的陷阱" class="headerlink" title="避免的陷阱"></a>避免的陷阱</h2><ol><li>时间沉没成本<br>我已经花了多少时间在这上面？这部分投入换算成金钱，增加到我的亏损上，最终结果应当还是盈余。</li><li>未获得的和已经失去的</li><li>短线的痛苦</li></ol><h2 id="正确的心态"><a href="#正确的心态" class="headerlink" title="正确的心态"></a>正确的心态</h2><ol><li>长远眼光</li><li>市场知识的学习</li><li>人性的学习</li><li>避免生活中的陷阱</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;普通投资者把精力花在学习投资知识和策略上，有什么意义呢？什么是健康的投资心态？从投资这件事上如何历练正确的积极的心态，以对我们的人生有所帮助？&lt;/p&gt;
&lt;h2 id=&quot;避免的陷阱&quot;&gt;&lt;a href=&quot;#避免的陷阱&quot; class=&quot;headerlink&quot; title=&quot;避免的</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/02/13/%E5%A4%B4%E6%9D%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E9%A1%B9%E7%9B%AE/"/>
    <id>http://example.com/2023/02/13/%E5%A4%B4%E6%9D%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8E%A8%E8%8D%90%E9%A1%B9%E7%9B%AE/</id>
    <published>2023-02-13T05:36:25.488Z</published>
    <updated>2023-02-12T09:21:50.806Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/image-20230211193156286.png"></p><h1 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h1><h2 id="启动-hadoop、hive-连接-mysql"><a href="#启动-hadoop、hive-连接-mysql" class="headerlink" title="启动 hadoop、hive(连接 mysql)"></a>启动 hadoop、hive(连接 mysql)</h2><pre><code class="shell">#~/hadoop_code/start_hive.shstart-all.shservice docker startdocker start mysqlhive --service metastore &amp;</code></pre><pre><code class="shell">#查看mysqldocker exec -it mysql bashmysql -uroot -p#密码: passwordctrl+P+Q 退出</code></pre><h2 id="启动-hbase、spark、thriftserver"><a href="#启动-hbase、spark、thriftserver" class="headerlink" title="启动 hbase、spark、thriftserver"></a>启动 hbase、spark、thriftserver</h2><pre><code class="shell">cd ~/bigdatastart-hbase.sh./spark/sbin/start-all.shhbase thrift start</code></pre><h2 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h2><pre><code class="shell">jps10948 ThriftServer3816 ResourceManager3145 DataNode6571 HMaster4813 RunJar7667 Master13557 Jps6998 HRegionServer9691 Worker9948 RunJar3645 SecondaryNameNode2751 NameNode4223 NodeManager6463 HQuorumPeer</code></pre><h1 id="离线计算更新物品画像"><a href="#离线计算更新物品画像" class="headerlink" title="离线计算更新物品画像"></a>离线计算更新物品画像</h1><h2 id="用-Sqoop-迁移和同步数据库"><a href="#用-Sqoop-迁移和同步数据库" class="headerlink" title="用 Sqoop 迁移和同步数据库"></a>用 Sqoop 迁移和同步数据库</h2><p>业务数据通常存放在 mysql 数据库中，我们需要把它定期同步到 hadoop 的 hive 数据仓库中。</p><pre><code class="sql">create database if not exists toutiao comment "user,news information of 136 mysql" location '/user/hive/warehouse/toutiao.db/';</code></pre><pre><code class="shell">sqoop list-databases --connect jdbc:mysql://192.168.19.137:3306/ --username root -P</code></pre><p>密码：<strong>password</strong><br>会显示连接到的数据库:</p><pre><code>information_schemahivemysqlperformance_schemasystoutiao</code></pre><p>写增量导入的 Sqoop 脚本</p><pre><code class="shell">#/root/toutiao_project/scripts/import_incremental.shtime=`date +"%Y-%m-%d" -d "-1day"`declare -A checkcheck=([user_profile]=update_time [user_basic]=last_login [news_channel]=update_time)declare -A mergemerge=([user_profile]=user_id [user_basic]=user_id [news_channel]=channel_id)for k in ${!check[@]}do    sqoop import \        --connect jdbc:mysql://192.168.19.137/toutiao \        --username root \        --password password \        --table $k \        --m 4 \        --target-dir /user/hive/warehouse/toutiao.db/$k \        --incremental lastmodified \        --check-column ${check[$k]} \        --merge-key ${merge[$k]} \        --last-value ${time}done</code></pre><p>写 crontab-shell 脚本让 Sqoop 定时运行</p><pre><code class="shell">crontab -e#每30分钟运行一次*/30 * * * * /root/toutiao_project/scripts/import_incremental.shservice crond start</code></pre><blockquote><p>这里 MySQL 里面没有创建好，实际会报错，不管。</p></blockquote><h2 id="用户行为埋点收集"><a href="#用户行为埋点收集" class="headerlink" title="用户行为埋点收集"></a>用户行为埋点收集</h2><h3 id="埋点设置"><a href="#埋点设置" class="headerlink" title="埋点设置"></a>埋点设置</h3><pre><code class="json"># 曝光的参数，{"actionTime":"2019-04-10 18:15:35","readTime":"","channelId":0,"param":{"action": "exposure", "userId": "2", "articleId": "[18577, 14299]", "algorithmCombine": "C2"}}# 对文章发生行为的参数{"actionTime":"2019-04-10 18:12:11","readTime":"2886","channelId":18,"param":{"action": "read", "userId": "2", "articleId": "18005", "algorithmCombine": "C2"}}{"actionTime":"2019-04-10 18:15:32","readTime":"","channelId":18,"param":{"action": "click", "userId": "2", "articleId": "18005", "algorithmCombine": "C2"}}{"actionTime":"2019-04-10 18:15:34","readTime":"1053","channelId":18,"param":{"action": "read", "userId": "2", "articleId": "18005", "algorithmCombine": "C2"}}...</code></pre><h3 id="用-flume-收集到-hive-中"><a href="#用-flume-收集到-hive-中" class="headerlink" title="用 flume 收集到 hive 中"></a>用 flume 收集到 hive 中</h3><p>创建 flume 配置文件</p><pre><code class="shell">#/root/bigdata/flume/collect_click.confa1.sources = s1a1.sinks = k1a1.channels = c1# 实时查看日志文件尾a1.sources.s1.channels= c1a1.sources.s1.type = execa1.sources.s1.command = tail -F /root/logs/userClick.log# 设置两个拦截器 1.格式过滤 2.附加时间戳a1.sources.s1.interceptors=i1 i2a1.sources.s1.interceptors.i1.type=regex_filtera1.sources.s1.interceptors.i1.regex=\\{.*\\}a1.sources.r1.interceptors.i1.excludeEvents = falsea1.sources.s1.interceptors.i2.type=timestamp# 指定缓冲区和batchdataa1.channels.c1.type=memorya1.channels.c1.capacity=30000a1.channels.c1.transactionCapacity=1000# 连接hdfsa1.sinks.k1.type=hdfsa1.sinks.k1.channel=c1a1.sinks.k1.hdfs.path=hdfs://192.168.19.137:9000/user/hive/warehouse/profile.db/user_action/%Y-%m-%da1.sinks.k1.hdfs.useLocalTimeStamp = truea1.sinks.k1.hdfs.fileType=DataStreama1.sinks.k1.hdfs.writeFormat=Texta1.sinks.k1.hdfs.rollInterval=0a1.sinks.k1.hdfs.rollSize=10240a1.sinks.k1.hdfs.rollCount=0a1.sinks.k1.hdfs.idleTimeout=60</code></pre><p>hive 中创建数据库和表</p><pre><code class="sql">create database if not exists profile comment "user action" location '/user/hive/warehouse/profile.db/';create table user_action(actionTime STRING comment "user actions time",readTime STRING comment "user reading time",channelId INT comment "article channel id",param map comment "action parameter")COMMENT "user primitive action"PARTITIONED BY(dt STRING)ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'LOCATION '/user/hive/warehouse/profile.db/user_action';</code></pre><p><code>ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'</code>:添加 json 格式匹配功能</p><p>flume 会自动生成目录，在 hive 内部表上直接同步。但是如果想要通过 spark sql 获取内容，每天还是要主动关联：</p><pre><code class="sql">alter table user_action add partition (dt='2023-02-11') location "/user/hive/warehouse/profile.db/user_action/2023-02-11/"</code></pre><h3 id="使用-supervisor-管理-flume-进程"><a href="#使用-supervisor-管理-flume-进程" class="headerlink" title="使用 supervisor 管理 flume 进程"></a>使用 supervisor 管理 flume 进程</h3><p>flume 及其依赖写入脚本/root/toutiao_project/scripts/collect-click.sh</p><pre><code class="shell">#!/usr/bin/env bashexport JAVA_HOME=/root/bigdata/jdkexport HADOOP_HOME=/root/bigdata/hadoopexport PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin/root/bigdata/flume/bin/flume-ng agent -c /root/bigdata/flume/conf -f /root/bigdata/flume/conf/collect_click.conf -Dflume.root.logger=INFO,console -name a1</code></pre><p>在/etc/supervisor 的 reco.conf 添加</p><pre><code class="shell">[program:collect-click]command=/bin/bash /root/toutiao_project/scripts/collect_click.shuser=rootautorestart=trueredirect_stderr=truestdout_logfile=/root/logs/collect.logloglevel=infostopsignal=KILLstopasgroup=truekillasgroup=true</code></pre><p>最后用 supervisord 启动收集</p><pre><code class="shell">pip install supervisorsupervisord -c /etc/supervisord.confsupervisorctl status</code></pre><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><pre><code class="shell">echo {\"actionTime\":\"2023-02-11 21:04:39\",\"readTime\":\"\",\"channelId\":18,\"param\":{\"action\": \"click\", \"userId\": \"2\", \"articleId\": \"14299\", \"algorithmCombine\": \"C2\"}} &gt;&gt; userClick.log</code></pre><p>在 <a href="http://192.168.19.137:50070/explorer.html#/user/hive/warehouse/profile.db/user_action/">前端页面</a> 和 hive 中应当看到结果。</p><h2 id="离线文章画像计算"><a href="#离线文章画像计算" class="headerlink" title="离线文章画像计算"></a>离线文章画像计算</h2><h3 id="原始文章数据合并"><a href="#原始文章数据合并" class="headerlink" title="原始文章数据合并"></a>原始文章数据合并</h3><ol><li>创建 spark 基类</li><li>启动 jupyter</li></ol><pre><code class="shell">source activate py365jupyter notebook --allow-root --ip=192.168.19.137# 密码：123</code></pre><ol start="3"><li>运行 full_call/merge_data</li></ol><h3 id="历史文章-tfidf-计算"><a href="#历史文章-tfidf-计算" class="headerlink" title="历史文章 tfidf 计算"></a>历史文章 tfidf 计算</h3><ol><li>jieba 分词，去除停用词，保留名词、英文和自定义词库中的词</li><li>使用 spark ML 中 CountVectorizer 包进行词频统计，得到词袋模型/字典<br><img src="/image-20230211214707213.png"></li><li>使用 spark ML 中 IDF 包进一步计算每个单词的权重</li><li>根据索引和权重排序得到可以每篇文章权重最高的 20 个词</li></ol><h3 id="历史文章-textrank-计算"><a href="#历史文章-textrank-计算" class="headerlink" title="历史文章 textrank 计算"></a>历史文章 textrank 计算</h3><pre><code class="python">def textrank(partition):    import os    import jieba    import jieba.analyse    import jieba.posseg as pseg    import codecs    abspath = "/root/words"    # 结巴加载用户词典    userDict_path = os.path.join(abspath, "ITKeywords.txt")    jieba.load_userdict(userDict_path)    # 停用词文本    stopwords_path = os.path.join(abspath, "stopwords.txt")    def get_stopwords_list():        """返回stopwords列表"""        stopwords_list = [i.strip()                          for i in codecs.open(stopwords_path).readlines()]        return stopwords_list    # 所有的停用词列表    stopwords_list = get_stopwords_list()    class TextRank(jieba.analyse.TextRank):        def __init__(self, window=20, word_min_len=2):            super(TextRank, self).__init__()            self.span = window  # 窗口大小            self.word_min_len = word_min_len  # 单词的最小长度            # 要保留的词性，根据jieba github ，具体参见https://github.com/baidu/lac            self.pos_filt = frozenset(                ('n', 'x', 'eng', 'f', 's', 't', 'nr', 'ns', 'nt', "nw", "nz", "PER", "LOC", "ORG"))        def pairfilter(self, wp):            """过滤条件，返回True或者False"""            if wp.flag == "eng":                if len(wp.word) &lt;= 2:                    return False            if wp.flag in self.pos_filt and len(wp.word.strip()) &gt;= self.word_min_len \                    and wp.word.lower() not in stopwords_list:                return True    # TextRank过滤窗口大小为5，单词最小为2    textrank_model = TextRank(window=5, word_min_len=2)    allowPOS = ('n', "x", 'eng', 'nr', 'ns', 'nt', "nw", "nz", "c")</code></pre><p>同样可以给出 20 个关键词。但是最终结果由 Textank * IDF 再取前 20 给出<br><img src="/image-20230211220415129.png"></p><h3 id="训练词向量模型-word2vec-和增量文章编码"><a href="#训练词向量模型-word2vec-和增量文章编码" class="headerlink" title="训练词向量模型 word2vec 和增量文章编码"></a>训练词向量模型 word2vec 和增量文章编码</h3><pre><code class="python">from pyspark.ml.feature import Word2Vec# minCount忽略总频率低于此频率的所有单词w2v = Word2Vec(vectorSize=100, inputCol='words', outputCol='model', minCount=3)w2v_model = w2v.fit(words_df)w2v_model.write().overwrite().save("hdfs://hadoop-master:9000/headlines/models/test.word2vec")from pyspark.ml.feature import Word2VecModelword_vec = Word2VecModel.load("hdfs://hadoop-master:9000/headlines/models/test.word2vec")vectors = word_vec.getVectors()</code></pre><p>编码后和每个单词权重相乘，最终得到每篇文章的特征向量（文章画像）</p><h3 id="用-Apscheduler-定时更新文章画像"><a href="#用-Apscheduler-定时更新文章画像" class="headerlink" title="用 Apscheduler 定时更新文章画像"></a>用 Apscheduler 定时更新文章画像</h3><ol><li>增量更新文章编码，包括 hive 里的 article_profile<blockquote><p>新词可以用平均值填充</p></blockquote></li><li>定期重新计算 tfidf、textrank 和 word2vec 模型</li><li>Apsheduler 是 crontab 升级版</li></ol><pre><code class="python">import sysimport osBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))sys.path.insert(0, os.path.join(BASE_DIR))sys.path.insert(0, os.path.join(BASE_DIR, 'reco_sys'))from apscheduler.schedulers.blocking import BlockingSchedulerfrom apscheduler.executors.pool import ProcessPoolExecutorfrom scheduler.update import update_article_profile# 创建scheduler，多进程执行executors = {    'default': ProcessPoolExecutor(3)}scheduler = BlockingScheduler(executors=executors)# 添加定时更新任务更新文章画像,每隔一小时更新scheduler.add_job(update_article_profile, trigger='interval', hours=1)scheduler.start()</code></pre><h1 id="离线用户召回集与排序计算"><a href="#离线用户召回集与排序计算" class="headerlink" title="离线用户召回集与排序计算"></a>离线用户召回集与排序计算</h1><h2 id="用户画像存储与获取"><a href="#用户画像存储与获取" class="headerlink" title="用户画像存储与获取"></a>用户画像存储与获取</h2><p>用户画像需要快速迭代，方便读取，选择存储在 hbase 中。这里我们从 hbase 关联到 hive。</p><pre><code class="sql">create external table user_profile_hbase(user_id STRING comment "userID",information map&lt;string, DOUBLE&gt; comment "user basic information",article_partial map&lt;string, DOUBLE&gt; comment "article partial",env map&lt;string, INT&gt; comment "user env")COMMENT "user profile table"STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,basic:,partial:,env:")TBLPROPERTIES ("hbase.table.name" = "user_profile");</code></pre><p>读取 user_article_basic 表，<strong>合并行为表</strong>与<strong>文章画像中的主题词</strong></p><pre><code class="python"># 获取基本用户行为信息，然后进行文章画像的主题词合并uup.spark.sql("use profile")# 取出日志中的channel_iduser_article_ = uup.spark.sql("select * from user_article_basic").drop('channel_id')uup.spark.sql('use article')article_label = uup.spark.sql("select article_id, channel_id, topics from article_profile")# 合并使用文章中正确的channel_idclick_article_res = user_article_.join(article_label, how='left', on=['article_id'])</code></pre><h3 id="用户权重计算公式"><a href="#用户权重计算公式" class="headerlink" title="用户权重计算公式"></a>用户权重计算公式</h3><p><strong>用户标签权重 =( 行为类型权重之和) × 时间衰减</strong></p><table><thead><tr><th>行为</th><th>分值</th></tr></thead><tbody><tr><td>阅读时间(&lt;1000)</td><td>1</td></tr><tr><td>阅读时间(&gt;=1000)</td><td>2</td></tr><tr><td>收藏</td><td>2</td></tr><tr><td>分享</td><td>3</td></tr><tr><td>点击</td><td>5</td></tr><tr><td><strong>时间衰减</strong>=1/(log(t)+1) ,t 为时间发生时间距离当前时间的大小</td><td></td></tr></tbody></table><p>使用 happybase 关联文章表，统计每个词的标签权重，得到用户的关键词喜好 top10</p><pre><code class="python">import happybase#  用于读取hbase缓存结果配置pool = happybase.ConnectionPool(size=10, host='192.168.19.137', port=9090)with pool.connection() as conn:    table = conn.table('user_profile')    # 获取每个键 对应的所有列的结果    data = table.row(b'user:2', columns=[b'partial'])    conn.close()</code></pre><p>完善代码后，添加到 Apscheduler 中</p><pre><code class="python">scheduler.add_job(update_user_profile, trigger='interval', hours=2)</code></pre><h2 id="召回排序"><a href="#召回排序" class="headerlink" title="召回排序"></a>召回排序</h2><ul><li>用户冷启动（前期点击行为较少情况）<ul><li>非个性化推荐<ul><li><strong>热门召回</strong>：自定义热门规则，根据当前时间段热点定期更新维护<em>热点文章库</em></li><li><strong>新文章召回</strong>：为了提高新文章的曝光率，建立<em>新文章库</em>，进行推荐</li></ul></li><li>个性化推荐：<ul><li><strong>基于内容的协同过滤在线召回</strong>：基于用户实时兴趣画像相似的召回结果用于首页的个性化推荐</li></ul></li></ul></li><li>后期离线部分（用户点击行为较多，用户画像完善）<ul><li>建立用户长期兴趣画像（详细）：包括用户各个维度的兴趣特征</li><li>训练排序模型<ul><li><strong>LR 模型、FTRL、Wide&amp;Deep</strong></li></ul></li><li>离线部分的召回：<ul><li><strong>基于模型协同过滤推荐离线召回</strong>：ALS</li><li><strong>基于内容的离线召回</strong>：或者称基于用户画像的召回</li></ul></li></ul></li></ul><h3 id="基于-ALS-模型的召回"><a href="#基于-ALS-模型的召回" class="headerlink" title="基于 ALS 模型的召回"></a>基于 ALS 模型的召回</h3><pre><code class="python">from pyspark.ml.recommendation import ALS# 模型训练和推荐默认每个用户固定文章个数als = ALS(userCol='als_user_id', itemCol='als_article_id', ratingCol='clicked', checkpointInterval=1)model = als.fit(als_user_article_click)recall_res = model.recommendForAllUsers(100)</code></pre><p>召回结果存储</p><pre><code class="python">def save_offline_recall_hbase(partition):    """离线模型召回结果存储    """    import happybase    pool = happybase.ConnectionPool(size=10, host='hadoop-master', port=9090)    for row in partition:        with pool.connection() as conn:            # 获取历史看过的该频道文章            history_table = conn.table('history_recall')            # 多个版本            data = history_table.cells('reco:his:{}'.format(row.user_id).encode(),                                       'channel:{}'.format(row.channel_id).encode())            history = []            if len(data) &gt;= 2:                for l in data[:-1]:                    history.extend(eval(l))            else:                history = []            # 过滤reco_article与history            reco_res = list(set(row.article_list) - set(history))            if reco_res:                table = conn.table('cb_recall')                # 默认放在推荐频道                table.put('recall:user:{}'.format(row.user_id).encode(),                          {'als:{}'.format(row.channel_id).encode(): str(reco_res).encode()})                conn.close()                # 放入历史推荐过文章                history_table.put("reco:his:{}".format(row.user_id).encode(),                                  {'channel:{}'.format(row.channel_id): str(reco_res).encode()})            conn.close()als_recall.foreachPartition(save_offline_recall_hbase)</code></pre><h3 id="基于内容的召回"><a href="#基于内容的召回" class="headerlink" title="基于内容的召回"></a>基于内容的召回</h3><p>即根据 LHS 等算法，快速得到用户当前点击文章的相似文章集，进行推荐。</p><pre><code class="python"># 循环partitionfor row in partition:    # 获取相似文章结果表    similar_article = similar_table.row(str(row.article_id).encode(),                                        columns=[b'similar'])    # 相似文章相似度排序过滤，召回不需要太大的数据， 百个，千    _srt = sorted(similar_article.items(), key=lambda item: item[1], reverse=True)    if _srt:        # 每次行为推荐若干篇文章        reco_article = [int(i[0].split(b':')[1]) for i in _srt][:10]</code></pre><blockquote><p>基于内容和基于模型的结果存入同一张 hbase 表</p></blockquote><pre><code class="sql">create external table cb_recall_hbase(user_id STRING comment "userID",als map&lt;string, ARRAY&lt;BIGINT&gt;&gt; comment "als recall",content map&lt;string, ARRAY&lt;BIGINT&gt;&gt; comment "content recall",online map&lt;string, ARRAY&lt;BIGINT&gt;&gt; comment "online recall")COMMENT "user recall table"STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'WITH SERDEPROPERTIES ("hbase.columns.mapping" = ":key,als:,content:,online:")TBLPROPERTIES ("hbase.table.name" = "cb_recall");</code></pre><h3 id="离线排序模型-CTR"><a href="#离线排序模型-CTR" class="headerlink" title="离线排序模型 CTR"></a>离线排序模型 CTR</h3><p>CTR（Click-Through Rate）预估：给定一个 Item，预测该 Item 会被点击的概率<br>最基础的模型目前都是基于 LR 的点击率预估策略，目前在工业使用模型做预估的有这么几种类型</p><ul><li>宽模型 + 特征⼯程<ul><li>LR/MLR + 非 ID 类特征(⼈⼯离散/GBDT/FM)</li><li>spark 中可以直接使用</li></ul></li><li>宽模型 + 深模型<ul><li>wide&amp;deep,DeepFM</li><li>使用 TensorFlow 进行训练</li></ul></li><li>深模型：<ul><li>DNN + 特征 embedding</li><li>使用 TensorFlow 进行训练</li></ul></li></ul><p>特征包含：用户画像关键词 10+文章画像关键词 10+channel_id(25, onehot)+文章主题词向量(concat, 100)</p><pre><code class="python">cols = ['article_id', 'user_id', 'channel_id', 'articlevector', 'weights', 'article_weights', 'clicked']train_version_two = VectorAssembler().setInputCols(cols[2:6]).setOutputCol("features").transform(train)</code></pre><p><img src="/image-20230212102837399.png"><br>训练线性回归模型，可以服务于在线召回</p><pre><code class="python">lr = LogisticRegression()model = lr.setLabelCol("clicked").setFeaturesCol("features").fit(train_version_two)model.save("hdfs://hadoop-master:9000/headlines/models/lr.obj")</code></pre><p>定期重新训练</p><h1 id="实时计算业务"><a href="#实时计算业务" class="headerlink" title="实时计算业务"></a>实时计算业务</h1><p>实时（在线）计算：</p><ul><li>解决用户冷启动问题</li><li>实时计算能够根据用户的点击实时反馈，快速跟踪用户的喜好</li></ul><p>日志数据我们已经收集到 hadoop 中，但是做实时分析的时候，我们需要将每个时刻用户产生的点击行为收集到 KAFKA 当中，等待 spark streaming 程序去消费。</p><h2 id="Kafka-简介"><a href="#Kafka-简介" class="headerlink" title="Kafka 简介"></a>Kafka 简介</h2><p><strong>Kafka</strong>是由<a href="https://zh.wikipedia.org/wiki/Apache%E8%BD%AF%E4%BB%B6%E5%9F%BA%E9%87%91%E4%BC%9A" title="Apache软件基金会">Apache 软件基金会</a>开发的一个<a href="https://zh.wikipedia.org/wiki/%E5%BC%80%E6%BA%90" title="开源">开源</a><a href="https://zh.wikipedia.org/wiki/%E6%B5%81%E5%A4%84%E7%90%86" title="流处理">流处理</a>平台，由<a href="https://zh.wikipedia.org/wiki/Scala" title="Scala">Scala</a>和<a href="https://zh.wikipedia.org/wiki/Java" title="Java">Java</a>编写。该项目的目标是为处理实时数据提供一个统一、高吞吐、低延迟的平台。其持久化层本质上是一个“按照分布式事务日志架构的大规模发布/订阅消息队列”，这使它作为企业级基础设施来处理流式数据非常有价值。</p><h2 id="flume-收集日志到-kafka"><a href="#flume-收集日志到-kafka" class="headerlink" title="flume 收集日志到 kafka"></a>flume 收集日志到 kafka</h2><p>开启 zookeeper,需要在一直在服务器端实时运行，以守护进程运行</p><pre><code class="shell">/root/bigdata/kafka/bin/zookeeper-server-start.sh -daemon /root/bigdata/kafka/config/zookeeper.properties</code></pre><p>以及 kafka</p><pre><code>/root/bigdata/kafka/bin/kafka-server-start.sh /root/bigdata/kafka/config/server.properties</code></pre><p>测试</p><pre><code class="shell"> #开启消息生产者/root/bigdata/kafka/bin/kafka-console-producer.sh --broker-list 192.168.19.137:9092 --sync --topic click-trace #开启消费者/root/bigdata/kafka/bin/kafka-console-consumer.sh --bootstrap-server 192.168.19.137:9092 --topic  click-trace#在生产者窗口输入任意内容测试</code></pre><p>修改原来收集日志的文件，添加 flume 收集日志行为到 kafka 的 source, channel, sink</p><pre><code>a1.sources = s1a1.sinks = k1 k2a1.channels = c1 c2a1.sources.s1.channels= c1 c2a1.sources.s1.type = execa1.sources.s1.command = tail -F /root/logs/userClick.loga1.sources.s1.interceptors=i1 i2a1.sources.s1.interceptors.i1.type=regex_filtera1.sources.r1.interceptors.i1.excludeEvents = falsea1.sources.s1.interceptors.i1.regex=\\{.*\\}a1.sources.s1.interceptors.i2.type=timestamp# channel1a1.channels.c1.type=memorya1.channels.c1.capacity=30000a1.channels.c1.transactionCapacity=1000# channel2a1.channels.c2.type=memorya1.channels.c2.capacity=30000a1.channels.c2.transactionCapacity=1000# k1a1.sinks.k1.type=hdfsa1.sinks.k1.channel=c1a1.sinks.k1.hdfs.path=hdfs://192.168.19.137:9000/user/hive/warehouse/profile.db/user_action/%Y-%m-%da1.sinks.k1.hdfs.useLocalTimeStamp = truea1.sinks.k1.hdfs.fileType=DataStreama1.sinks.k1.hdfs.writeFormat=Texta1.sinks.k1.hdfs.rollInterval=0a1.sinks.k1.hdfs.rollSize=10240a1.sinks.k1.hdfs.rollCount=0a1.sinks.k1.hdfs.idleTimeout=60# k2a1.sinks.k2.channel=c2a1.sinks.k2.type=org.apache.flume.sink.kafka.KafkaSinka1.sinks.k2.kafka.bootstrap.servers=192.168.19.137:9092a1.sinks.k2.kafka.topic=click-tracea1.sinks.k2.kafka.batchSize=20a1.sinks.k2.kafka.producer.requiredAcks=1</code></pre><p>添加 supervisor 配置</p><pre><code>[program:kafka]command=/bin/bash /root/toutiao_project/scripts/start_kafka.shuser=rootautorestart=trueredirect_stderr=truestdout_logfile=/root/logs/kafka.logloglevel=infostopsignal=KILLstopasgroup=truekillasgroup=true</code></pre><p>用 supervisorctl 启动后测试</p><h2 id="实时召回集业务"><a href="#实时召回集业务" class="headerlink" title="实时召回集业务"></a>实时召回集业务</h2><p>实时召回基于相似度的文章推荐</p><p>创建 online 文件夹，建立在线实时处理程序</p><ul><li>目的：对用户日志进行处理，实时达到求出相似文章，放入用户召回集合中</li><li>步骤：<ul><li>1、配置 spark streaming 信息</li><li>2、读取点击行为日志数据，获取相似文章列表</li><li>3、过滤历史文章集合</li><li>4、存入召回结果以及历史记录结果</li></ul></li></ul><p>happybase 和 kafka 对接 spark streaming 的配置</p><pre><code class="python"># 增加spark online 启动配置class DefaultConfig(object):    """默认的一些配置信息    """    SPARK_ONLINE_CONFIG = (        ("spark.app.name", "onlineUpdate"),  # 设置启动的spark的app名称，没有提供，将随机产生一个名称        ("spark.master", "yarn"),        ("spark.executor.instances", 4)    )# 添加sparkstreaming启动对接kafka的配置from pyspark import SparkConffrom pyspark.sql import SparkSessionfrom pyspark import SparkContextfrom pyspark.streaming import StreamingContextfrom pyspark.streaming.kafka import KafkaUtilsfrom setting.default import DefaultConfigimport happybase#  用于读取hbase缓存结果配置pool = happybase.ConnectionPool(size=10, host='hadoop-master', port=9090)# 1、创建confconf = SparkConf()conf.setAll(DefaultConfig.SPARK_ONLINE_CONFIG)# 建立spark session以及spark streaming contextsc = SparkContext(conf=conf)# 创建Streaming Contextstream_c = StreamingContext(sc, 60)# KAFKA配置KAFKA_SERVER = "192.168.19.137:9092"# 基于内容召回配置，用于收集用户行为，获取相似文章实时推荐similar_kafkaParams = {"metadata.broker.list": DefaultConfig.KAFKA_SERVER, "group.id": 'similar'}SIMILAR_DS = KafkaUtils.createDirectStream(stream_c, ['click-trace'], similar_kafkaParams)</code></pre><p>主代码</p><pre><code class="python">class OnlineRecall(object):"""在线处理计算平台"""    def __init__(self):        pass        def _update_online_cb(self):            """            通过点击行为更新用户的cb召回表中的online召回结果            :return:            """            def foreachFunc(rdd):                    for data in rdd.collect():                    logger.info(                        "{}, INFO: rdd filter".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')))                    # 判断日志行为类型，只处理点击流日志                    if data["param"]["action"] in ["click", "collect", "share"]:                        # print(data)                        with pool.connection() as conn:                            try:                                # 相似文章表                                sim_table = conn.table("article_similar")                                    # 根据用户点击流日志涉及文章找出与之最相似文章(基于内容的相似)，选取TOP-k相似的作为召回推荐结果                                _dic = sim_table.row(str(data["param"]["articleId"]).encode(), columns=[b"similar"])                                _srt = sorted(_dic.items(), key=lambda obj: obj[1], reverse=True)  # 按相似度排序                                if _srt:                                        topKSimIds = [int(i[0].split(b":")[1]) for i in _srt[:self.k]]                                        # 根据历史推荐集过滤，已经给用户推荐过的文章                                    history_table = conn.table("history_recall")                                        _history_data = history_table.cells(                                        b"reco:his:%s" % data["param"]["userId"].encode(),                                        b"channel:%d" % data["channelId"]                                    )                                    # print("_history_data: ", _history_data)                                        history = []                                    if len(data) &gt;= 2:                                        for l in data[:-1]:                                            history.extend(eval(l))                                    else:                                        history = []                                        # 根据历史召回记录，过滤召回结果                                    recall_list = list(set(topKSimIds) - set(history_data))                                        # print("recall_list: ", recall_list)                                    logger.info("{}, INFO: store user:{} cb_recall data".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), data["param"]["userId"]))                                    if recall_list:                                        # 如果有推荐结果集，那么将数据添加到cb_recall表中，同时记录到历史记录表中                                        logger.info(                                            "{}, INFO: get online-recall data".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')))                                        recall_table = conn.table("cb_recall")                                            recall_table.put(                                            b"recall:user:%s" % data["param"]["userId"].encode(),                                            {b"online:%d" % data["channelId"]: str(recall_list).encode()}                                        )                                            history_table.put(                                            b"reco:his:%s" % data["param"]["userId"].encode(),                                            {b"channel:%d" % data["channelId"]: str(recall_list).encode()}                                        )                            except Exception as e:                                logger.info("{}, WARN: {}".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), e))                            finally:                                conn.close()                SIMILAR_DS.map(lambda x: json.loads(x[1])).foreachRDD(foreachFunc)                return None</code></pre><h1 id="推荐业务流实现与-AB-测试"><a href="#推荐业务流实现与-AB-测试" class="headerlink" title="推荐业务流实现与 AB 测试"></a>推荐业务流实现与 AB 测试</h1><ul><li><p>逻辑流程</p><ul><li>1、后端发送推荐请求，实时推荐系统拿到请求参数<ul><li>grpc对接</li></ul></li><li>2、根据用户进行ABTest分流<ul><li>ABTest实验中心，用于进行分流任务，方便测试调整不同的模型上线</li></ul></li><li>3、推荐中心服务<ul><li>根据用户在ABTest分配的算法进行召回服务和排序服务读取返回结果</li></ul></li><li>4、返回推荐结果和埋点参数封装</li></ul></li></ul><p><img src="/image-20230212160039176.png"></p><h2 id="gRPC"><a href="#gRPC" class="headerlink" title="gRPC"></a>gRPC</h2><ul><li>gRPC是由Google公司开源的高性能RPC框架。</li><li>gRPC支持多语言<br>gRPC原生使用C、Java、Go进行了三种实现，而C语言实现的版本进行封装后又支持C++、C#、Node、ObjC、 Python、Ruby、PHP等开发语言</li><li>gRPC支持多平台<br>支持的平台包括：Linux、Android、iOS、MacOS、Windows</li><li>gRPC的消息协议使用Google自家开源的Protocol Buffers协议机制（proto3） 序列化</li><li>gRPC的传输使用HTTP/2标准，支持双向流和连接多路复用</li></ul><h3 id="创建user-reco-proto协议文件"><a href="#创建user-reco-proto协议文件" class="headerlink" title="创建user_reco.proto协议文件"></a>创建user_reco.proto协议文件</h3><ul><li>用户刷新feed流接口<ul><li>user_recommend(User) returns (Track)</li></ul></li><li>文章相似(猜你喜欢)接口<ul><li>article_recommend(Article) returns(Similar)</li></ul></li></ul><p>编写grpc_tools.protoc</p><pre><code class="shell">syntax = "proto3";message User {    string user_id = 1;    int32 channel_id = 2;    int32 article_num = 3;    int64 time_stamp = 4;}// int32 ---&gt; int64 article_idmessage Article {    int64 article_id = 1;    int32 article_num = 2;}message param2 {    string click = 1;    string collect = 2;    string share = 3;    string read = 4;}message param1 {    int64 article_id = 1;    param2 params = 2;}message Track {    string exposure = 1;    repeated param1 recommends = 2;    int64 time_stamp = 3;}message Similar {    repeated int64 article_id = 1;}service UserRecommend {    // feed recommend    rpc user_recommend(User) returns (Track) {}    rpc article_recommend(Article) returns(Similar) {}}</code></pre><p>通过命令生成</p><pre><code class="shell">python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. user_reco.proto</code></pre><h3 id="服务端编写"><a href="#服务端编写" class="headerlink" title="服务端编写"></a>服务端编写</h3><pre><code class="python"># route.py# 基于用户推荐的rpc服务推荐# 定义指定的rpc服务输入输出参数格式protoRPC_SERVER = '192.168.19.137:9999'class UserRecommendServicer(user_reco_pb2_grpc.UserRecommendServicer):    """    对用户进行技术文章推荐    """    def user_recommend(self, request, context):        """        用户feed流推荐        :param request:        :param context:        :return:        """        # 选择C4组合        user_id = request.user_id        channel_id = request.channel_id        article_num = request.article_num        time_stamp = request.time_stamp        # 解析参数，并进行推荐中心推荐(暂时使用假数据替代)        class Temp(object):            user_id = -10            algo = 'test'            time_stamp = -10        tp = Temp()        tp.user_id = user_id        tp.time_stamp = time_stamp        _track = add_track([], tp)        # 解析返回参数到rpc结果参数        # 参数如下        # [       {"article_id": 1, "param": {"click": "", "collect": "", "share": "", 'detentionTime':''}},        #         {"article_id": 2, "param": {"click": "", "collect": "", "share": "", 'detentionTime':''}},        #         {"article_id": 3, "param": {"click": "", "collect": "", "share": "", 'detentionTime':''}},        #         {"article_id": 4, "param": {"click": "", "collect": "", "share": "", 'detentionTime':''}}        #     ]        # 第二个rpc参数        _param1 = []        for _ in _track['recommends']:            # param的封装            _params = user_reco_pb2.param2(click=_['param']['click'],                                           collect=_['param']['collect'],                                           share=_['param']['share'],                                           read=_['param']['read'])            _p2 = user_reco_pb2.param1(article_id=_['article_id'], params=_params)            _param1.append(_p2)        # param        return user_reco_pb2.Track(exposure=_track['param'], recommends=_param1, time_stamp=_track['timestamp'])#    def article_recommend(self, request, context):#        """#       文章相似推荐#       :param request:#       :param context:#       :return:#       """#       # 获取web参数#       article_id = request.article_id#       article_num = request.article_num##        # 进行文章相似推荐,调用推荐中心的文章相似#       _article_list = article_reco_list(article_id, article_num, 105)##       # rpc参数封装#       return user_reco_pb2.Similar(article_id=_article_list)def add_track(res, temp):    """    封装埋点参数    :param res: 推荐文章id列表    :param cb: 合并参数    :param rpc_param: rpc参数    :return: 埋点参数        文章列表参数        单文章参数    """    # 添加埋点参数    track = {}    # 准备曝光参数    # 全部字符串形式提供，在hive端不会解析问题    _exposure = {"action": "exposure", "userId": temp.user_id, "articleId": json.dumps(res),                 "algorithmCombine": temp.algo}    track['param'] = json.dumps(_exposure)    track['recommends'] = []    # 准备其它点击参数    for _id in res:        # 构造字典        _dic = {}        _dic['article_id'] = _id        _dic['param'] = {}        # 准备click参数        _p = {"action": "click", "userId": temp.user_id, "articleId": str(_id),              "algorithmCombine": temp.algo}        _dic['param']['click'] = json.dumps(_p)        # 准备collect参数        _p["action"] = 'collect'        _dic['param']['collect'] = json.dumps(_p)        # 准备share参数        _p["action"] = 'share'        _dic['param']['share'] = json.dumps(_p)        # 准备detentionTime参数        _p["action"] = 'read'        _dic['param']['read'] = json.dumps(_p)        track['recommends'].append(_dic)    track['timestamp'] = temp.time_stamp    return trackdef serve():    # 多线程服务器    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))    # 注册本地服务    user_reco_pb2_grpc.add_UserRecommendServicer_to_server(UserRecommendServicer(), server)    # 监听端口    server.add_insecure_port(DefaultConfig.RPC_SERVER)    # 开始接收请求进行服务    server.start()    # 使用 ctrl+c 可以退出服务    _ONE_DAY_IN_SECONDS = 60 * 60 * 24    try:        while True:            time.sleep(_ONE_DAY_IN_SECONDS)    except KeyboardInterrupt:        server.stop(0)if __name__ == '__main__':    # 测试grpc服务    serve()</code></pre><p>客户端测试代码：</p><pre><code class="python">import osimport sysBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))sys.path.insert(0, os.path.join(BASE_DIR))from abtest import user_reco_pb2_grpcfrom abtest import user_reco_pb2import grpcfrom setting.default import DefaultConfigimport timedef test():    article_dict = {}    # 构造传入数据    req_article = user_reco_pb2.User()    req_article.user_id = '1115629498121846784'    req_article.channel_id = 18    req_article.article_num = 10    req_article.time_stamp = int(time.time() * 1000)    # req_article.time_stamp = 1555573069870    with grpc.insecure_channel(DefaultConfig.RPC_SERVER) as rpc_cli:        print('''''')        try:            stub = user_reco_pb2_grpc.UserRecommendStub(rpc_cli)            resp = stub.user_recommend(req_article)        except Exception as e:            print(e)            article_dict['param'] = []        else:            # 解析返回结果参数            article_dict['exposure_param'] = resp.exposure            reco_arts = resp.recommends            reco_art_param = []            reco_list = []            for art in reco_arts:                reco_art_param.append({                    'artcle_id': art.article_id,                    'params': {                        'click': art.params.click,                        'collect': art.params.collect,                        'share': art.params.share,                        'read': art.params.read                    }                })                reco_list.append(art.article_id)            article_dict['param'] = reco_art_param            # 文章列表以及参数（曝光参数 以及 每篇文章的点击等参数）            print(reco_list, article_dict)if __name__ == '__main__':    test()</code></pre><h2 id="通过哈希分桶进行流量切分"><a href="#通过哈希分桶进行流量切分" class="headerlink" title="通过哈希分桶进行流量切分"></a>通过哈希分桶进行流量切分</h2><pre><code class="python">def feed_recommend(user_id, channel_id, article_num, time_stamp):    """    1、根据web提供的参数，进行分流    2、找到对应的算法组合之后，去推荐中心调用不同的召回和排序服务    3、进行埋点参数封装    :param user_id:用户id    :param article_num:推荐文章个数    :return: track:埋点参数结果: 参考上面埋点参数组合    """    #  产品前期推荐由于较少的点击行为，所以去做 用户冷启动 + 文章冷启动    # 用户冷启动：'推荐'频道：热门频道的召回+用户实时行为画像召回（在线的不保存画像）  'C2'组合    #            # 其它频道：热门召回 + 新文章召回   'C1'组合    # 定义返回参数的类    class TempParam(object):        user_id = -10        channel_id = -10        article_num = -10        time_stamp = -10        algo = ""    temp = TempParam()    temp.user_id = user_id    temp.channel_id = channel_id    temp.article_num = article_num    # 请求的时间戳大小    temp.time_stamp = time_stamp    # 先读取缓存数据redis+待推荐hbase结果    # 如果有返回并加上埋点参数    # 并且写入hbase 当前推荐时间戳用户（登录和匿名）的历史推荐文章列表    # 传入用户id为空的直接召回结果    if temp.user_id == "":        temp.algo = ""        return add_track([], temp)    # 进行分桶实现分流，制定不同的实验策略    bucket = hashlib.md5(user_id.encode()).hexdigest()[:1]    if bucket in RAParam.BYPASS[0]['Bucket']:        temp.algo = RAParam.BYPASS[0]['Strategy']    else:        temp.algo = RAParam.BYPASS[1]['Strategy']    # 推荐服务中心推荐结果(这里做测试)    track = add_track([], temp)    return track</code></pre><h2 id="推荐服务中心"><a href="#推荐服务中心" class="headerlink" title="推荐服务中心"></a>推荐服务中心</h2><ul><li>根据时间戳<ul><li>时间戳T小于HBASE历史推荐记录，则获取历史记录，返回该时间戳T上次的时间戳T-1</li><li>时间戳T大于HBASE历史推荐记录，则获取新推荐，则获取HBASE数据库中最近的一次时间戳<ul><li>如果有缓存，从缓存中拿，并且写入推荐历史表中</li><li>如果没有缓存，就进行一次指定算法组合的召回结果读取，排序，然后写入待推荐wait_recommend中，其中推荐出去的放入历史推荐表中</li></ul></li></ul></li></ul><h3 id="推荐中心业务逻辑"><a href="#推荐中心业务逻辑" class="headerlink" title="推荐中心业务逻辑"></a>推荐中心业务逻辑</h3><pre><code class="python">def feed_recommend_logic(self, temp):    """推荐流业务逻辑    :param temp:ABTest传入的业务请求参数    """    # 判断用请求的时间戳大小决定获取历史记录还是刷新推荐文章    try:        last_stamp = self.hbu.get_table_row('history_recommend', 'reco:his:{}'.format(temp.user_id).encode(),                                            'channel:{}'.format(temp.channel_id).encode(), include_timestamp=True)[1]        logger.info("{} INFO get user_id:{} channel:{} history last_stamp".format(            datetime.now().strftime('%Y-%m-%d %H:%M:%S'), temp.user_id, temp.channel_id))    except Exception as e:        logger.warning("{} WARN read history recommend exception:{}".format(            datetime.now().strftime('%Y-%m-%d %H:%M:%S'), e))        last_stamp = 0    # 如果小于，走一遍正常的推荐流程，缓存或者召回排序    logger.info("{} INFO history last_stamp:{},temp.time_stamp:{}".                format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), last_stamp, temp.time_stamp))    if last_stamp &lt; temp.time_stamp:        # 获取        res = redis_cache.get_reco_from_cache(temp, self.hbu)        # 如果没有，然后走一遍算法推荐 召回+排序，同时写入到hbase待推荐结果列表        if not res:            logger.info("{} INFO get user_id:{} channel:{} recall/sort data".                        format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), temp.user_id, temp.channel_id))            res = self.user_reco_list(temp)        temp.time_stamp = int(last_stamp)        track = add_track(res, temp)    else:        logger.info("{} INFO read user_id:{} channel:{} history recommend data".format(            datetime.now().strftime('%Y-%m-%d %H:%M:%S'), temp.user_id, temp.channel_id))        try:            row = self.hbu.get_table_cells('history_recommend',                                      'reco:his:{}'.format(temp.user_id).encode(),                                      'channel:{}'.format(temp.channel_id).encode(),                                      timestamp=temp.time_stamp + 1,                                      include_timestamp=True)        except Exception as e:            logger.warning("{} WARN read history recommend exception:{}".format(                datetime.now().strftime('%Y-%m-%d %H:%M:%S'), e))            row = []            res = []        # 1、如果没有历史数据，返回时间戳0以及结果空列表        # 2、如果历史数据只有一条，返回这一条历史数据以及时间戳正好为请求时间戳，修改时间戳为0        # 3、如果历史数据多条，返回最近一条历史数据，然后返回        if not row:            temp.time_stamp = 0            res = []        elif len(row) == 1 and row[0][1] == temp.time_stamp:            res = eval(row[0][0])            temp.time_stamp = 0        elif len(row) &gt;= 2:            res = eval(row[0][0])            temp.time_stamp = int(row[1][1])        res = list(map(int, res))        logger.info(            "{} INFO history:{}, {}".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), res, temp.time_stamp))        track = add_track(res, temp)        # 曝光参数设置为空        track['param'] = ''    return track</code></pre><h3 id="获取用户召回结果"><a href="#获取用户召回结果" class="headerlink" title="获取用户召回结果"></a>获取用户召回结果</h3><pre><code class="python">  def user_reco_list(self, temp):        """        获取用户的召回结果进行推荐        :param temp:        :return:        """        reco_set = []        # 1、循环算法组合参数，遍历不同召回结果进行过滤        for _num in RAParam.COMBINE[temp.algo][1]:            # 进行每个召回结果的读取100,101,102,103,104            if _num == 103:                # 新文章召回读取                _res = self.recall_service.read_redis_new_article(temp.channel_id)                reco_set = list(set(reco_set).union(set(_res)))            elif _num == 104:                # 热门文章召回读取                _res = self.recall_service.read_redis_hot_article(temp.channel_id)                reco_set = list(set(reco_set).union(set(_res)))            else:                _res = self.recall_service.\                    read_hbase_recall_data(RAParam.RECALL[_num][0],                                           'recall:user:{}'.format(temp.user_id).encode(),                                           '{}:{}'.format(RAParam.RECALL[_num][1], temp.channel_id).encode())                # 进行合并某个协同过滤召回的结果                reco_set = list(set(reco_set).union(set(_res)))        # reco_set都是新推荐的结果，进行过滤        history_list = []        try:            data = self.hbu.get_table_cells('history_recommend',                                            'reco:his:{}'.format(temp.user_id).encode(),                                            'channel:{}'.format(temp.channel_id).encode())            for _ in data:                history_list = list(set(history_list).union(set(eval(_))))            logger.info("{} INFO filter user_id:{} channel:{} history data".format(                datetime.now().strftime('%Y-%m-%d %H:%M:%S'), temp.user_id, temp.channel_id))        except Exception as e:            logger.warning(                "{} WARN filter history article exception:{}".format(datetime.now().                                                                     strftime('%Y-%m-%d %H:%M:%S'), e))        # 如果0号频道有历史记录，也需要过滤        try:            data = self.hbu.get_table_cells('history_recommend',                                            'reco:his:{}'.format(temp.user_id).encode(),                                            'channel:{}'.format(0).encode())            for _ in data:                history_list = list(set(history_list).union(set(eval(_))))            logger.info("{} INFO filter user_id:{} channel:{} history data".format(                datetime.now().strftime('%Y-%m-%d %H:%M:%S'), temp.user_id, 0))        except Exception as e:            logger.warning(                "{} WARN filter history article exception:{}".format(datetime.now().                                                                     strftime('%Y-%m-%d %H:%M:%S'), e))        # 过滤操作 reco_set 与history_list进行过滤        reco_set = list(set(reco_set).difference(set(history_list)))        # 排序代码逻辑        # _sort_num = RAParam.COMBINE[temp.algo][2][0]        # reco_set = sort_dict[RAParam.SORT[_sort_num]](reco_set, temp, self.hbu)        # 如果没有内容，直接返回        if not reco_set:            return reco_set        else:            # 类型进行转换            reco_set = list(map(int, reco_set))            # 跟后端需要推荐的文章数量进行比对 article_num            # article_num &gt; reco_set            if len(reco_set) &lt;= temp.article_num:                res = reco_set            else:                # 之取出推荐出去的内容                res = reco_set[:temp.article_num]                # 剩下的推荐结果放入wait_recommend等待下次帅新的时候直接推荐                self.hbu.get_table_put('wait_recommend',                                       'reco:{}'.format(temp.user_id).encode(),                                       'channel:{}'.format(temp.channel_id).encode(),                                       str(reco_set[temp.article_num:]).encode(),                                       timestamp=temp.time_stamp)                logger.info(                    "{} INFO put user_id:{} channel:{} wait data".format(                        datetime.now().strftime('%Y-%m-%d %H:%M:%S'), temp.user_id, temp.channel_id))            # 放入历史记录表当中            self.hbu.get_table_put('history_recommend',                                   'reco:his:{}'.format(temp.user_id).encode(),                                   'channel:{}'.format(temp.channel_id).encode(),                                   str(res).encode(),                                   timestamp=temp.time_stamp)            # 放入历史记录日志            logger.info(                "{} INFO store recall/sorted user_id:{} channel:{} history_recommend data".format(                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'), temp.user_id, temp.channel_id))            return res</code></pre><h3 id="在线预测"><a href="#在线预测" class="headerlink" title="在线预测"></a>在线预测</h3><p>除了对召回集进行排序以外，还可以在在线平台上使用离线训练好的点击率模型，得到高点击召回集。</p><pre><code class="python">def lr_sort_service(reco_set, temp, hbu):    """    排序返回推荐文章    :param reco_set:召回合并过滤后的结果    :param temp: 参数    :param hbu: Hbase工具    :return:    """    # 排序    # 1、读取用户特征中心特征    try:        user_feature = eval(hbu.get_table_row('ctr_feature_user',                                              '{}'.format(temp.user_id).encode(),                                              'channel:{}'.format(temp.channel_id).encode()))        logger.info("{} INFO get user user_id:{} channel:{} profile data".format(            datetime.now().strftime('%Y-%m-%d %H:%M:%S'), temp.user_id, temp.channel_id))    except Exception as e:        user_feature = []    if user_feature:        # 2、读取文章特征中心特征        result = []        for article_id in reco_set:            try:                article_feature = eval(hbu.get_table_row('ctr_feature_article',                                                         '{}'.format(article_id).encode(),                                                         'article:{}'.format(article_id).encode()))            except Exception as e:                article_feature = [0.0] * 111            f = []            # 第一个channel_id            f.extend([article_feature[0]])            # 第二个article_vector            f.extend(article_feature[11:])            # 第三个用户权重特征            f.extend(user_feature)            # 第四个文章权重特征            f.extend(article_feature[1:11])            vector = DenseVector(f)            result.append([temp.user_id, article_id, vector])        # 4、预测并进行排序是筛选        df = pd.DataFrame(result, columns=["user_id", "article_id", "features"])        test = SORT_SPARK.createDataFrame(df)        # 加载逻辑回归模型        model = LogisticRegressionModel.load("hdfs://hadoop-master:9000/headlines/models/LR.obj")        predict = model.transform(test)        def vector_to_double(row):            return float(row.article_id), float(row.probability[1])        res = predict.select(['article_id', 'probability']).rdd.map(vector_to_double).toDF(            ['article_id', 'probability']).sort('probability', ascending=False)        article_list = [i.article_id for i in res.collect()]        logger.info("{} INFO sorting user_id:{} recommend article".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'),                                                                          temp.user_id))        # 排序后，只将排名在前100个文章ID返回给用户推荐        if len(article_list) &gt; 100:            article_list = article_list[:100]        reco_set = list(map(int, article_list))    return reco_set</code></pre><h3 id="多路召回"><a href="#多路召回" class="headerlink" title="多路召回"></a>多路召回</h3><pre><code class="python">import osimport sysBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))sys.path.insert(0, os.path.join(BASE_DIR))from server import redis_clientfrom server import poolimport loggingfrom datetime import datetimefrom abtest.utils import HBaseUtilslogger = logging.getLogger('recommend')class ReadRecall(object):    """读取召回集的结果    """    def __init__(self):        self.client = redis_client        self.hbu = HBaseUtils(pool)    def read_hbase_recall_data(self, table_name, key_format, column_format):        """获取指定用户的对应频道的召回结果,在线画像召回，离线画像召回，离线协同召回        :return:        """        # 获取family对应的值        # 数据库中的键都是bytes类型，所以需要进行编码相加        # 读取召回结果多个版本合并        recall_list = []        try:            data = self.hbu.get_table_cells(table_name, key_format, column_format)            for _ in data:                recall_list = list(set(recall_list).union(set(eval(_))))            # 读取所有这个用户的在线推荐的版本，清空该频道的数据            # self.hbu.get_table_delete(table_name, key_format, column_format)        except Exception as e:            logger.warning(                "{} WARN read recall data exception:{}".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), e))        return recall_list    def read_redis_new_data(self, channel_id):        """获取redis新文章结果        :param channel_id:        :return:        """        # format结果        logger.info("{} INFO read channel:{} new recommend data".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), channel_id))        _key = "ch:{}:new".format(channel_id)        try:            res = self.client.zrevrange(_key, 0, -1)        except redis.exceptions.ResponseError as e:            logger.warning("{} WARN read new article exception:{}".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), e))            res = []        return list(map(int, res))    def read_redis_hot_data(self, channel_id):        """获取redis热门文章结果        :param channel_id:        :return:        """        # format结果        logger.info("{} INFO read channel:{} hot recommend data".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), channel_id))        _key = "ch:{}:hot".format(channel_id)        try:            _res = self.client.zrevrange(_key, 0, -1)        except redis.exceptions.ResponseError as e:            logger.warning("{} WARN read hot article exception:{}".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), e))            _res = []        # 每次返回前50热门文章        res = list(map(int, _res))        if len(res) &gt; 50:            res = res[:50]        return res    def read_hbase_article_similar(self, table_name, key_format, article_num):        """获取文章相似结果        :param article_id: 文章id        :param article_num: 文章数量        :return:        """        # 第一种表结构方式测试：        # create 'article_similar', 'similar'        # put 'article_similar', '1', 'similar:1', 0.2        # put 'article_similar', '1', 'similar:2', 0.34        try:            _dic = self.hbu.get_table_row(table_name, key_format)            res = []            _srt = sorted(_dic.items(), key=lambda obj: obj[1], reverse=True)            if len(_srt) &gt; article_num:                _srt = _srt[:article_num]            for _ in _srt:                res.append(int(_[0].decode().split(':')[1]))        except Exception as e:            logger.error("{} ERROR read similar article exception: {}".format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), e))            res = []        return resif __name__ == '__main__':    rr = ReadRecall()    print(rr.read_hbase_article_similar('article_similar', b'13342', 10))    print(rr.read_hbase_recall_data('cb_recall', b'recall:user:1115629498121846784', b'als:18'))    # rr = ReadRecall()    # print(rr.read_redis_new_data(18))</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/image-20230211193156286.png&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;环境配置&quot;&gt;&lt;a href=&quot;#环境配置&quot; class=&quot;headerlink&quot; title=&quot;环境配置&quot;&gt;&lt;/a&gt;环境配置&lt;/h1&gt;&lt;h2 id=&quot;启动-hadoop</summary>
      
    
    
    
    
  </entry>
  
</feed>
